{"version":3,"file":"lib.modern.js","sources":["../src/BaseConversation.ts","../src/utils/BaseConnection.ts","../src/version.ts","../src/utils/events.ts","../src/utils/overrides.ts","../src/utils/errors.ts","../src/utils/WebSocketConnection.ts","../src/utils/audio.ts","../src/utils/createWorkletModuleLoader.ts","../src/utils/rawAudioProcessor.generated.ts","../src/utils/WebRTCConnection.ts","../src/utils/ConnectionFactory.ts","../src/utils/compatibility.ts","../src/utils/applyDelay.ts","../src/TextConversation.ts","../src/utils/input.ts","../src/utils/audioConcatProcessor.generated.ts","../src/utils/output.ts","../src/VoiceConversation.ts","../src/utils/postOverallFeedback.ts","../src/scribe/connection.ts","../src/utils/scribeAudioProcessor.generated.ts","../src/scribe/scribe.ts","../src/index.ts"],"sourcesContent":["import { Callbacks, Mode, Status } from \"@elevenlabs/types\";\nimport type {\n  BaseConnection,\n  DisconnectionDetails,\n  SessionConfig,\n  FormatConfig,\n} from \"./utils/BaseConnection\";\nimport type {\n  AgentAudioEvent,\n  AgentChatResponsePartEvent,\n  AgentResponseEvent,\n  ClientToolCallEvent,\n  IncomingSocketEvent,\n  InternalTentativeAgentResponseEvent,\n  InterruptionEvent,\n  UserTranscriptionEvent,\n  VadScoreEvent,\n  MCPToolCallClientEvent,\n  AgentToolResponseEvent,\n  ConversationMetadataEvent,\n  AsrInitiationMetadataEvent,\n  MCPConnectionStatusEvent,\n  ErrorMessageEvent,\n  AgentToolRequestEvent,\n} from \"./utils/events\";\nimport type { InputConfig } from \"./utils/input\";\nimport type { OutputConfig } from \"./utils/output\";\n\nexport type { Role, Mode, Status, Callbacks } from \"@elevenlabs/types\";\n\n/** Allows self-hosting the worklets to avoid whitelisting blob: and data: in the CSP script-src  */\nexport type AudioWorkletConfig = {\n  workletPaths?: {\n    rawAudioProcessor?: string;\n    audioConcatProcessor?: string;\n  };\n  libsampleratePath?: string;\n};\n\nexport type Options = SessionConfig &\n  Callbacks &\n  ClientToolsConfig &\n  InputConfig &\n  OutputConfig &\n  AudioWorkletConfig;\n\nexport type PartialOptions = SessionConfig &\n  Partial<Callbacks> &\n  Partial<ClientToolsConfig> &\n  Partial<InputConfig> &\n  Partial<OutputConfig> &\n  Partial<FormatConfig> &\n  Partial<AudioWorkletConfig>;\n\nexport type ClientToolsConfig = {\n  clientTools: Record<\n    string,\n    (\n      parameters: any\n    ) => Promise<string | number | void> | string | number | void\n  >;\n};\n\nconst EMPTY_FREQUENCY_DATA = new Uint8Array(0);\n\nexport function isTextOnly(options: PartialOptions): boolean | undefined {\n  const { textOnly: textOnlyOverride } = options.overrides?.conversation ?? {};\n  const { textOnly } = options;\n  if (typeof textOnly === \"boolean\") {\n    if (\n      typeof textOnlyOverride === \"boolean\" &&\n      textOnly !== textOnlyOverride\n    ) {\n      console.warn(\n        `Conflicting textOnly options provided: ${textOnly} via options.textOnly (will be used) and ${textOnlyOverride} via options.overrides.conversation.textOnly (will be ignored)`\n      );\n    }\n    return textOnly;\n  } else if (typeof textOnlyOverride === \"boolean\") {\n    return textOnlyOverride;\n  } else {\n    return undefined;\n  }\n}\n\nexport class BaseConversation {\n  protected lastInterruptTimestamp = 0;\n  protected mode: Mode = \"listening\";\n  protected status: Status = \"connecting\";\n  protected volume = 1;\n  protected currentEventId = 1;\n  protected lastFeedbackEventId = 0;\n  protected canSendFeedback = false;\n\n  protected static getFullOptions(partialOptions: PartialOptions): Options {\n    const textOnly = isTextOnly(partialOptions);\n    return {\n      clientTools: {},\n      onConnect: () => {},\n      onDebug: () => {},\n      onDisconnect: () => {},\n      onError: () => {},\n      onMessage: () => {},\n      onAudio: () => {},\n      onModeChange: () => {},\n      onStatusChange: () => {},\n      onCanSendFeedbackChange: () => {},\n      onInterruption: () => {},\n      ...partialOptions,\n      textOnly,\n      overrides: {\n        ...partialOptions.overrides,\n        conversation: {\n          ...partialOptions.overrides?.conversation,\n          textOnly,\n        },\n      },\n    };\n  }\n\n  protected constructor(\n    protected readonly options: Options,\n    protected readonly connection: BaseConnection\n  ) {\n    if (this.options.onConnect) {\n      this.options.onConnect({ conversationId: connection.conversationId });\n    }\n    this.connection.onMessage(this.onMessage);\n    this.connection.onDisconnect(this.endSessionWithDetails);\n    this.connection.onModeChange(mode => this.updateMode(mode));\n    this.updateStatus(\"connected\");\n  }\n\n  public endSession() {\n    return this.endSessionWithDetails({ reason: \"user\" });\n  }\n\n  private endSessionWithDetails = async (details: DisconnectionDetails) => {\n    if (this.status !== \"connected\" && this.status !== \"connecting\") return;\n    this.updateStatus(\"disconnecting\");\n    await this.handleEndSession();\n    this.updateStatus(\"disconnected\");\n    if (this.options.onDisconnect) {\n      this.options.onDisconnect(details);\n    }\n  };\n\n  protected async handleEndSession() {\n    this.connection.close();\n  }\n\n  protected updateMode(mode: Mode) {\n    if (mode !== this.mode) {\n      this.mode = mode;\n      if (this.options.onModeChange) {\n        this.options.onModeChange({ mode });\n      }\n    }\n  }\n\n  protected updateStatus(status: Status) {\n    if (status !== this.status) {\n      this.status = status;\n      if (this.options.onStatusChange) {\n        this.options.onStatusChange({ status });\n      }\n    }\n  }\n\n  protected updateCanSendFeedback() {\n    const canSendFeedback = this.currentEventId !== this.lastFeedbackEventId;\n    if (this.canSendFeedback !== canSendFeedback) {\n      this.canSendFeedback = canSendFeedback;\n      if (this.options.onCanSendFeedbackChange) {\n        this.options.onCanSendFeedbackChange({ canSendFeedback });\n      }\n    }\n  }\n\n  protected handleInterruption(event: InterruptionEvent) {\n    if (event.interruption_event) {\n      this.lastInterruptTimestamp = event.interruption_event.event_id;\n\n      if (this.options.onInterruption) {\n        this.options.onInterruption({\n          event_id: event.interruption_event.event_id,\n        });\n      }\n    }\n  }\n\n  protected handleAgentResponse(event: AgentResponseEvent) {\n    if (this.options.onMessage) {\n      this.options.onMessage({\n        source: \"ai\",\n        role: \"agent\",\n        message: event.agent_response_event.agent_response,\n      });\n    }\n  }\n\n  protected handleUserTranscript(event: UserTranscriptionEvent) {\n    if (this.options.onMessage) {\n      this.options.onMessage({\n        source: \"user\",\n        role: \"user\",\n        message: event.user_transcription_event.user_transcript,\n      });\n    }\n  }\n\n  protected handleTentativeAgentResponse(\n    event: InternalTentativeAgentResponseEvent\n  ) {\n    if (this.options.onDebug) {\n      this.options.onDebug({\n        type: \"tentative_agent_response\",\n        response:\n          event.tentative_agent_response_internal_event\n            .tentative_agent_response,\n      });\n    }\n  }\n\n  protected handleVadScore(event: VadScoreEvent) {\n    if (this.options.onVadScore) {\n      this.options.onVadScore({\n        vadScore: event.vad_score_event.vad_score,\n      });\n    }\n  }\n\n  protected async handleClientToolCall(event: ClientToolCallEvent) {\n    if (\n      Object.prototype.hasOwnProperty.call(\n        this.options.clientTools,\n        event.client_tool_call.tool_name\n      )\n    ) {\n      try {\n        const result =\n          (await this.options.clientTools[event.client_tool_call.tool_name](\n            event.client_tool_call.parameters\n          )) ?? \"Client tool execution successful.\"; // default client-tool call response\n\n        // The API expects result to be a string, so we need to convert it if it's not already a string\n        const formattedResult =\n          typeof result === \"object\" ? JSON.stringify(result) : String(result);\n\n        this.connection.sendMessage({\n          type: \"client_tool_result\",\n          tool_call_id: event.client_tool_call.tool_call_id,\n          result: formattedResult,\n          is_error: false,\n        });\n      } catch (e) {\n        this.onError(\n          `Client tool execution failed with following error: ${(e as Error)?.message}`,\n          {\n            clientToolName: event.client_tool_call.tool_name,\n          }\n        );\n        this.connection.sendMessage({\n          type: \"client_tool_result\",\n          tool_call_id: event.client_tool_call.tool_call_id,\n          result: `Client tool execution failed: ${(e as Error)?.message}`,\n          is_error: true,\n        });\n      }\n    } else {\n      if (this.options.onUnhandledClientToolCall) {\n        this.options.onUnhandledClientToolCall(event.client_tool_call);\n\n        return;\n      }\n\n      this.onError(\n        `Client tool with name ${event.client_tool_call.tool_name} is not defined on client`,\n        {\n          clientToolName: event.client_tool_call.tool_name,\n        }\n      );\n      this.connection.sendMessage({\n        type: \"client_tool_result\",\n        tool_call_id: event.client_tool_call.tool_call_id,\n        result: `Client tool with name ${event.client_tool_call.tool_name} is not defined on client`,\n        is_error: true,\n      });\n    }\n  }\n\n  protected handleAudio(event: AgentAudioEvent) {}\n\n  protected handleMCPToolCall(event: MCPToolCallClientEvent) {\n    if (this.options.onMCPToolCall) {\n      this.options.onMCPToolCall(event.mcp_tool_call);\n    }\n  }\n\n  protected handleMCPConnectionStatus(event: MCPConnectionStatusEvent) {\n    if (this.options.onMCPConnectionStatus) {\n      this.options.onMCPConnectionStatus(event.mcp_connection_status);\n    }\n  }\n\n  protected handleAgentToolRequest(event: AgentToolRequestEvent) {\n    if (this.options.onAgentToolRequest) {\n      this.options.onAgentToolRequest(event.agent_tool_request);\n    }\n  }\n\n  protected handleAgentToolResponse(event: AgentToolResponseEvent) {\n    if (event.agent_tool_response.tool_name === \"end_call\") {\n      this.endSessionWithDetails({\n        reason: \"agent\",\n        context: new CloseEvent(\"end_call\", { reason: \"Agent ended the call\" }),\n      });\n    }\n\n    if (this.options.onAgentToolResponse) {\n      this.options.onAgentToolResponse(event.agent_tool_response);\n    }\n  }\n\n  protected handleConversationMetadata(event: ConversationMetadataEvent) {\n    if (this.options.onConversationMetadata) {\n      this.options.onConversationMetadata(\n        event.conversation_initiation_metadata_event\n      );\n    }\n  }\n\n  protected handleAsrInitiationMetadata(event: AsrInitiationMetadataEvent) {\n    if (this.options.onAsrInitiationMetadata) {\n      this.options.onAsrInitiationMetadata(event.asr_initiation_metadata_event);\n    }\n  }\n\n  protected handleAgentChatResponsePart(event: AgentChatResponsePartEvent) {\n    if (this.options.onAgentChatResponsePart) {\n      this.options.onAgentChatResponsePart(event.text_response_part);\n    }\n  }\n\n  protected handleErrorEvent(event: ErrorMessageEvent) {\n    const errorType = event.error_event.error_type;\n    const message =\n      event.error_event.message || event.error_event.reason || \"Unknown error\";\n\n    if (errorType === \"max_duration_exceeded\") {\n      this.endSessionWithDetails({\n        reason: \"error\",\n        message: message,\n        context: new Event(\"max_duration_exceeded\"),\n      });\n      return;\n    }\n\n    this.onError(`Server error: ${message}`, {\n      errorType,\n      code: event.error_event.code,\n      debugMessage: event.error_event.debug_message,\n      details: event.error_event.details,\n    });\n  }\n\n  private onMessage = async (parsedEvent: IncomingSocketEvent) => {\n    switch (parsedEvent.type) {\n      case \"interruption\": {\n        this.handleInterruption(parsedEvent);\n        return;\n      }\n      case \"agent_response\": {\n        this.handleAgentResponse(parsedEvent);\n        return;\n      }\n      case \"user_transcript\": {\n        this.handleUserTranscript(parsedEvent);\n        return;\n      }\n      case \"internal_tentative_agent_response\": {\n        this.handleTentativeAgentResponse(parsedEvent);\n        return;\n      }\n      case \"client_tool_call\": {\n        try {\n          await this.handleClientToolCall(parsedEvent);\n        } catch (error) {\n          this.onError(\n            `Unexpected error in client tool call handling: ${error instanceof Error ? error.message : String(error)}`,\n            {\n              clientToolName: parsedEvent.client_tool_call.tool_name,\n              toolCallId: parsedEvent.client_tool_call.tool_call_id,\n            }\n          );\n        }\n        return;\n      }\n      case \"audio\": {\n        this.handleAudio(parsedEvent);\n        return;\n      }\n\n      case \"vad_score\": {\n        this.handleVadScore(parsedEvent);\n        return;\n      }\n\n      case \"ping\": {\n        this.connection.sendMessage({\n          type: \"pong\",\n          event_id: parsedEvent.ping_event.event_id,\n        });\n        // parsedEvent.ping_event.ping_ms can be used on client side, for example\n        // to warn if ping is too high that experience might be degraded.\n        return;\n      }\n\n      case \"mcp_tool_call\": {\n        this.handleMCPToolCall(parsedEvent);\n        return;\n      }\n\n      case \"mcp_connection_status\": {\n        this.handleMCPConnectionStatus(parsedEvent);\n        return;\n      }\n\n      case \"agent_tool_request\": {\n        this.handleAgentToolRequest(parsedEvent);\n        return;\n      }\n\n      case \"agent_tool_response\": {\n        this.handleAgentToolResponse(parsedEvent);\n        return;\n      }\n\n      case \"conversation_initiation_metadata\": {\n        this.handleConversationMetadata(parsedEvent);\n        return;\n      }\n\n      case \"asr_initiation_metadata\": {\n        this.handleAsrInitiationMetadata(parsedEvent);\n        return;\n      }\n\n      case \"agent_chat_response_part\": {\n        this.handleAgentChatResponsePart(parsedEvent);\n        return;\n      }\n\n      case \"error\": {\n        this.handleErrorEvent(parsedEvent);\n        return;\n      }\n\n      default: {\n        if (this.options.onDebug) {\n          this.options.onDebug(parsedEvent);\n        }\n        return;\n      }\n    }\n  };\n\n  private onError(message: string, context?: any) {\n    console.error(message, context);\n    if (this.options.onError) {\n      this.options.onError(message, context);\n    }\n  }\n\n  public getId() {\n    return this.connection.conversationId;\n  }\n\n  public isOpen() {\n    return this.status === \"connected\";\n  }\n\n  public setVolume = ({ volume }: { volume: number }) => {\n    this.volume = volume;\n  };\n\n  public setMicMuted(isMuted: boolean) {\n    this.connection.setMicMuted(isMuted);\n  }\n\n  public getInputByteFrequencyData(): Uint8Array {\n    return EMPTY_FREQUENCY_DATA;\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array {\n    return EMPTY_FREQUENCY_DATA;\n  }\n\n  public getInputVolume() {\n    return 0;\n  }\n\n  public getOutputVolume() {\n    return 0;\n  }\n\n  public sendFeedback(like: boolean) {\n    if (!this.canSendFeedback) {\n      console.warn(\n        this.lastFeedbackEventId === 0\n          ? \"Cannot send feedback: the conversation has not started yet.\"\n          : \"Cannot send feedback: feedback has already been sent for the current response.\"\n      );\n      return;\n    }\n\n    this.connection.sendMessage({\n      type: \"feedback\",\n      score: like ? \"like\" : \"dislike\",\n      event_id: this.currentEventId,\n    });\n    this.lastFeedbackEventId = this.currentEventId;\n    this.updateCanSendFeedback();\n  }\n\n  public sendContextualUpdate(text: string) {\n    this.connection.sendMessage({\n      type: \"contextual_update\",\n      text,\n    });\n  }\n\n  public sendUserMessage(text: string) {\n    this.connection.sendMessage({\n      type: \"user_message\",\n      text,\n    });\n  }\n\n  public sendUserActivity() {\n    this.connection.sendMessage({\n      type: \"user_activity\",\n    });\n  }\n\n  public sendMCPToolApprovalResult(toolCallId: string, isApproved: boolean) {\n    this.connection.sendMessage({\n      type: \"mcp_tool_approval_result\",\n      tool_call_id: toolCallId,\n      is_approved: isApproved,\n    });\n  }\n}\n","import type { IncomingSocketEvent, OutgoingSocketEvent } from \"./events\";\nimport type { Mode } from \"../BaseConversation\";\nimport type { ConversationConfigOverrideAgentLanguage as Language } from \"@elevenlabs/types/generated/types/asyncapi-types\";\nimport type { DisconnectionDetails } from \"@elevenlabs/types\";\n\nexport type {\n  DisconnectionDetails,\n  ConversationConfigOverrideAgentLanguage as Language,\n} from \"@elevenlabs/types\";\n\nexport type DelayConfig = {\n  default: number;\n  android?: number;\n  ios?: number;\n};\n\nexport type FormatConfig = {\n  format: \"pcm\" | \"ulaw\";\n  sampleRate: number;\n  outputDeviceId?: string;\n};\n\nexport type OnDisconnectCallback = (details: DisconnectionDetails) => void;\nexport type OnMessageCallback = (event: IncomingSocketEvent) => void;\n\nexport type BaseSessionConfig = {\n  origin?: string;\n  authorization?: string;\n  livekitUrl?: string;\n  overrides?: {\n    agent?: {\n      prompt?: {\n        prompt?: string;\n      };\n      firstMessage?: string;\n      language?: Language;\n    };\n    tts?: {\n      voiceId?: string;\n      speed?: number;\n      stability?: number;\n      similarityBoost?: number;\n    };\n    conversation?: {\n      textOnly?: boolean;\n    };\n    client?: {\n      source?: string;\n      version?: string;\n    };\n  };\n  customLlmExtraBody?: unknown;\n  dynamicVariables?: Record<string, string | number | boolean>;\n  useWakeLock?: boolean;\n  connectionDelay?: DelayConfig;\n  textOnly?: boolean;\n  userId?: string;\n};\n\nexport type ConnectionType = \"websocket\" | \"webrtc\";\n\nexport type PublicSessionConfig = BaseSessionConfig & {\n  agentId: string;\n  connectionType: ConnectionType;\n  signedUrl?: never;\n  conversationToken?: never;\n};\n\nexport type PrivateWebSocketSessionConfig = BaseSessionConfig & {\n  signedUrl: string;\n  connectionType?: \"websocket\";\n  agentId?: never;\n  conversationToken?: never;\n};\n\nexport type PrivateWebRTCSessionConfig = BaseSessionConfig & {\n  conversationToken: string;\n  connectionType?: \"webrtc\";\n  agentId?: never;\n  signedUrl?: never;\n};\n\n// Union type for all possible session configurations\nexport type SessionConfig =\n  | PublicSessionConfig\n  | PrivateWebSocketSessionConfig\n  | PrivateWebRTCSessionConfig;\n\nexport abstract class BaseConnection {\n  public abstract readonly conversationId: string;\n  public abstract readonly inputFormat: FormatConfig;\n  public abstract readonly outputFormat: FormatConfig;\n\n  protected queue: IncomingSocketEvent[] = [];\n  protected disconnectionDetails: DisconnectionDetails | null = null;\n  protected onDisconnectCallback: OnDisconnectCallback | null = null;\n  protected onMessageCallback: OnMessageCallback | null = null;\n  protected onModeChangeCallback: ((mode: Mode) => void) | null = null;\n  protected onDebug?: (info: unknown) => void;\n\n  constructor(config: { onDebug?: (info: unknown) => void } = {}) {\n    this.onDebug = config.onDebug;\n  }\n\n  protected debug(info: unknown) {\n    if (this.onDebug) this.onDebug(info);\n  }\n\n  public abstract close(): void;\n  public abstract sendMessage(message: OutgoingSocketEvent): void;\n  public abstract setMicMuted(isMuted: boolean): Promise<void>;\n\n  public onMessage(callback: OnMessageCallback) {\n    this.onMessageCallback = callback;\n    const queue = this.queue;\n    this.queue = [];\n\n    if (queue.length > 0) {\n      // Make sure the queue is flushed after the constructors finishes and\n      // classes are initialized.\n      queueMicrotask(() => {\n        queue.forEach(callback);\n      });\n    }\n  }\n\n  public onDisconnect(callback: OnDisconnectCallback) {\n    this.onDisconnectCallback = callback;\n    const details = this.disconnectionDetails;\n    if (details) {\n      // Make sure the event is triggered after the constructors finishes and\n      // classes are initialized.\n      queueMicrotask(() => {\n        callback(details);\n      });\n    }\n  }\n\n  public onModeChange(callback: (mode: Mode) => void) {\n    this.onModeChangeCallback = callback;\n  }\n\n  protected updateMode(mode: Mode) {\n    this.onModeChangeCallback?.(mode);\n  }\n\n  protected disconnect(details: DisconnectionDetails) {\n    if (!this.disconnectionDetails) {\n      this.disconnectionDetails = details;\n      this.onDisconnectCallback?.(details);\n    }\n  }\n\n  protected handleMessage(parsedEvent: IncomingSocketEvent) {\n    if (this.onMessageCallback) {\n      this.onMessageCallback(parsedEvent);\n    } else {\n      this.queue.push(parsedEvent);\n    }\n  }\n}\n\nexport function parseFormat(format: string): FormatConfig {\n  const [formatPart, sampleRatePart] = format.split(\"_\");\n  if (![\"pcm\", \"ulaw\"].includes(formatPart)) {\n    throw new Error(`Invalid format: ${format}`);\n  }\n\n  const sampleRate = Number.parseInt(sampleRatePart);\n  if (Number.isNaN(sampleRate)) {\n    throw new Error(`Invalid sample rate: ${sampleRatePart}`);\n  }\n\n  return {\n    format: formatPart as FormatConfig[\"format\"],\n    sampleRate,\n  };\n}\n","// This file is auto-generated during build\nexport const PACKAGE_VERSION = \"0.14.0\";\n","import { Outgoing } from \"@elevenlabs/types\";\nimport type { AudioAlignmentEvent } from \"@elevenlabs/types\";\nimport {\n  AgentChatResponsePartClientEvent,\n  AgentResponse,\n  AgentResponseCorrection,\n  AgentToolResponseClientEvent,\n  AsrInitiationMetadataEvent as AsrMetadataEvent,\n  Audio,\n  AgentToolRequestClientEvent,\n  ClientToolCallMessage,\n  ConversationMetadata,\n  ErrorMessage,\n  Interruption,\n  McpConnectionStatusClientEvent,\n  McpToolCall,\n  Ping,\n  InternalTentativeAgentResponse as TentativeAgentResponseInternal,\n  UserTranscript,\n  VadScore,\n} from \"@elevenlabs/types/generated/types/asyncapi-types\";\n\n// Compatibility layer - incoming events\nexport type UserTranscriptionEvent = UserTranscript;\nexport type AgentResponseEvent = AgentResponse;\nexport type AgentAudioEvent = Audio;\nexport type InterruptionEvent = Interruption;\nexport type InternalTentativeAgentResponseEvent =\n  TentativeAgentResponseInternal;\nexport type ConfigEvent = ConversationMetadata;\nexport type PingEvent = Ping;\nexport type ClientToolCallEvent = ClientToolCallMessage;\nexport type VadScoreEvent = VadScore;\nexport type MCPToolCallClientEvent = McpToolCall;\nexport type AgentResponseCorrectionEvent = AgentResponseCorrection;\nexport type AgentToolRequestEvent = AgentToolRequestClientEvent;\nexport type AgentToolResponseEvent = AgentToolResponseClientEvent;\nexport type ConversationMetadataEvent = ConversationMetadata;\nexport type AsrInitiationMetadataEvent = AsrMetadataEvent;\nexport type MCPConnectionStatusEvent = McpConnectionStatusClientEvent;\nexport type AgentChatResponsePartEvent = AgentChatResponsePartClientEvent;\nexport type ErrorMessageEvent = ErrorMessage;\nexport type { AudioAlignmentEvent };\n\nexport type IncomingSocketEvent =\n  | UserTranscriptionEvent\n  | AgentResponseEvent\n  | AgentResponseCorrectionEvent\n  | AgentAudioEvent\n  | InterruptionEvent\n  | InternalTentativeAgentResponseEvent\n  | ConfigEvent\n  | PingEvent\n  | ClientToolCallEvent\n  | VadScoreEvent\n  | MCPToolCallClientEvent\n  | AgentToolRequestEvent\n  | AgentToolResponseEvent\n  | ConversationMetadataEvent\n  | AsrInitiationMetadataEvent\n  | MCPConnectionStatusEvent\n  | AgentChatResponsePartEvent\n  | ErrorMessageEvent;\n\n// Compatibility layer - outgoing events\nexport type PongEvent = Outgoing.PongClientToOrchestratorEvent;\nexport type UserAudioEvent = Outgoing.UserAudio;\nexport type UserFeedbackEvent = Outgoing.UserFeedbackClientToOrchestratorEvent;\nexport type ClientToolResultEvent =\n  Outgoing.ClientToolResultClientToOrchestratorEvent;\nexport type InitiationClientDataEvent =\n  Outgoing.ConversationInitiationClientToOrchestratorEvent;\nexport type ContextualUpdateEvent =\n  Outgoing.ContextualUpdateClientToOrchestratorEvent;\nexport type UserMessageEvent = Outgoing.UserMessageClientToOrchestratorEvent;\nexport type UserActivityEvent = Outgoing.UserActivityClientToOrchestratorEvent;\nexport type MCPToolApprovalResultEvent =\n  Outgoing.McpToolApprovalResultClientToOrchestratorEvent;\n\nexport type OutgoingSocketEvent =\n  | PongEvent\n  | UserAudioEvent\n  | InitiationClientDataEvent\n  | UserFeedbackEvent\n  | ClientToolResultEvent\n  | ContextualUpdateEvent\n  | UserMessageEvent\n  | UserActivityEvent\n  | MCPToolApprovalResultEvent;\n\nexport function isValidSocketEvent(event: any): event is IncomingSocketEvent {\n  return !!event.type;\n}\n","import type { SessionConfig } from \"./BaseConnection\";\nimport type { InitiationClientDataEvent } from \"./events\";\n\nexport const CONVERSATION_INITIATION_CLIENT_DATA_TYPE =\n  \"conversation_initiation_client_data\";\n\nexport function constructOverrides(\n  config: SessionConfig\n): InitiationClientDataEvent {\n  const overridesEvent: InitiationClientDataEvent = {\n    type: CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n  };\n\n  if (config.overrides) {\n    overridesEvent.conversation_config_override = {\n      agent: {\n        prompt: config.overrides.agent?.prompt,\n        first_message: config.overrides.agent?.firstMessage,\n        language: config.overrides.agent?.language,\n      },\n      tts: {\n        voice_id: config.overrides.tts?.voiceId,\n        speed: config.overrides.tts?.speed,\n        stability: config.overrides.tts?.stability,\n        similarity_boost: config.overrides.tts?.similarityBoost,\n      },\n      conversation: {\n        text_only: config.overrides.conversation?.textOnly,\n      },\n    };\n  }\n\n  if (config.customLlmExtraBody) {\n    overridesEvent.custom_llm_extra_body = config.customLlmExtraBody;\n  }\n\n  if (config.dynamicVariables) {\n    overridesEvent.dynamic_variables = config.dynamicVariables;\n  }\n\n  if (config.userId) {\n    overridesEvent.user_id = config.userId;\n  }\n\n  if (config.overrides?.client) {\n    overridesEvent.source_info = {\n      source: config.overrides.client.source,\n      version: config.overrides.client.version,\n    };\n  }\n\n  return overridesEvent;\n}\n","export class SessionConnectionError extends Error {\n  public readonly closeCode?: number;\n  public readonly closeReason?: string;\n\n  constructor(\n    message: string,\n    options?: { closeCode?: number; closeReason?: string }\n  ) {\n    super(message);\n    this.name = \"SessionConnectionError\";\n    this.closeCode = options?.closeCode;\n    this.closeReason = options?.closeReason;\n  }\n}\n","import {\n  BaseConnection,\n  type SessionConfig,\n  type FormatConfig,\n  parseFormat,\n} from \"./BaseConnection\";\nimport { PACKAGE_VERSION } from \"../version\";\nimport {\n  type ConfigEvent,\n  isValidSocketEvent,\n  type OutgoingSocketEvent,\n} from \"./events\";\nimport { constructOverrides } from \"./overrides\";\nimport { SessionConnectionError } from \"./errors\";\n\nconst MAIN_PROTOCOL = \"convai\";\nconst WSS_API_ORIGIN = \"wss://api.elevenlabs.io\";\nconst WSS_API_PATHNAME = \"/v1/convai/conversation?agent_id=\";\n\nexport class WebSocketConnection extends BaseConnection {\n  public readonly conversationId: string;\n  public readonly inputFormat: FormatConfig;\n  public readonly outputFormat: FormatConfig;\n\n  private constructor(\n    private readonly socket: WebSocket,\n    conversationId: string,\n    inputFormat: FormatConfig,\n    outputFormat: FormatConfig\n  ) {\n    super();\n    this.conversationId = conversationId;\n    this.inputFormat = inputFormat;\n    this.outputFormat = outputFormat;\n\n    this.socket.addEventListener(\"error\", event => {\n      // In case the error event is followed by a close event, we want the\n      // latter to be the one that disconnects the session as it contains more\n      // useful information.\n      setTimeout(\n        () =>\n          this.disconnect({\n            reason: \"error\",\n            message: \"The connection was closed due to a socket error.\",\n            context: event,\n          }),\n        0\n      );\n    });\n\n    this.socket.addEventListener(\"close\", event => {\n      this.disconnect(\n        event.code === 1000\n          ? {\n              reason: \"agent\",\n              context: event,\n              closeCode: event.code,\n              closeReason: event.reason || undefined,\n            }\n          : {\n              reason: \"error\",\n              message:\n                event.reason || \"The connection was closed by the server.\",\n              context: event,\n              closeCode: event.code,\n              closeReason: event.reason || undefined,\n            }\n      );\n    });\n\n    this.socket.addEventListener(\"message\", event => {\n      try {\n        const parsedEvent = JSON.parse(event.data);\n        if (!isValidSocketEvent(parsedEvent)) {\n          this.debug({\n            type: \"invalid_event\",\n            message: \"Received invalid socket event\",\n            data: event.data,\n          });\n          return;\n        }\n        this.handleMessage(parsedEvent);\n      } catch (error) {\n        this.debug({\n          type: \"parsing_error\",\n          message: \"Failed to parse socket message\",\n          error: error instanceof Error ? error.message : String(error),\n          data: event.data,\n        });\n      }\n    });\n  }\n\n  public static async create(\n    config: SessionConfig\n  ): Promise<WebSocketConnection> {\n    let socket: WebSocket | null = null;\n\n    try {\n      const origin = config.origin ?? WSS_API_ORIGIN;\n      let url: string;\n\n      const version = config.overrides?.client?.version || PACKAGE_VERSION;\n      const source = config.overrides?.client?.source || \"js_sdk\";\n\n      if (config.signedUrl) {\n        const separator = config.signedUrl.includes(\"?\") ? \"&\" : \"?\";\n        url = `${config.signedUrl}${separator}source=${source}&version=${version}`;\n      } else {\n        url = `${origin}${WSS_API_PATHNAME}${config.agentId}&source=${source}&version=${version}`;\n      }\n\n      const protocols = [MAIN_PROTOCOL];\n      if (config.authorization) {\n        protocols.push(`bearer.${config.authorization}`);\n      }\n      socket = new WebSocket(url, protocols);\n\n      const conversationConfig = await new Promise<\n        ConfigEvent[\"conversation_initiation_metadata_event\"]\n      >((resolve, reject) => {\n        socket!.addEventListener(\n          \"open\",\n          () => {\n            const overridesEvent = constructOverrides(config);\n\n            socket?.send(JSON.stringify(overridesEvent));\n          },\n          { once: true }\n        );\n\n        socket!.addEventListener(\"error\", event => {\n          // In case the error event is followed by a close event, we want the\n          // latter to be the one that rejects the promise as it contains more\n          // useful information.\n          setTimeout(\n            () =>\n              reject(\n                new SessionConnectionError(\n                  \"The connection was closed due to a socket error.\"\n                )\n              ),\n            0\n          );\n        });\n\n        socket!.addEventListener(\"close\", (event: CloseEvent) => {\n          const message =\n            event.reason ||\n            (event.code === 1000\n              ? \"Connection closed normally before session could be established.\"\n              : \"Connection closed unexpectedly before session could be established.\");\n          reject(\n            new SessionConnectionError(message, {\n              closeCode: event.code,\n              closeReason: event.reason || undefined,\n            })\n          );\n        });\n\n        socket!.addEventListener(\n          \"message\",\n          (event: MessageEvent) => {\n            const message = JSON.parse(event.data);\n\n            if (!isValidSocketEvent(message)) {\n              return;\n            }\n\n            if (message.type === \"conversation_initiation_metadata\") {\n              resolve(message.conversation_initiation_metadata_event);\n            } else {\n              console.warn(\n                \"First received message is not conversation metadata.\"\n              );\n            }\n          },\n          { once: true }\n        );\n      });\n\n      const {\n        conversation_id,\n        agent_output_audio_format,\n        user_input_audio_format,\n      } = conversationConfig;\n\n      const inputFormat = parseFormat(user_input_audio_format ?? \"pcm_16000\");\n      const outputFormat = parseFormat(agent_output_audio_format);\n\n      return new WebSocketConnection(\n        socket,\n        conversation_id,\n        inputFormat,\n        outputFormat\n      );\n    } catch (error) {\n      socket?.close();\n      throw error;\n    }\n  }\n\n  public close() {\n    this.socket.close(1000, \"User ended conversation\");\n  }\n\n  public sendMessage(message: OutgoingSocketEvent) {\n    this.socket.send(JSON.stringify(message));\n  }\n\n  public async setMicMuted(isMuted: boolean): Promise<void> {\n    console.warn(\n      `WebSocket connection setMicMuted called with ${isMuted}, but this is handled by VoiceConversation`\n    );\n  }\n}\n","export function arrayBufferToBase64(b: ArrayBufferLike) {\n  const buffer = new Uint8Array(b);\n  // @ts-ignore\n  const base64Data = window.btoa(String.fromCharCode(...buffer));\n  return base64Data;\n}\n\nexport function base64ToArrayBuffer(base64: string): ArrayBuffer {\n  const binaryString = window.atob(base64);\n  const len = binaryString.length;\n  const bytes = new Uint8Array(len);\n  for (let i = 0; i < len; i++) {\n    bytes[i] = binaryString.charCodeAt(i);\n  }\n  return bytes.buffer;\n}\n","const URLCache = new Map<string, string>();\n\nexport function createWorkletModuleLoader(name: string, sourceCode: string) {\n  return async (worklet: AudioWorklet, path?: string) => {\n    const cachedUrl = URLCache.get(name);\n    if (cachedUrl) {\n      return worklet.addModule(cachedUrl);\n    }\n\n    // If a path is provided, use it directly (CSP-friendly approach)\n    if (path) {\n      try {\n        await worklet.addModule(path);\n        URLCache.set(name, path);\n        return;\n      } catch (error) {\n        throw new Error(\n          `Failed to load the ${name} worklet module from path: ${path}. Error: ${error}`\n        );\n      }\n    }\n\n    const blob = new Blob([sourceCode], { type: \"application/javascript\" });\n    const blobURL = URL.createObjectURL(blob);\n    try {\n      await worklet.addModule(blobURL);\n      URLCache.set(name, blobURL);\n      return;\n    } catch {\n      URL.revokeObjectURL(blobURL);\n    }\n\n    try {\n      // Attempting to start a conversation in Safari inside an iframe will\n      // throw a CORS error because the blob:// protocol is considered\n      // cross-origin. In such cases, fall back to using a base64 data URL:\n      const base64 = btoa(sourceCode);\n      const moduleURL = `data:application/javascript;base64,${base64}`;\n      await worklet.addModule(moduleURL);\n      URLCache.set(name, moduleURL);\n    } catch (error) {\n      throw new Error(\n        `Failed to load the ${name} worklet module. Make sure the browser supports AudioWorklets. If you are using a strict CSP, you may need to self-host the worklet files.`\n      );\n    }\n  };\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadRawAudioProcessor = createWorkletModuleLoader(\n  \"rawAudioProcessor\",\n  // language=JavaScript\n  `/*\n * ulaw encoding logic taken from the wavefile library\n * https://github.com/rochars/wavefile/blob/master/lib/codecs/mulaw.js\n * USED BY @elevenlabs/client\n */\n\nconst BIAS = 0x84;\nconst CLIP = 32635;\nconst encodeTable = [\n  0,0,1,1,2,2,2,2,3,3,3,3,3,3,3,3,\n  4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,\n  5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\n  5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7\n];\n\nfunction encodeSample(sample) {\n  let sign;\n  let exponent;\n  let mantissa;\n  let muLawSample;\n  sign = (sample >> 8) & 0x80;\n  if (sign !== 0) sample = -sample;\n  sample = sample + BIAS;\n  if (sample > CLIP) sample = CLIP;\n  exponent = encodeTable[(sample>>7) & 0xFF];\n  mantissa = (sample >> (exponent+3)) & 0x0F;\n  muLawSample = ~(sign | (exponent << 4) | mantissa);\n  \n  return muLawSample;\n}\n\nclass RawAudioProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n              \n    this.port.onmessage = ({ data }) => {\n      switch (data.type) {\n        case \"setFormat\":\n          this.isMuted = false;\n          this.buffer = []; // Initialize an empty buffer\n          this.bufferSize = data.sampleRate / 10;\n          this.format = data.format;\n\n          if (globalThis.LibSampleRate && sampleRate !== data.sampleRate) {\n            globalThis.LibSampleRate.create(1, sampleRate, data.sampleRate).then(resampler => {\n              this.resampler = resampler;\n            });\n          }\n          break;\n        case \"setMuted\":\n          this.isMuted = data.isMuted;\n          break;\n      }\n    };\n  }\n  process(inputs) {\n    if (!this.buffer) {\n      return true;\n    }\n    \n    const input = inputs[0]; // Get the first input node\n    if (input.length > 0) {\n      let channelData = input[0]; // Get the first channel's data\n\n      // Resample the audio if necessary\n      if (this.resampler) {\n        channelData = this.resampler.full(channelData);\n      }\n\n      // Add channel data to the buffer\n      this.buffer.push(...channelData);\n      // Get max volume \n      let sum = 0.0;\n      for (let i = 0; i < channelData.length; i++) {\n        sum += channelData[i] * channelData[i];\n      }\n      const maxVolume = Math.sqrt(sum / channelData.length);\n      // Check if buffer size has reached or exceeded the threshold\n      if (this.buffer.length >= this.bufferSize) {\n        const float32Array = this.isMuted \n          ? new Float32Array(this.buffer.length)\n          : new Float32Array(this.buffer);\n\n        let encodedArray = this.format === \"ulaw\"\n          ? new Uint8Array(float32Array.length)\n          : new Int16Array(float32Array.length);\n\n        // Iterate through the Float32Array and convert each sample to PCM16\n        for (let i = 0; i < float32Array.length; i++) {\n          // Clamp the value to the range [-1, 1]\n          let sample = Math.max(-1, Math.min(1, float32Array[i]));\n\n          // Scale the sample to the range [-32768, 32767]\n          let value = sample < 0 ? sample * 32768 : sample * 32767;\n          if (this.format === \"ulaw\") {\n            value = encodeSample(Math.round(value));\n          }\n\n          encodedArray[i] = value;\n        }\n\n        // Send the buffered data to the main script\n        this.port.postMessage([encodedArray, maxVolume]);\n\n        // Clear the buffer after sending\n        this.buffer = [];\n      }\n    }\n    return true; // Continue processing\n  }\n}\nregisterProcessor(\"rawAudioProcessor\", RawAudioProcessor);\n`\n);\n","import {\n  BaseConnection,\n  type SessionConfig,\n  type FormatConfig,\n  parseFormat,\n} from \"./BaseConnection\";\nimport { PACKAGE_VERSION } from \"../version\";\nimport { isValidSocketEvent, type OutgoingSocketEvent } from \"./events\";\nimport {\n  Room,\n  RoomEvent,\n  Track,\n  ConnectionState,\n  createLocalAudioTrack,\n} from \"livekit-client\";\nimport type {\n  RemoteAudioTrack,\n  Participant,\n  TrackPublication,\n  RemoteParticipant,\n} from \"livekit-client\";\nimport {\n  constructOverrides,\n  CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n} from \"./overrides\";\nimport { arrayBufferToBase64 } from \"./audio\";\nimport { loadRawAudioProcessor } from \"./rawAudioProcessor.generated\";\n\nconst DEFAULT_LIVEKIT_WS_URL = \"wss://livekit.rtc.elevenlabs.io\";\nconst HTTPS_API_ORIGIN = \"https://api.elevenlabs.io\";\n\n// Convert WSS origin to HTTPS for API calls\nfunction convertWssToHttps(origin: string): string {\n  return origin.replace(/^wss:\\/\\//, \"https://\");\n}\n\nexport type ConnectionConfig = SessionConfig & {\n  onDebug?: (info: unknown) => void;\n};\n\nexport class WebRTCConnection extends BaseConnection {\n  public conversationId: string;\n  public readonly inputFormat: FormatConfig;\n  public readonly outputFormat: FormatConfig;\n\n  private room: Room;\n  private isConnected = false;\n  private audioEventId = 1;\n  private audioCaptureContext: AudioContext | null = null;\n  private audioElements: HTMLAudioElement[] = [];\n  private outputDeviceId: string | null = null;\n\n  private outputAnalyser: AnalyserNode | null = null;\n  private outputFrequencyData: Uint8Array<ArrayBuffer> | null = null;\n\n  private constructor(\n    room: Room,\n    conversationId: string,\n    inputFormat: FormatConfig,\n    outputFormat: FormatConfig,\n    config: { onDebug?: (info: unknown) => void } = {}\n  ) {\n    super(config);\n    this.room = room;\n    this.conversationId = conversationId;\n    this.inputFormat = inputFormat;\n    this.outputFormat = outputFormat;\n\n    this.setupRoomEventListeners();\n  }\n\n  public static async create(\n    config: ConnectionConfig\n  ): Promise<WebRTCConnection> {\n    let conversationToken: string;\n\n    // Handle different authentication scenarios\n    if (\"conversationToken\" in config && config.conversationToken) {\n      // Direct token provided\n      conversationToken = config.conversationToken;\n    } else if (\"agentId\" in config && config.agentId) {\n      // Agent ID provided - fetch token from API\n      try {\n        const version = config.overrides?.client?.version || PACKAGE_VERSION;\n        const source = config.overrides?.client?.source || \"js_sdk\";\n        const configOrigin = config.origin ?? HTTPS_API_ORIGIN;\n        const origin = convertWssToHttps(configOrigin); //origin is wss, not https\n        const url = `${origin}/v1/convai/conversation/token?agent_id=${config.agentId}&source=${source}&version=${version}`;\n        const response = await fetch(url);\n\n        if (!response.ok) {\n          throw new Error(\n            `ElevenLabs API returned ${response.status} ${response.statusText}`\n          );\n        }\n\n        const data = await response.json();\n        conversationToken = data.token;\n\n        if (!conversationToken) {\n          throw new Error(\"No conversation token received from API\");\n        }\n      } catch (error) {\n        let msg = error instanceof Error ? error.message : String(error);\n        if (error instanceof Error && error.message.includes(\"401\")) {\n          msg =\n            \"Your agent has authentication enabled, but no signed URL or conversation token was provided.\";\n        }\n\n        throw new Error(\n          `Failed to fetch conversation token for agent ${config.agentId}: ${msg}`\n        );\n      }\n    } else {\n      throw new Error(\n        \"Either conversationToken or agentId is required for WebRTC connection\"\n      );\n    }\n\n    const room = new Room();\n\n    try {\n      // Create connection instance first to set up event listeners\n      const conversationId = `room_${Date.now()}`;\n      const inputFormat = parseFormat(\"pcm_48000\");\n      const outputFormat = parseFormat(\"pcm_48000\");\n      const connection = new WebRTCConnection(\n        room,\n        conversationId,\n        inputFormat,\n        outputFormat,\n        config\n      );\n\n      // Use configurable LiveKit URL or default if not provided\n      const livekitUrl = config.livekitUrl || DEFAULT_LIVEKIT_WS_URL;\n\n      // Connect to the LiveKit room and wait for the Connected event\n      await room.connect(livekitUrl, conversationToken);\n\n      // Wait for the Connected event to ensure isConnected is true\n      await new Promise<void>(resolve => {\n        if (connection.isConnected) {\n          resolve();\n        } else {\n          const onConnected = () => {\n            room.off(RoomEvent.Connected, onConnected);\n            resolve();\n          };\n          room.on(RoomEvent.Connected, onConnected);\n        }\n      });\n\n      if (room.name) {\n        connection.conversationId =\n          room.name.match(/(conv_[a-zA-Z0-9]+)/)?.[0] || room.name;\n      }\n\n      // Enable microphone only if not text-only mode\n      if (!config.textOnly) {\n        await room.localParticipant.setMicrophoneEnabled(true);\n      }\n\n      const overridesEvent = constructOverrides(config);\n\n      connection.debug({\n        type: CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n        message: overridesEvent,\n      });\n\n      await connection.sendMessage(overridesEvent);\n\n      return connection;\n    } catch (error) {\n      await room.disconnect();\n      throw error;\n    }\n  }\n\n  private setupRoomEventListeners() {\n    this.room.on(RoomEvent.Connected, async () => {\n      this.isConnected = true;\n      console.info(\"WebRTC room connected\");\n    });\n\n    this.room.on(RoomEvent.Disconnected, reason => {\n      this.isConnected = false;\n      this.disconnect({\n        reason: \"agent\",\n        context: new CloseEvent(\"close\", { reason: reason?.toString() }),\n      });\n    });\n\n    this.room.on(RoomEvent.ConnectionStateChanged, state => {\n      if (state === ConnectionState.Disconnected) {\n        this.isConnected = false;\n        this.disconnect({\n          reason: \"error\",\n          message: `LiveKit connection state changed to ${state}`,\n          context: new Event(\"connection_state_changed\"),\n        });\n      }\n    });\n\n    // Handle incoming data messages\n    this.room.on(\n      RoomEvent.DataReceived,\n      (payload: Uint8Array, _participant) => {\n        try {\n          const message = JSON.parse(new TextDecoder().decode(payload));\n\n          // Filter out audio messages for WebRTC - they're handled via audio tracks\n          if (message.type === \"audio\") {\n            return;\n          }\n\n          if (isValidSocketEvent(message)) {\n            this.handleMessage(message);\n          } else {\n            console.warn(\"Invalid socket event received:\", message);\n          }\n        } catch (error) {\n          console.warn(\"Failed to parse incoming data message:\", error);\n          console.warn(\"Raw payload:\", new TextDecoder().decode(payload));\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.TrackSubscribed,\n      async (\n        track: Track,\n        _publication: TrackPublication,\n        participant: Participant\n      ) => {\n        if (\n          track.kind === Track.Kind.Audio &&\n          participant.identity.includes(\"agent\")\n        ) {\n          // Play the audio track\n          const remoteAudioTrack = track as RemoteAudioTrack;\n          const audioElement = remoteAudioTrack.attach();\n          audioElement.autoplay = true;\n          audioElement.controls = false;\n\n          // Set output device if one was previously selected\n          if (this.outputDeviceId && audioElement.setSinkId) {\n            try {\n              await audioElement.setSinkId(this.outputDeviceId);\n            } catch (error) {\n              console.warn(\n                \"Failed to set output device for new audio element:\",\n                error\n              );\n            }\n          }\n\n          // Add to DOM (hidden) to ensure it plays\n          audioElement.style.display = \"none\";\n          document.body.appendChild(audioElement);\n\n          // Store reference for volume control\n          this.audioElements.push(audioElement);\n\n          // Apply current volume if it exists (for when volume was set before audio track arrived)\n          if (this.audioElements.length === 1) {\n            // First audio element - trigger a callback to sync with current volume\n            this.onDebug?.({ type: \"audio_element_ready\" });\n          }\n\n          // Set up audio capture for onAudio callback\n          await this.setupAudioCapture(remoteAudioTrack);\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.ActiveSpeakersChanged,\n      async (speakers: Participant[]) => {\n        if (speakers.length > 0) {\n          this.updateMode(\n            speakers[0].identity.startsWith(\"agent\") ? \"speaking\" : \"listening\"\n          );\n        } else {\n          this.updateMode(\"listening\");\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.ParticipantDisconnected,\n      (participant: RemoteParticipant) => {\n        if (participant.identity?.startsWith(\"agent\")) {\n          this.disconnect({\n            reason: \"agent\",\n            context: new CloseEvent(\"close\", { reason: \"agent disconnected\" }),\n          });\n        }\n      }\n    );\n  }\n\n  public close() {\n    if (this.isConnected) {\n      try {\n        // Explicitly stop all local tracks before disconnecting to ensure microphone is released\n        this.room.localParticipant.audioTrackPublications.forEach(\n          publication => {\n            if (publication.track) {\n              publication.track.stop();\n            }\n          }\n        );\n      } catch (error) {\n        console.warn(\"Error stopping local tracks:\", error);\n      }\n\n      // Clean up audio capture context (non-blocking)\n      if (this.audioCaptureContext) {\n        this.audioCaptureContext.close().catch(error => {\n          console.warn(\"Error closing audio capture context:\", error);\n        });\n        this.audioCaptureContext = null;\n      }\n\n      // Clean up audio elements\n      this.audioElements.forEach(element => {\n        if (element.parentNode) {\n          element.parentNode.removeChild(element);\n        }\n      });\n      this.audioElements = [];\n\n      this.room.disconnect();\n    }\n  }\n\n  public async sendMessage(message: OutgoingSocketEvent) {\n    if (!this.isConnected || !this.room.localParticipant) {\n      console.warn(\n        \"Cannot send message: room not connected or no local participant\"\n      );\n      return;\n    }\n\n    // In WebRTC mode, audio is sent via published tracks, not data messages\n    if (\"user_audio_chunk\" in message) {\n      // Ignore audio data messages - audio flows through WebRTC tracks\n      return;\n    }\n\n    try {\n      const encoder = new TextEncoder();\n      const data = encoder.encode(JSON.stringify(message));\n\n      await this.room.localParticipant.publishData(data, { reliable: true });\n    } catch (error) {\n      this.debug({\n        type: \"send_message_error\",\n        message: {\n          message,\n          error,\n        },\n      });\n      console.error(\"Failed to send message via WebRTC:\", error);\n    }\n  }\n\n  // Get the room instance for advanced usage\n  public getRoom(): Room {\n    return this.room;\n  }\n\n  public async setMicMuted(isMuted: boolean): Promise<void> {\n    if (!this.isConnected || !this.room.localParticipant) {\n      console.warn(\n        \"Cannot set microphone muted: room not connected or no local participant\"\n      );\n      return;\n    }\n\n    // Get the microphone track publication\n    const micTrackPublication = this.room.localParticipant.getTrackPublication(\n      Track.Source.Microphone\n    );\n\n    if (micTrackPublication?.track) {\n      try {\n        // Use LiveKit's built-in track muting\n        if (isMuted) {\n          await micTrackPublication.track.mute();\n        } else {\n          await micTrackPublication.track.unmute();\n        }\n      } catch (_error) {\n        // If track muting fails, fall back to participant-level control\n        await this.room.localParticipant.setMicrophoneEnabled(!isMuted);\n      }\n    } else {\n      // No track found, use participant-level control directly\n      await this.room.localParticipant.setMicrophoneEnabled(!isMuted);\n    }\n  }\n\n  private async setupAudioCapture(track: RemoteAudioTrack) {\n    try {\n      // Create audio context for processing\n      const audioContext = new AudioContext();\n      this.audioCaptureContext = audioContext;\n\n      // Create analyser for frequency data\n      this.outputAnalyser = audioContext.createAnalyser();\n      this.outputAnalyser.fftSize = 2048;\n      this.outputAnalyser.smoothingTimeConstant = 0.8;\n\n      // Create MediaStream from the track\n      const mediaStream = new MediaStream([track.mediaStreamTrack]);\n\n      // Create audio source from the stream\n      const source = audioContext.createMediaStreamSource(mediaStream);\n\n      // Connect source to analyser\n      source.connect(this.outputAnalyser);\n\n      await loadRawAudioProcessor(audioContext.audioWorklet);\n      const worklet = new AudioWorkletNode(audioContext, \"rawAudioProcessor\");\n\n      // Connect analyser to worklet for processing\n      this.outputAnalyser.connect(worklet);\n\n      // Configure the processor for the output format\n      worklet.port.postMessage({\n        type: \"setFormat\",\n        format: this.outputFormat.format,\n        sampleRate: this.outputFormat.sampleRate,\n      });\n\n      // Handle processed audio data\n      worklet.port.onmessage = (event: MessageEvent) => {\n        const [audioData, maxVolume] = event.data;\n\n        // Only send audio if there's significant volume (not just silence)\n        const volumeThreshold = 0.01;\n\n        if (maxVolume > volumeThreshold) {\n          // Convert to base64\n          const base64Audio = arrayBufferToBase64(audioData.buffer);\n\n          // Use sequential event ID for proper feedback tracking\n          const eventId = this.audioEventId++;\n\n          // Trigger the onAudio callback by simulating an audio event\n          this.handleMessage({\n            type: \"audio\",\n            audio_event: {\n              audio_base_64: base64Audio,\n              event_id: eventId,\n            },\n          });\n        }\n      };\n\n      // Connect the audio processing chain\n      source.connect(worklet);\n    } catch (error) {\n      console.warn(\"Failed to set up audio capture:\", error);\n    }\n  }\n\n  public setAudioVolume(volume: number) {\n    this.audioElements.forEach(element => {\n      element.volume = volume;\n    });\n  }\n\n  public async setAudioOutputDevice(deviceId: string): Promise<void> {\n    if (!(\"setSinkId\" in HTMLAudioElement.prototype)) {\n      throw new Error(\"setSinkId is not supported in this browser\");\n    }\n\n    // Set output device for all existing audio elements\n    const promises = this.audioElements.map(async element => {\n      try {\n        await element.setSinkId(deviceId);\n      } catch (error) {\n        console.error(\"Failed to set sink ID for audio element:\", error);\n        throw error;\n      }\n    });\n\n    await Promise.all(promises);\n\n    // Store the device ID for future audio elements\n    this.outputDeviceId = deviceId;\n  }\n\n  public async setAudioInputDevice(deviceId: string): Promise<void> {\n    if (!this.isConnected || !this.room.localParticipant) {\n      throw new Error(\n        \"Cannot change input device: room not connected or no local participant\"\n      );\n    }\n\n    try {\n      // Get the current microphone track publication\n      const currentMicTrackPublication =\n        this.room.localParticipant.getTrackPublication(Track.Source.Microphone);\n\n      // Stop the current microphone track if it exists\n      if (currentMicTrackPublication?.track) {\n        await currentMicTrackPublication.track.stop();\n        await this.room.localParticipant.unpublishTrack(\n          currentMicTrackPublication.track\n        );\n      }\n\n      // Create constraints for the new input device\n      const audioConstraints: MediaTrackConstraints = {\n        deviceId: { exact: deviceId },\n        echoCancellation: true,\n        noiseSuppression: true,\n        autoGainControl: true,\n        channelCount: { ideal: 1 },\n      };\n\n      // Create new audio track with the specified device\n      const audioTrack = await createLocalAudioTrack(audioConstraints);\n\n      // Publish the new microphone track\n      await this.room.localParticipant.publishTrack(audioTrack, {\n        name: \"microphone\",\n        source: Track.Source.Microphone,\n      });\n    } catch (error) {\n      console.error(\"Failed to change input device:\", error);\n\n      // Try to re-enable default microphone on failure\n      try {\n        await this.room.localParticipant.setMicrophoneEnabled(true);\n      } catch (recoveryError) {\n        console.error(\n          \"Failed to recover microphone after device switch error:\",\n          recoveryError\n        );\n      }\n\n      throw error;\n    }\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array<ArrayBuffer> | null {\n    if (!this.outputAnalyser) return null;\n\n    this.outputFrequencyData ??= new Uint8Array(\n      this.outputAnalyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.outputAnalyser.getByteFrequencyData(this.outputFrequencyData);\n    return this.outputFrequencyData;\n  }\n}\n","import type {\n  BaseConnection,\n  SessionConfig,\n  ConnectionType,\n} from \"./BaseConnection\";\nimport { WebSocketConnection } from \"./WebSocketConnection\";\nimport { WebRTCConnection } from \"./WebRTCConnection\";\n\nfunction determineConnectionType(config: SessionConfig): ConnectionType {\n  // If connectionType is explicitly specified, use it\n  if (config.connectionType) {\n    return config.connectionType;\n  }\n\n  // If conversationToken is provided, use WebRTC\n  if (\"conversationToken\" in config && config.conversationToken) {\n    return \"webrtc\";\n  }\n\n  // Default to WebSocket for backward compatibility\n  return \"websocket\";\n}\n\nexport async function createConnection(\n  config: SessionConfig\n): Promise<BaseConnection> {\n  const connectionType = determineConnectionType(config);\n\n  switch (connectionType) {\n    case \"websocket\":\n      return WebSocketConnection.create(config);\n    case \"webrtc\":\n      return WebRTCConnection.create(config);\n    default:\n      throw new Error(`Unknown connection type: ${connectionType}`);\n  }\n}\n","export function isIosDevice() {\n  return (\n    [\n      \"iPad Simulator\",\n      \"iPhone Simulator\",\n      \"iPod Simulator\",\n      \"iPad\",\n      \"iPhone\",\n      \"iPod\",\n    ].includes(navigator.platform) ||\n    // iPad on iOS 13 detection\n    (navigator.userAgent.includes(\"Mac\") && \"ontouchend\" in document)\n  );\n}\n\nexport function isAndroidDevice() {\n  return /android/i.test(navigator.userAgent);\n}\n","import { isAndroidDevice, isIosDevice } from \"./compatibility\";\nimport type { DelayConfig } from \"./connection\";\n\nexport async function applyDelay(\n  delayConfig: DelayConfig = {\n    default: 0,\n    // Give the Android AudioManager enough time to switch to the correct audio mode\n    android: 3_000,\n  }\n) {\n  let delay = delayConfig.default;\n  if (isAndroidDevice()) {\n    delay = delayConfig.android ?? delay;\n  } else if (isIosDevice()) {\n    delay = delayConfig.ios ?? delay;\n  }\n\n  if (delay > 0) {\n    await new Promise(resolve => setTimeout(resolve, delay));\n  }\n}\n","import { createConnection } from \"./utils/ConnectionFactory\";\nimport type { BaseConnection } from \"./utils/BaseConnection\";\nimport { applyDelay } from \"./utils/applyDelay\";\nimport { BaseConversation, type PartialOptions } from \"./BaseConversation\";\n\nexport class TextConversation extends BaseConversation {\n  public static async startSession(\n    options: PartialOptions\n  ): Promise<TextConversation> {\n    const fullOptions = BaseConversation.getFullOptions(options);\n\n    if (fullOptions.onStatusChange) {\n      fullOptions.onStatusChange({ status: \"connecting\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n    if (fullOptions.onModeChange) {\n      fullOptions.onModeChange({ mode: \"listening\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n\n    let connection: BaseConnection | null = null;\n    try {\n      await applyDelay(fullOptions.connectionDelay);\n      connection = await createConnection(options);\n      return new TextConversation(fullOptions, connection);\n    } catch (error) {\n      if (fullOptions.onStatusChange) {\n        fullOptions.onStatusChange({ status: \"disconnected\" });\n      }\n      connection?.close();\n      throw error;\n    }\n  }\n}\n","import { loadRawAudioProcessor } from \"./rawAudioProcessor.generated\";\nimport type { FormatConfig } from \"./connection\";\nimport { isIosDevice } from \"./compatibility\";\nimport type { AudioWorkletConfig } from \"../BaseConversation\";\n\nexport type InputConfig = {\n  preferHeadphonesForIosDevices?: boolean;\n  inputDeviceId?: string;\n  onError?(message: string, context?: unknown): void;\n};\n\nconst LIBSAMPLERATE_JS =\n  \"https://cdn.jsdelivr.net/npm/@alexanderolsen/libsamplerate-js@2.1.2/dist/libsamplerate.worklet.js\";\n\nconst defaultConstraints = {\n  echoCancellation: true,\n  noiseSuppression: true,\n  // Automatic gain control helps maintain a steady volume level with microphones: https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackSettings/autoGainControl\n  autoGainControl: true,\n  // Mono audio for better echo cancellation\n  channelCount: { ideal: 1 },\n};\n\nexport class Input {\n  public static async create({\n    sampleRate,\n    format,\n    preferHeadphonesForIosDevices,\n    inputDeviceId,\n    workletPaths,\n    libsampleratePath,\n    onError,\n  }: FormatConfig & InputConfig & AudioWorkletConfig): Promise<Input> {\n    let context: AudioContext | null = null;\n    let inputStream: MediaStream | null = null;\n\n    try {\n      const options: MediaTrackConstraints = {\n        sampleRate: { ideal: sampleRate },\n        ...defaultConstraints,\n      };\n\n      if (isIosDevice() && preferHeadphonesForIosDevices) {\n        const availableDevices =\n          await window.navigator.mediaDevices.enumerateDevices();\n        const idealDevice = availableDevices.find(\n          d =>\n            // cautious to include \"bluetooth\" in the search\n            // as might trigger bluetooth speakers\n            d.kind === \"audioinput\" &&\n            [\"airpod\", \"headphone\", \"earphone\"].find(keyword =>\n              d.label.toLowerCase().includes(keyword)\n            )\n        );\n        if (idealDevice) {\n          options.deviceId = { ideal: idealDevice.deviceId };\n        }\n      }\n\n      if (inputDeviceId) {\n        options.deviceId = Input.getDeviceIdConstraint(inputDeviceId);\n      }\n\n      const supportsSampleRateConstraint =\n        navigator.mediaDevices.getSupportedConstraints().sampleRate;\n\n      context = new window.AudioContext(\n        supportsSampleRateConstraint ? { sampleRate } : {}\n      );\n      const analyser = context.createAnalyser();\n      if (!supportsSampleRateConstraint) {\n        // Use custom libsamplerate path if provided, otherwise fallback to CDN\n        const libsamplerateUrl = libsampleratePath || LIBSAMPLERATE_JS;\n        await context.audioWorklet.addModule(libsamplerateUrl);\n      }\n      await loadRawAudioProcessor(\n        context.audioWorklet,\n        workletPaths?.[\"rawAudioProcessor\"]\n      );\n\n      const constraints = { voiceIsolation: true, ...options };\n      inputStream = await navigator.mediaDevices.getUserMedia({\n        audio: constraints,\n      });\n\n      const source = context.createMediaStreamSource(inputStream);\n      const worklet = new AudioWorkletNode(context, \"rawAudioProcessor\");\n      worklet.port.postMessage({ type: \"setFormat\", format, sampleRate });\n\n      source.connect(analyser);\n      analyser.connect(worklet);\n\n      await context.resume();\n\n      const permissions = await navigator.permissions.query({\n        name: \"microphone\",\n      });\n      return new Input(\n        context,\n        analyser,\n        worklet,\n        inputStream,\n        source,\n        permissions,\n        onError\n      );\n    } catch (error) {\n      inputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      context?.close();\n      throw error;\n    }\n  }\n\n  // Use { ideal } on iOS as a defensive measure - some iOS versions may not support { exact } for deviceId constraints\n  private static getDeviceIdConstraint(\n    inputDeviceId?: string\n  ): MediaTrackConstraints[\"deviceId\"] {\n    if (!inputDeviceId) {\n      return undefined;\n    }\n    return isIosDevice() ? { ideal: inputDeviceId } : { exact: inputDeviceId };\n  }\n\n  private constructor(\n    public readonly context: AudioContext,\n    public readonly analyser: AnalyserNode,\n    public readonly worklet: AudioWorkletNode,\n    public inputStream: MediaStream,\n    private mediaStreamSource: MediaStreamAudioSourceNode,\n    private permissions: PermissionStatus,\n    private onError: (\n      message: string,\n      context?: unknown\n    ) => void = console.error\n  ) {\n    this.permissions.addEventListener(\"change\", this.handlePermissionsChange);\n  }\n\n  private forgetInputStreamAndSource() {\n    for (const track of this.inputStream.getTracks()) {\n      track.stop();\n    }\n    this.mediaStreamSource.disconnect();\n  }\n\n  public async close() {\n    this.forgetInputStreamAndSource();\n    this.permissions.removeEventListener(\n      \"change\",\n      this.handlePermissionsChange\n    );\n    await this.context.close();\n  }\n\n  public setMuted(isMuted: boolean) {\n    this.worklet.port.postMessage({ type: \"setMuted\", isMuted });\n  }\n\n  private settingInput: boolean = false;\n  public async setInputDevice(inputDeviceId?: string): Promise<void> {\n    try {\n      if (this.settingInput) {\n        throw new Error(\"Input device is already being set\");\n      }\n      this.settingInput = true;\n      // Create new constraints with the specified device or use default\n      const options: MediaTrackConstraints = {\n        ...defaultConstraints,\n      };\n\n      if (inputDeviceId) {\n        options.deviceId = Input.getDeviceIdConstraint(inputDeviceId);\n      }\n      // If inputDeviceId is undefined, don't set deviceId constraint - browser uses default\n\n      const constraints = { voiceIsolation: true, ...options };\n\n      // Get new media stream with the specified device before forgetting the old one\n      // this prevents unintended interruption of the audio stream in case the new stream isn't obtained\n      const newInputStream = await navigator.mediaDevices.getUserMedia({\n        audio: constraints,\n      });\n\n      this.forgetInputStreamAndSource();\n\n      // Replace the stream and create new source\n      this.inputStream = newInputStream;\n      this.mediaStreamSource =\n        this.context.createMediaStreamSource(newInputStream);\n\n      // Reconnect the audio graph\n      this.mediaStreamSource.connect(this.analyser);\n    } catch (error) {\n      this.onError(\"Failed to switch input device:\", error);\n      throw error;\n    } finally {\n      this.settingInput = false;\n    }\n  }\n\n  private handlePermissionsChange = () => {\n    if (this.permissions.state === \"denied\") {\n      this.onError(\"Microphone permission denied\");\n      // TODO: Tell the user to grant permission in some other way\n    } else if (!this.settingInput) {\n      // Let's try to reset the input device, but only if we're not already in the process of setting it\n      const [track] = this.inputStream.getAudioTracks();\n      const { deviceId } = track?.getSettings() ?? {};\n      this.setInputDevice(deviceId).catch(error => {\n        this.onError(\n          \"Failed to reset input device after permission change:\",\n          error\n        );\n      });\n    }\n  };\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadAudioConcatProcessor = createWorkletModuleLoader(\n  \"audioConcatProcessor\",\n  // language=JavaScript\n  `/*\n * ulaw decoding logic taken from the wavefile library\n * https://github.com/rochars/wavefile/blob/master/lib/codecs/mulaw.js\n * USED BY @elevenlabs/client\n */\n\nconst decodeTable = [0,132,396,924,1980,4092,8316,16764];\n\nfunction decodeSample(muLawSample) {\n  let sign;\n  let exponent;\n  let mantissa;\n  let sample;\n  muLawSample = ~muLawSample;\n  sign = (muLawSample & 0x80);\n  exponent = (muLawSample >> 4) & 0x07;\n  mantissa = muLawSample & 0x0F;\n  sample = decodeTable[exponent] + (mantissa << (exponent+3));\n  if (sign !== 0) sample = -sample;\n\n  return sample;\n}\n\nclass AudioConcatProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.buffers = []; // Initialize an empty buffer\n    this.cursor = 0;\n    this.currentBuffer = null;\n    this.wasInterrupted = false;\n    this.finished = false;\n    \n    this.port.onmessage = ({ data }) => {\n      switch (data.type) {\n        case \"setFormat\":\n          this.format = data.format;\n          break;\n        case \"buffer\":\n          this.wasInterrupted = false;\n          this.buffers.push(\n            this.format === \"ulaw\"\n              ? new Uint8Array(data.buffer)\n              : new Int16Array(data.buffer)\n          );\n          break;\n        case \"interrupt\":\n          this.wasInterrupted = true;\n          break;\n        case \"clearInterrupted\":\n          if (this.wasInterrupted) {\n            this.wasInterrupted = false;\n            this.buffers = [];\n            this.currentBuffer = null;\n          }\n      }\n    };\n  }\n  process(_, outputs) {\n    let finished = false;\n    const output = outputs[0][0];\n    for (let i = 0; i < output.length; i++) {\n      if (!this.currentBuffer) {\n        if (this.buffers.length === 0) {\n          finished = true;\n          break;\n        }\n        this.currentBuffer = this.buffers.shift();\n        this.cursor = 0;\n      }\n\n      let value = this.currentBuffer[this.cursor];\n      if (this.format === \"ulaw\") {\n        value = decodeSample(value);\n      }\n      output[i] = value / 32768;\n      this.cursor++;\n\n      if (this.cursor >= this.currentBuffer.length) {\n        this.currentBuffer = null;\n      }\n    }\n\n    if (this.finished !== finished) {\n      this.finished = finished;\n      this.port.postMessage({ type: \"process\", finished });\n    }\n\n    return true; // Continue processing\n  }\n}\n\nregisterProcessor(\"audioConcatProcessor\", AudioConcatProcessor);\n`\n);\n","import { loadAudioConcatProcessor } from \"./audioConcatProcessor.generated\";\nimport type { FormatConfig } from \"./connection\";\nimport type { AudioWorkletConfig } from \"../BaseConversation\";\n\nexport type OutputConfig = {\n  outputDeviceId?: string;\n};\n\nexport class Output {\n  public static async create({\n    sampleRate,\n    format,\n    outputDeviceId,\n    workletPaths,\n  }: FormatConfig & OutputConfig & AudioWorkletConfig): Promise<Output> {\n    let context: AudioContext | null = null;\n    let audioElement: HTMLAudioElement | null = null;\n    try {\n      context = new AudioContext({ sampleRate });\n      const analyser = context.createAnalyser();\n      const gain = context.createGain();\n\n      // Always create an audio element for device switching capability\n      audioElement = new Audio();\n      audioElement.src = \"\";\n      audioElement.load();\n      audioElement.autoplay = true;\n      audioElement.style.display = \"none\";\n\n      document.body.appendChild(audioElement);\n\n      // Create media stream destination to route audio to the element\n      const destination = context.createMediaStreamDestination();\n      audioElement.srcObject = destination.stream;\n\n      gain.connect(analyser);\n      analyser.connect(destination);\n\n      await loadAudioConcatProcessor(\n        context.audioWorklet,\n        workletPaths?.[\"audioConcatProcessor\"]\n      );\n      const worklet = new AudioWorkletNode(context, \"audioConcatProcessor\");\n      worklet.port.postMessage({ type: \"setFormat\", format });\n      worklet.connect(gain);\n\n      await context.resume();\n\n      // Set initial output device if provided\n      if (outputDeviceId && audioElement.setSinkId) {\n        await audioElement.setSinkId(outputDeviceId);\n      }\n\n      const newOutput = new Output(\n        context,\n        analyser,\n        gain,\n        worklet,\n        audioElement\n      );\n\n      return newOutput;\n    } catch (error) {\n      // Clean up audio element from DOM\n      if (audioElement?.parentNode) {\n        audioElement.parentNode.removeChild(audioElement);\n      }\n      audioElement?.pause();\n      if (context && context.state !== \"closed\") {\n        await context.close();\n      }\n\n      throw error;\n    }\n  }\n\n  private constructor(\n    public readonly context: AudioContext,\n    public readonly analyser: AnalyserNode,\n    public readonly gain: GainNode,\n    public readonly worklet: AudioWorkletNode,\n    public readonly audioElement: HTMLAudioElement\n  ) {}\n\n  public async setOutputDevice(deviceId?: string): Promise<void> {\n    if (!(\"setSinkId\" in HTMLAudioElement.prototype)) {\n      throw new Error(\"setSinkId is not supported in this browser\");\n    }\n\n    // If deviceId is undefined, use empty string which resets to default device\n    await this.audioElement.setSinkId(deviceId || \"\");\n  }\n\n  public async close() {\n    // Remove audio element from DOM\n    if (this.audioElement.parentNode) {\n      this.audioElement.parentNode.removeChild(this.audioElement);\n    }\n    this.audioElement.pause();\n    await this.context.close();\n  }\n}\n","import { arrayBufferToBase64, base64ToArrayBuffer } from \"./utils/audio\";\nimport { Input, type InputConfig } from \"./utils/input\";\nimport { Output } from \"./utils/output\";\nimport { createConnection } from \"./utils/ConnectionFactory\";\nimport type { BaseConnection, FormatConfig } from \"./utils/BaseConnection\";\nimport { WebRTCConnection } from \"./utils/WebRTCConnection\";\nimport type { AgentAudioEvent, InterruptionEvent } from \"./utils/events\";\nimport { applyDelay } from \"./utils/applyDelay\";\nimport {\n  BaseConversation,\n  type Options,\n  type PartialOptions,\n} from \"./BaseConversation\";\nimport { WebSocketConnection } from \"./utils/WebSocketConnection\";\n\nexport class VoiceConversation extends BaseConversation {\n  private static async requestWakeLock(): Promise<WakeLockSentinel | null> {\n    if (\"wakeLock\" in navigator) {\n      // unavailable without HTTPS, including localhost in dev\n      try {\n        return await navigator.wakeLock.request(\"screen\");\n      } catch (_e) {\n        // Wake Lock is not required for the conversation to work\n      }\n    }\n    return null;\n  }\n\n  public static async startSession(\n    options: PartialOptions\n  ): Promise<VoiceConversation> {\n    const fullOptions = BaseConversation.getFullOptions(options);\n\n    if (fullOptions.onStatusChange) {\n      fullOptions.onStatusChange({ status: \"connecting\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n\n    let input: Input | null = null;\n    let connection: BaseConnection | null = null;\n    let output: Output | null = null;\n    let preliminaryInputStream: MediaStream | null = null;\n\n    const useWakeLock = options.useWakeLock ?? true;\n    let wakeLock: WakeLockSentinel | null = null;\n    if (useWakeLock) {\n      wakeLock = await VoiceConversation.requestWakeLock();\n    }\n\n    try {\n      // some browsers won't allow calling getSupportedConstraints or enumerateDevices\n      // before getting approval for microphone access\n      preliminaryInputStream = await navigator.mediaDevices.getUserMedia({\n        audio: true,\n      });\n\n      await applyDelay(fullOptions.connectionDelay);\n      connection = await createConnection(options);\n      [input, output] = await Promise.all([\n        Input.create({\n          ...connection.inputFormat,\n          preferHeadphonesForIosDevices: options.preferHeadphonesForIosDevices,\n          inputDeviceId: options.inputDeviceId,\n          workletPaths: options.workletPaths,\n          libsampleratePath: options.libsampleratePath,\n        }),\n        Output.create({\n          ...connection.outputFormat,\n          outputDeviceId: options.outputDeviceId,\n          workletPaths: options.workletPaths,\n        }),\n      ]);\n\n      preliminaryInputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      preliminaryInputStream = null;\n\n      return new VoiceConversation(\n        fullOptions,\n        connection,\n        input,\n        output,\n        wakeLock\n      );\n    } catch (error) {\n      if (fullOptions.onStatusChange) {\n        fullOptions.onStatusChange({ status: \"disconnected\" });\n      }\n      preliminaryInputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      connection?.close();\n      await input?.close();\n      await output?.close();\n      try {\n        await wakeLock?.release();\n        wakeLock = null;\n      } catch (_e) {}\n      throw error;\n    }\n  }\n\n  private inputFrequencyData?: Uint8Array<ArrayBuffer>;\n  private outputFrequencyData?: Uint8Array<ArrayBuffer>;\n  private visibilityChangeHandler: (() => void) | null = null;\n\n  protected constructor(\n    options: Options,\n    connection: BaseConnection,\n    public input: Input,\n    public output: Output,\n    public wakeLock: WakeLockSentinel | null\n  ) {\n    super(options, connection);\n    this.input.worklet.port.onmessage = this.onInputWorkletMessage;\n    this.output.worklet.port.onmessage = this.onOutputWorkletMessage;\n\n    if (wakeLock) {\n      // Wake locks are automatically released when a page is hidden like when switching tabs\n      // so attempt to re-acquire lock when page becomes visible again\n      this.visibilityChangeHandler = () => {\n        if (document.visibilityState === \"visible\" && this.wakeLock?.released) {\n          VoiceConversation.requestWakeLock().then(lock => {\n            this.wakeLock = lock;\n          });\n        }\n      };\n      document.addEventListener(\n        \"visibilitychange\",\n        this.visibilityChangeHandler\n      );\n    }\n  }\n\n  protected override async handleEndSession() {\n    await super.handleEndSession();\n\n    if (this.visibilityChangeHandler) {\n      document.removeEventListener(\n        \"visibilitychange\",\n        this.visibilityChangeHandler\n      );\n    }\n\n    try {\n      await this.wakeLock?.release();\n      this.wakeLock = null;\n    } catch (_e) {}\n\n    await this.input.close();\n    await this.output.close();\n  }\n\n  protected override handleInterruption(event: InterruptionEvent) {\n    super.handleInterruption(event);\n    this.fadeOutAudio();\n  }\n\n  protected override handleAudio(event: AgentAudioEvent) {\n    super.handleAudio(event);\n\n    if (event.audio_event.alignment && this.options.onAudioAlignment) {\n      this.options.onAudioAlignment(event.audio_event.alignment);\n    }\n\n    if (this.lastInterruptTimestamp <= event.audio_event.event_id) {\n      if (event.audio_event.audio_base_64) {\n        this.options.onAudio?.(event.audio_event.audio_base_64);\n\n        // Only play audio through the output worklet for WebSocket connections\n        // WebRTC connections handle audio playback directly through LiveKit tracks\n        if (!(this.connection instanceof WebRTCConnection)) {\n          this.addAudioBase64Chunk(event.audio_event.audio_base_64);\n        }\n      }\n\n      this.currentEventId = event.audio_event.event_id;\n      this.updateCanSendFeedback();\n      this.updateMode(\"speaking\");\n    }\n  }\n\n  private onInputWorkletMessage = (event: MessageEvent): void => {\n    const rawAudioPcmData = event.data[0];\n\n    // TODO: When supported, maxVolume can be used to avoid sending silent audio\n    // const maxVolume = event.data[1];\n\n    if (this.status === \"connected\") {\n      this.connection.sendMessage({\n        user_audio_chunk: arrayBufferToBase64(rawAudioPcmData.buffer),\n      });\n    }\n  };\n\n  private onOutputWorkletMessage = ({ data }: MessageEvent): void => {\n    if (data.type === \"process\") {\n      this.updateMode(data.finished ? \"listening\" : \"speaking\");\n    }\n  };\n\n  private addAudioBase64Chunk = (chunk: string) => {\n    this.output.gain.gain.cancelScheduledValues(\n      this.output.context.currentTime\n    );\n    this.output.gain.gain.value = this.volume;\n    this.output.worklet.port.postMessage({ type: \"clearInterrupted\" });\n    this.output.worklet.port.postMessage({\n      type: \"buffer\",\n      buffer: base64ToArrayBuffer(chunk),\n    });\n  };\n\n  private fadeOutAudio = () => {\n    // mute agent\n    this.updateMode(\"listening\");\n    this.output.worklet.port.postMessage({ type: \"interrupt\" });\n    this.output.gain.gain.exponentialRampToValueAtTime(\n      0.0001,\n      this.output.context.currentTime + 2\n    );\n\n    // reset volume back\n    setTimeout(() => {\n      this.output.gain.gain.value = this.volume;\n      this.output.worklet.port.postMessage({ type: \"clearInterrupted\" });\n    }, 2000); // Adjust the duration as needed\n  };\n\n  private calculateVolume = (frequencyData: Uint8Array) => {\n    if (frequencyData.length === 0) {\n      return 0;\n    }\n\n    // TODO: Currently this averages all frequencies, but we should probably\n    // bias towards the frequencies that are more typical for human voice\n    let volume = 0;\n    for (let i = 0; i < frequencyData.length; i++) {\n      volume += frequencyData[i] / 255;\n    }\n    volume /= frequencyData.length;\n\n    return volume < 0 ? 0 : volume > 1 ? 1 : volume;\n  };\n\n  public setMicMuted(isMuted: boolean) {\n    // Use LiveKit track muting for WebRTC connections\n    if (this.connection instanceof WebRTCConnection) {\n      this.connection.setMicMuted(isMuted);\n    } else {\n      // Use input muting for WebSocket connections\n      this.input.setMuted(isMuted);\n    }\n  }\n\n  public getInputByteFrequencyData(): Uint8Array<ArrayBuffer> {\n    this.inputFrequencyData ??= new Uint8Array(\n      this.input.analyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.input.analyser.getByteFrequencyData(this.inputFrequencyData);\n    return this.inputFrequencyData;\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array<ArrayBuffer> {\n    // Use WebRTC analyser if available\n    if (this.connection instanceof WebRTCConnection) {\n      const webrtcData = this.connection.getOutputByteFrequencyData();\n      if (webrtcData) {\n        return webrtcData as Uint8Array<ArrayBuffer>;\n      }\n      // Fallback to empty array if WebRTC analyser not ready\n      return new Uint8Array(1024) as Uint8Array<ArrayBuffer>;\n    }\n\n    this.outputFrequencyData ??= new Uint8Array(\n      this.output.analyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.output.analyser.getByteFrequencyData(this.outputFrequencyData);\n    return this.outputFrequencyData;\n  }\n\n  public getInputVolume() {\n    return this.calculateVolume(this.getInputByteFrequencyData());\n  }\n\n  public getOutputVolume() {\n    return this.calculateVolume(this.getOutputByteFrequencyData());\n  }\n\n  public async changeInputDevice({\n    sampleRate,\n    format,\n    preferHeadphonesForIosDevices,\n    inputDeviceId,\n  }: FormatConfig & InputConfig): Promise<Input> {\n    try {\n      // For WebSocket connections, try to change device on existing input first\n      if (this.connection instanceof WebSocketConnection) {\n        try {\n          await this.input.setInputDevice(inputDeviceId);\n          return this.input;\n        } catch (error) {\n          console.warn(\n            \"Failed to change device on existing input, recreating:\",\n            error\n          );\n          // Fall back to recreating the input\n        }\n      }\n\n      // Handle WebRTC connections differently\n      if (this.connection instanceof WebRTCConnection) {\n        await this.connection.setAudioInputDevice(inputDeviceId || \"\");\n      }\n\n      // Fallback: recreate the input\n      await this.input.close();\n\n      const newInput = await Input.create({\n        sampleRate: sampleRate ?? this.connection.inputFormat.sampleRate,\n        format: format ?? this.connection.inputFormat.format,\n        preferHeadphonesForIosDevices,\n        inputDeviceId,\n        workletPaths: this.options.workletPaths,\n        libsampleratePath: this.options.libsampleratePath,\n        onError: this.options.onError,\n      });\n\n      this.input = newInput;\n      this.input.worklet.port.onmessage = this.onInputWorkletMessage;\n\n      return this.input;\n    } catch (error) {\n      console.error(\"Error changing input device\", error);\n      throw error;\n    }\n  }\n\n  public async changeOutputDevice({\n    sampleRate,\n    format,\n    outputDeviceId,\n  }: FormatConfig): Promise<Output> {\n    try {\n      // For WebSocket connections, try to change device on existing output first\n      if (this.connection instanceof WebSocketConnection) {\n        try {\n          await this.output.setOutputDevice(outputDeviceId);\n          return this.output;\n        } catch (error) {\n          console.warn(\n            \"Failed to change device on existing output, recreating:\",\n            error\n          );\n          // Fall back to recreating the output\n        }\n      }\n\n      // Handle WebRTC connections differently\n      if (this.connection instanceof WebRTCConnection) {\n        await this.connection.setAudioOutputDevice(outputDeviceId || \"\");\n      }\n\n      // Fallback: recreate the output\n      await this.output.close();\n\n      const newOutput = await Output.create({\n        sampleRate: sampleRate ?? this.connection.outputFormat.sampleRate,\n        format: format ?? this.connection.outputFormat.format,\n        outputDeviceId,\n        workletPaths: this.options.workletPaths,\n      });\n\n      this.output = newOutput;\n\n      return this.output;\n    } catch (error) {\n      console.error(\"Error changing output device\", error);\n      throw error;\n    }\n  }\n\n  public setVolume = ({ volume }: { volume: number }) => {\n    // clamp & coerce\n    const clampedVolume = Number.isFinite(volume)\n      ? Math.min(1, Math.max(0, volume))\n      : 1;\n    this.volume = clampedVolume;\n\n    if (this.connection instanceof WebRTCConnection) {\n      // For WebRTC connections, control volume via HTML audio elements\n      this.connection.setAudioVolume(clampedVolume);\n    } else {\n      // For WebSocket connections, control volume via gain node\n      this.output.gain.gain.value = clampedVolume;\n    }\n  };\n}\n","const HTTPS_API_ORIGIN = \"https://api.elevenlabs.io\";\n\nexport interface RatingFeedback {\n  rating: number;\n  comment?: string;\n}\n\ntype Feedback = RatingFeedback;\n\nexport function postOverallFeedback(\n  conversationId: string,\n  like: boolean,\n  origin?: string\n): Promise<Response>;\nexport function postOverallFeedback(\n  conversationId: string,\n  feedback: Feedback,\n  origin?: string\n): Promise<Response>;\nexport function postOverallFeedback(\n  conversationId: string,\n  likeOrFeedback: boolean | Feedback,\n  origin: string = HTTPS_API_ORIGIN\n): Promise<Response> {\n  const body: {\n    feedback?: \"like\" | \"dislike\";\n    rating?: number;\n    comment?: string;\n  } = {};\n\n  if (typeof likeOrFeedback === \"boolean\") {\n    body.feedback = likeOrFeedback ? \"like\" : \"dislike\";\n  } else {\n    body.rating = likeOrFeedback.rating;\n    body.comment = likeOrFeedback.comment;\n  }\n\n  return fetch(`${origin}/v1/convai/conversations/${conversationId}/feedback`, {\n    method: \"POST\",\n    body: JSON.stringify(body),\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n  });\n}\n","import type {\n  InputAudioChunk,\n  SessionStartedMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n  ScribeCommitThrottledErrorMessage,\n  ScribeTranscriberErrorMessage,\n  ScribeUnacceptedTermsErrorMessage,\n  ScribeRateLimitedErrorMessage,\n  ScribeInputErrorMessage,\n  ScribeQueueOverflowErrorMessage,\n  ScribeResourceExhaustedErrorMessage,\n  ScribeSessionTimeLimitExceededErrorMessage,\n  ScribeChunkSizeExceededErrorMessage,\n  ScribeInsufficientAudioActivityErrorMessage,\n} from \"@elevenlabs/types\";\n\n// Re-export types for public API\nexport type {\n  SessionStartedMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n  ScribeCommitThrottledErrorMessage,\n  ScribeTranscriberErrorMessage,\n  ScribeUnacceptedTermsErrorMessage,\n  ScribeRateLimitedErrorMessage,\n  ScribeInputErrorMessage,\n  ScribeQueueOverflowErrorMessage,\n  ScribeResourceExhaustedErrorMessage,\n  ScribeSessionTimeLimitExceededErrorMessage,\n  ScribeChunkSizeExceededErrorMessage,\n  ScribeInsufficientAudioActivityErrorMessage,\n};\n\nexport type WebSocketMessage =\n  | SessionStartedMessage\n  | PartialTranscriptMessage\n  | CommittedTranscriptMessage\n  | CommittedTranscriptWithTimestampsMessage\n  | ScribeErrorMessage\n  | ScribeAuthErrorMessage\n  | ScribeQuotaExceededErrorMessage\n  | ScribeCommitThrottledErrorMessage\n  | ScribeTranscriberErrorMessage\n  | ScribeUnacceptedTermsErrorMessage\n  | ScribeRateLimitedErrorMessage\n  | ScribeInputErrorMessage\n  | ScribeQueueOverflowErrorMessage\n  | ScribeResourceExhaustedErrorMessage\n  | ScribeSessionTimeLimitExceededErrorMessage\n  | ScribeChunkSizeExceededErrorMessage\n  | ScribeInsufficientAudioActivityErrorMessage;\n\n/**\n * Simple EventEmitter implementation for browser compatibility.\n */\nclass EventEmitter {\n  private listeners: Map<string, Set<(...args: unknown[]) => void>> = new Map();\n\n  on(event: string, listener: (...args: unknown[]) => void): void {\n    if (!this.listeners.has(event)) {\n      this.listeners.set(event, new Set());\n    }\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.add(listener);\n    }\n  }\n\n  off(event: string, listener: (...args: unknown[]) => void): void {\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.delete(listener);\n    }\n  }\n\n  emit(event: string, ...args: unknown[]): void {\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.forEach(listener => {\n        listener(...args);\n      });\n    }\n  }\n}\n\n/**\n * Events emitted by the RealtimeConnection.\n */\nexport enum RealtimeEvents {\n  /** Emitted when the session is successfully started */\n  SESSION_STARTED = \"session_started\",\n  /** Emitted when a partial (interim) transcript is available */\n  PARTIAL_TRANSCRIPT = \"partial_transcript\",\n  /** Emitted when a final transcript is available */\n  COMMITTED_TRANSCRIPT = \"committed_transcript\",\n  /** Emitted when a final transcript with timestamps is available */\n  COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS = \"committed_transcript_with_timestamps\",\n  /** Emitted when an authentication error occurs */\n  AUTH_ERROR = \"auth_error\",\n  /** Emitted when an error occurs (also emitted for all specific error types) */\n  ERROR = \"error\",\n  /** Emitted when the WebSocket connection is opened */\n  OPEN = \"open\",\n  /** Emitted when the WebSocket connection is closed */\n  CLOSE = \"close\",\n  /** Emitted when a quota exceeded error occurs */\n  QUOTA_EXCEEDED = \"quota_exceeded\",\n  /** Emitted when commit is throttled */\n  COMMIT_THROTTLED = \"commit_throttled\",\n  /** Emitted when a transcriber error occurs */\n  TRANSCRIBER_ERROR = \"transcriber_error\",\n  /** Emitted when terms have not been accepted */\n  UNACCEPTED_TERMS = \"unaccepted_terms\",\n  /** Emitted when rate limited */\n  RATE_LIMITED = \"rate_limited\",\n  /** Emitted when there's an input error */\n  INPUT_ERROR = \"input_error\",\n  /** Emitted when the queue overflows */\n  QUEUE_OVERFLOW = \"queue_overflow\",\n  /** Emitted when resources are exhausted */\n  RESOURCE_EXHAUSTED = \"resource_exhausted\",\n  /** Emitted when session time limit is exceeded */\n  SESSION_TIME_LIMIT_EXCEEDED = \"session_time_limit_exceeded\",\n  /** Emitted when chunk size is exceeded */\n  CHUNK_SIZE_EXCEEDED = \"chunk_size_exceeded\",\n  /** Emitted when there's insufficient audio activity */\n  INSUFFICIENT_AUDIO_ACTIVITY = \"insufficient_audio_activity\",\n}\n\n/**\n * Map of event types to their payload types.\n */\nexport interface RealtimeEventMap {\n  [RealtimeEvents.SESSION_STARTED]: SessionStartedMessage;\n  [RealtimeEvents.PARTIAL_TRANSCRIPT]: PartialTranscriptMessage;\n  [RealtimeEvents.COMMITTED_TRANSCRIPT]: CommittedTranscriptMessage;\n  [RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS]: CommittedTranscriptWithTimestampsMessage;\n  [RealtimeEvents.ERROR]: ScribeErrorMessage;\n  [RealtimeEvents.AUTH_ERROR]: ScribeAuthErrorMessage;\n  [RealtimeEvents.QUOTA_EXCEEDED]: ScribeQuotaExceededErrorMessage;\n  [RealtimeEvents.COMMIT_THROTTLED]: ScribeCommitThrottledErrorMessage;\n  [RealtimeEvents.TRANSCRIBER_ERROR]: ScribeTranscriberErrorMessage;\n  [RealtimeEvents.UNACCEPTED_TERMS]: ScribeUnacceptedTermsErrorMessage;\n  [RealtimeEvents.RATE_LIMITED]: ScribeRateLimitedErrorMessage;\n  [RealtimeEvents.INPUT_ERROR]: ScribeInputErrorMessage;\n  [RealtimeEvents.QUEUE_OVERFLOW]: ScribeQueueOverflowErrorMessage;\n  [RealtimeEvents.RESOURCE_EXHAUSTED]: ScribeResourceExhaustedErrorMessage;\n  [RealtimeEvents.SESSION_TIME_LIMIT_EXCEEDED]: ScribeSessionTimeLimitExceededErrorMessage;\n  [RealtimeEvents.CHUNK_SIZE_EXCEEDED]: ScribeChunkSizeExceededErrorMessage;\n  [RealtimeEvents.INSUFFICIENT_AUDIO_ACTIVITY]: ScribeInsufficientAudioActivityErrorMessage;\n  [RealtimeEvents.OPEN]: undefined;\n  [RealtimeEvents.CLOSE]: CloseEvent;\n}\n\n/**\n * Manages a real-time transcription WebSocket connection.\n *\n * @example\n * ```typescript\n * const connection = await Scribe.connect({\n *     token: \"...\",\n *     modelId: \"scribe_v2_realtime\",\n *     audioFormat: AudioFormat.PCM_16000,\n *     sampleRate: 16000,\n * });\n *\n * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {\n *     console.log(\"Session started\");\n * });\n *\n * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {\n *     console.log(\"Partial:\", data.transcript);\n * });\n *\n * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n *     console.log(\"Final:\", data.transcript);\n *     connection.close();\n * });\n *\n * // Send audio data\n * connection.send({ audioBase64: base64String });\n *\n * // Commit and close\n * connection.commit();\n * ```\n */\nexport class RealtimeConnection {\n  private websocket: WebSocket | null = null;\n  private eventEmitter: EventEmitter = new EventEmitter();\n  private currentSampleRate: number = 16000;\n  public _audioCleanup?: () => void;\n\n  constructor(sampleRate: number) {\n    this.currentSampleRate = sampleRate;\n  }\n\n  /**\n   * @internal\n   * Used internally by ScribeRealtime to attach the WebSocket after connection is created.\n   */\n  public setWebSocket(websocket: WebSocket): void {\n    this.websocket = websocket;\n\n    // If WebSocket is already open, emit OPEN event immediately\n    if (this.websocket.readyState === WebSocket.OPEN) {\n      this.eventEmitter.emit(RealtimeEvents.OPEN);\n    } else {\n      // Otherwise, wait for the open event\n      this.websocket.addEventListener(\"open\", () => {\n        this.eventEmitter.emit(RealtimeEvents.OPEN);\n      });\n    }\n\n    this.websocket.addEventListener(\"message\", (event: MessageEvent) => {\n      try {\n        const data = JSON.parse(event.data) as WebSocketMessage;\n\n        switch (data.message_type) {\n          case \"session_started\":\n            this.eventEmitter.emit(RealtimeEvents.SESSION_STARTED, data);\n            break;\n          case \"partial_transcript\":\n            this.eventEmitter.emit(RealtimeEvents.PARTIAL_TRANSCRIPT, data);\n            break;\n          case \"committed_transcript\":\n            this.eventEmitter.emit(RealtimeEvents.COMMITTED_TRANSCRIPT, data);\n            break;\n          case \"committed_transcript_with_timestamps\":\n            this.eventEmitter.emit(\n              RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS,\n              data\n            );\n            break;\n          // Error cases - emit both specific event and generic ERROR\n          case \"auth_error\":\n            this.eventEmitter.emit(RealtimeEvents.AUTH_ERROR, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"quota_exceeded\":\n            this.eventEmitter.emit(RealtimeEvents.QUOTA_EXCEEDED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"commit_throttled\":\n            this.eventEmitter.emit(RealtimeEvents.COMMIT_THROTTLED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"transcriber_error\":\n            this.eventEmitter.emit(RealtimeEvents.TRANSCRIBER_ERROR, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"unaccepted_terms\":\n            this.eventEmitter.emit(RealtimeEvents.UNACCEPTED_TERMS, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"rate_limited\":\n            this.eventEmitter.emit(RealtimeEvents.RATE_LIMITED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"input_error\":\n            this.eventEmitter.emit(RealtimeEvents.INPUT_ERROR, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"queue_overflow\":\n            this.eventEmitter.emit(RealtimeEvents.QUEUE_OVERFLOW, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"resource_exhausted\":\n            this.eventEmitter.emit(RealtimeEvents.RESOURCE_EXHAUSTED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"session_time_limit_exceeded\":\n            this.eventEmitter.emit(\n              RealtimeEvents.SESSION_TIME_LIMIT_EXCEEDED,\n              data\n            );\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"chunk_size_exceeded\":\n            this.eventEmitter.emit(RealtimeEvents.CHUNK_SIZE_EXCEEDED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"insufficient_audio_activity\":\n            this.eventEmitter.emit(\n              RealtimeEvents.INSUFFICIENT_AUDIO_ACTIVITY,\n              data\n            );\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"error\":\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          default:\n            console.warn(\"Unknown message type:\", data);\n        }\n      } catch (error) {\n        console.error(\"Failed to parse WebSocket message:\", error, event.data);\n        this.eventEmitter.emit(\n          RealtimeEvents.ERROR,\n          new Error(`Failed to parse message: ${error}`)\n        );\n      }\n    });\n\n    this.websocket.addEventListener(\"error\", (error: Event) => {\n      console.error(\"WebSocket error:\", error);\n      this.eventEmitter.emit(RealtimeEvents.ERROR, error);\n    });\n\n    this.websocket.addEventListener(\"close\", (event: CloseEvent) => {\n      console.log(\n        `WebSocket closed: code=${event.code}, reason=\"${event.reason}\", wasClean=${event.wasClean}`\n      );\n\n      // Emit error if close was not clean or had an error code\n      if (!event.wasClean || (event.code !== 1000 && event.code !== 1005)) {\n        const errorMessage = `WebSocket closed unexpectedly: ${event.code} - ${event.reason || \"No reason provided\"}`;\n        console.error(errorMessage);\n        this.eventEmitter.emit(RealtimeEvents.ERROR, new Error(errorMessage));\n      }\n\n      this.eventEmitter.emit(RealtimeEvents.CLOSE, event);\n    });\n  }\n\n  /**\n   * Attaches an event listener for the specified event.\n   *\n   * @param event - The event to listen for (use RealtimeEvents enum)\n   * @param listener - The callback function to execute when the event fires\n   *\n   * @example\n   * ```typescript\n   * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {\n   *     console.log(\"Session started\", data.session_id);\n   * });\n   *\n   * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {\n   *     console.log(\"Partial:\", data.text);\n   * });\n   *\n   * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n   *     console.log(\"Final:\", data.text);\n   * });\n   * ```\n   */\n  public on<E extends RealtimeEvents>(\n    event: E,\n    listener: RealtimeEventMap[E] extends undefined\n      ? () => void\n      : (data: RealtimeEventMap[E]) => void\n  ): void {\n    this.eventEmitter.on(event, listener as (...args: unknown[]) => void);\n  }\n\n  /**\n   * Removes an event listener for the specified event.\n   *\n   * @param event - The event to stop listening for\n   * @param listener - The callback function to remove\n   *\n   * @example\n   * ```typescript\n   * const handler = (data: PartialTranscriptMessage) => console.log(data.text);\n   * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);\n   *\n   * // Later, remove the listener\n   * connection.off(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);\n   * ```\n   */\n  public off<E extends RealtimeEvents>(\n    event: E,\n    listener: RealtimeEventMap[E] extends undefined\n      ? () => void\n      : (data: RealtimeEventMap[E]) => void\n  ): void {\n    this.eventEmitter.off(event, listener as (...args: unknown[]) => void);\n  }\n\n  /**\n   * Sends audio data to the transcription service.\n   *\n   * @param data - Audio data configuration\n   * @param data.audioBase64 - Base64-encoded audio data\n   * @param data.commit - Whether to commit the transcription after this chunk. You likely want to use connection.commit() instead (default: false)\n   * @param data.sampleRate - Sample rate of the audio (default: configured sample rate)\n   * @param data.previousText - Send context to the model via base64 encoded audio or text from a previous transcription. Can only be sent alongside the first audio chunk. If sent in a subsequent chunk, an error will be returned.\n   *\n   * @throws {Error} If the WebSocket connection is not open\n   *\n   * @example\n   * ```typescript\n   * // Send audio chunk without committing\n   * connection.send({\n   *     audioBase64: base64EncodedAudio,\n   * });\n   *\n   * // Send audio chunk with custom sample rate and previous text\n   * connection.send({\n   *     audioBase64: base64EncodedAudio,\n   *     sampleRate: 16000,\n   *     previousText: \"Previous transcription text\",\n   * });\n   * ```\n   */\n  public send(data: {\n    audioBase64: string;\n    commit?: boolean;\n    sampleRate?: number;\n    previousText?: string;\n  }): void {\n    if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {\n      throw new Error(\"WebSocket is not connected\");\n    }\n\n    const message: InputAudioChunk = {\n      message_type: \"input_audio_chunk\",\n      audio_base_64: data.audioBase64,\n      commit: data.commit ?? false,\n      sample_rate: data.sampleRate ?? this.currentSampleRate,\n      previous_text: data.previousText,\n    };\n\n    this.websocket.send(JSON.stringify(message));\n  }\n\n  /**\n   * Commits the transcription, signaling that a segment of audio has been sent. This clears the buffer and triggers a COMMITTED_TRANSCRIPT event. Context from previous segments is kept.\n   * Committing a segment triggers a COMMITTED_TRANSCRIPT event.\n   *\n   * @throws {Error} If the WebSocket connection is not open\n   *\n   * @remarks\n   * Only needed when using CommitStrategy.MANUAL.\n   * When using CommitStrategy.VAD, commits are handled automatically by the server.\n   *\n   * @example\n   * ```typescript\n   * // Send all audio chunks\n   * for (const chunk of audioChunks) {\n   *     connection.send({ audioBase64: chunk });\n   * }\n   *\n   * // Finalize the transcription\n   * connection.commit();\n   * ```\n   */\n  public commit(): void {\n    if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {\n      throw new Error(\"WebSocket is not connected\");\n    }\n\n    const message: InputAudioChunk = {\n      message_type: \"input_audio_chunk\",\n      audio_base_64: \"\",\n      commit: true,\n      sample_rate: this.currentSampleRate,\n    };\n\n    this.websocket.send(JSON.stringify(message));\n  }\n\n  /**\n   * Closes the WebSocket connection and cleans up resources.\n   * This will terminate any ongoing transcription and stop microphone streaming if active.\n   *\n   * @remarks\n   * After calling close(), this connection cannot be reused.\n   * Create a new connection if you need to start transcribing again.\n   *\n   * @example\n   * ```typescript\n   * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n   *     console.log(\"Segment committed:\", data.transcript);\n   *     connection.close();\n   * });\n   * ```\n   */\n  public close(): void {\n    // Cleanup audio resources (microphone stream, audio context)\n    if (this._audioCleanup) {\n      this._audioCleanup();\n    }\n\n    // Close WebSocket connection\n    if (this.websocket) {\n      this.websocket.close(1000, \"User ended session\");\n    }\n  }\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadScribeAudioProcessor = createWorkletModuleLoader(\n  \"scribeAudioProcessor\",\n  // language=JavaScript\n  `/*\n * Scribe Audio Processor for converting microphone audio to PCM16 format\n * Supports resampling for browsers like Firefox that don't support\n * AudioContext sample rate constraints.\n * USED BY @elevenlabs/client\n */\n\nclass ScribeAudioProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.buffer = [];\n    this.bufferSize = 4096; // Buffer size for optimal chunk transmission\n\n    // Resampling state\n    this.inputSampleRate = null;\n    this.outputSampleRate = null;\n    this.resampleRatio = 1;\n    this.lastSample = 0;\n    this.resampleAccumulator = 0;\n\n    this.port.onmessage = ({ data }) => {\n      if (data.type === \"configure\") {\n        this.inputSampleRate = data.inputSampleRate;\n        this.outputSampleRate = data.outputSampleRate;\n        if (this.inputSampleRate && this.outputSampleRate) {\n          this.resampleRatio = this.inputSampleRate / this.outputSampleRate;\n        }\n      }\n    };\n  }\n\n  // Linear interpolation resampling\n  resample(inputData) {\n    if (this.resampleRatio === 1 || !this.inputSampleRate) {\n      return inputData;\n    }\n\n    const outputSamples = [];\n\n    for (let i = 0; i < inputData.length; i++) {\n      const currentSample = inputData[i];\n\n      // Generate output samples using linear interpolation\n      while (this.resampleAccumulator < 1) {\n        const interpolated =\n          this.lastSample +\n          (currentSample - this.lastSample) * this.resampleAccumulator;\n        outputSamples.push(interpolated);\n        this.resampleAccumulator += this.resampleRatio;\n      }\n\n      this.resampleAccumulator -= 1;\n      this.lastSample = currentSample;\n    }\n\n    return new Float32Array(outputSamples);\n  }\n\n  process(inputs) {\n    const input = inputs[0];\n    if (input.length > 0) {\n      let channelData = input[0]; // Get first channel (mono)\n\n      // Resample if needed (for Firefox and other browsers that don't\n      // support AudioContext sample rate constraints)\n      if (this.resampleRatio !== 1) {\n        channelData = this.resample(channelData);\n      }\n\n      // Add incoming audio to buffer\n      for (let i = 0; i < channelData.length; i++) {\n        this.buffer.push(channelData[i]);\n      }\n\n      // When buffer reaches threshold, convert and send\n      if (this.buffer.length >= this.bufferSize) {\n        const float32Array = new Float32Array(this.buffer);\n        const int16Array = new Int16Array(float32Array.length);\n\n        // Convert Float32 [-1, 1] to Int16 [-32768, 32767]\n        for (let i = 0; i < float32Array.length; i++) {\n          // Clamp the value to prevent overflow\n          const sample = Math.max(-1, Math.min(1, float32Array[i]));\n          // Scale to PCM16 range\n          int16Array[i] = sample < 0 ? sample * 32768 : sample * 32767;\n        }\n\n        // Send to main thread as transferable ArrayBuffer\n        this.port.postMessage(\n          {\n            audioData: int16Array.buffer\n          },\n          [int16Array.buffer]\n        );\n\n        // Clear buffer\n        this.buffer = [];\n      }\n    }\n\n    return true; // Continue processing\n  }\n}\n\nregisterProcessor(\"scribeAudioProcessor\", ScribeAudioProcessor);\n\n`\n);\n","import { RealtimeConnection } from \"./connection\";\nimport { loadScribeAudioProcessor } from \"../utils/scribeAudioProcessor.generated\";\n\nexport enum AudioFormat {\n  PCM_8000 = \"pcm_8000\",\n  PCM_16000 = \"pcm_16000\",\n  PCM_22050 = \"pcm_22050\",\n  PCM_24000 = \"pcm_24000\",\n  PCM_44100 = \"pcm_44100\",\n  PCM_48000 = \"pcm_48000\",\n  ULAW_8000 = \"ulaw_8000\",\n}\n\nexport enum CommitStrategy {\n  MANUAL = \"manual\",\n  VAD = \"vad\",\n}\n\ninterface BaseOptions {\n  /**\n   * Token to use for the WebSocket connection. Obtained from the ElevenLabs API.\n   */\n  token: string;\n  /**\n   * Strategy for committing transcriptions.\n   * @default CommitStrategy.MANUAL\n   */\n  commitStrategy?: CommitStrategy;\n  /**\n   * Silence threshold in seconds for VAD (Voice Activity Detection).\n   * Must be a positive number between 0.3 and 3.0\n   */\n  vadSilenceThresholdSecs?: number;\n  /**\n   * Threshold for voice activity detection.\n   * Must be between 0.1 and 0.9.\n   */\n  vadThreshold?: number;\n  /**\n   * Minimum speech duration in milliseconds.\n   * Must be a positive integer between 50 and 2000.\n   */\n  minSpeechDurationMs?: number;\n  /**\n   * Minimum silence duration in milliseconds.\n   * Must be a positive integer between 50 and 2000.\n   */\n  minSilenceDurationMs?: number;\n  /**\n   * Model ID to use for transcription.\n   * Must be a valid model ID.\n   */\n  modelId: string;\n  /**\n   * An ISO-639-1 or ISO-639-3 language_code corresponding to the language of the audio file.\n   * Can sometimes improve transcription performance if known beforehand.\n   */\n  languageCode?: string;\n  /**\n   * Base URI to use for the WebSocket connection.\n   * If not provided, the default URI will be used.\n   */\n  baseUri?: string;\n  /**\n   * Whether to receive a committed_transcript_with_timestamps event which includes word-level timestamps.\n   * @default false\n   */\n  includeTimestamps?: boolean;\n}\n\nexport interface AudioOptions extends BaseOptions {\n  audioFormat: AudioFormat;\n  sampleRate: number;\n  microphone?: never;\n}\n\n/**\n * Options for automatic microphone streaming in the browser.\n */\nexport interface MicrophoneOptions extends BaseOptions {\n  microphone?: {\n    deviceId?: ConstrainDOMString;\n    echoCancellation?: boolean;\n    noiseSuppression?: boolean;\n    autoGainControl?: boolean;\n    channelCount?: number;\n  };\n  audioFormat?: never;\n  sampleRate?: never;\n}\n\n/**\n * Real-time speech-to-text transcription client for browser environments.\n * Supports microphone streaming and manual audio chunk transmission.\n */\n\n// biome-ignore lint/complexity/noStaticOnlyClass: This class is static only because it is a singleton\nexport class ScribeRealtime {\n  private static readonly DEFAULT_BASE_URI = \"wss://api.elevenlabs.io\";\n\n  private static getWebSocketUri(\n    baseUri: string = ScribeRealtime.DEFAULT_BASE_URI\n  ): string {\n    return `${baseUri}/v1/speech-to-text/realtime`;\n  }\n\n  private static buildWebSocketUri(\n    options: AudioOptions | MicrophoneOptions\n  ): string {\n    const baseUri = ScribeRealtime.getWebSocketUri(options.baseUri);\n    const params = new URLSearchParams();\n\n    // Model ID and token are required, so no check required\n    params.append(\"model_id\", options.modelId);\n    params.append(\"token\", options.token);\n\n    // Add optional parameters if provided, with validation\n    if (options.commitStrategy !== undefined) {\n      params.append(\"commit_strategy\", options.commitStrategy);\n    }\n    if (options.audioFormat !== undefined) {\n      params.append(\"audio_format\", options.audioFormat);\n    }\n    if (options.vadSilenceThresholdSecs !== undefined) {\n      if (\n        options.vadSilenceThresholdSecs <= 0.3 ||\n        options.vadSilenceThresholdSecs > 3.0\n      ) {\n        throw new Error(\"vadSilenceThresholdSecs must be between 0.3 and 3.0\");\n      }\n      params.append(\n        \"vad_silence_threshold_secs\",\n        options.vadSilenceThresholdSecs.toString()\n      );\n    }\n    if (options.vadThreshold !== undefined) {\n      if (options.vadThreshold < 0.1 || options.vadThreshold > 0.9) {\n        throw new Error(\"vadThreshold must be between 0.1 and 0.9\");\n      }\n      params.append(\"vad_threshold\", options.vadThreshold.toString());\n    }\n    if (options.minSpeechDurationMs !== undefined) {\n      if (\n        options.minSpeechDurationMs <= 50 ||\n        options.minSpeechDurationMs > 2000\n      ) {\n        throw new Error(\"minSpeechDurationMs must be between 50 and 2000\");\n      }\n      params.append(\n        \"min_speech_duration_ms\",\n        options.minSpeechDurationMs.toString()\n      );\n    }\n    if (options.minSilenceDurationMs !== undefined) {\n      if (\n        options.minSilenceDurationMs <= 50 ||\n        options.minSilenceDurationMs > 2000\n      ) {\n        throw new Error(\"minSilenceDurationMs must be between 50 and 2000\");\n      }\n      params.append(\n        \"min_silence_duration_ms\",\n        options.minSilenceDurationMs.toString()\n      );\n    }\n    if (options.languageCode !== undefined) {\n      params.append(\"language_code\", options.languageCode);\n    }\n    if (options.includeTimestamps !== undefined) {\n      params.append(\n        \"include_timestamps\",\n        options.includeTimestamps ? \"true\" : \"false\"\n      );\n    }\n\n    const queryString = params.toString();\n    return queryString ? `${baseUri}?${queryString}` : baseUri;\n  }\n\n  /**\n   * Establishes a WebSocket connection for real-time speech-to-text transcription.\n   *\n   * @param options - Configuration options for the connection\n   * @returns A RealtimeConnection instance\n   *\n   * @example\n   * ```typescript\n   * // Manual audio streaming\n   * const connection = Scribe.connect({\n   *     token: \"...\",\n   *     modelId: \"scribe_v2_realtime\",\n   *     audioFormat: AudioFormat.PCM_16000,\n   *     sampleRate: 16000,\n   * });\n   *\n   * // Automatic microphone streaming\n   * const connection = Scribe.connect({\n   *     token: \"...\",\n   *     modelId: \"scribe_v2_realtime\",\n   *     microphone: {\n   *         echoCancellation: true,\n   *         noiseSuppression: true\n   *     }\n   * });\n   * ```\n   */\n  public static connect(\n    options: AudioOptions | MicrophoneOptions\n  ): RealtimeConnection {\n    if (!options.modelId) {\n      throw new Error(\"modelId is required\");\n    }\n\n    // Create connection object first so users can attach event listeners before messages arrive\n    const sampleRate =\n      \"microphone\" in options && options.microphone\n        ? 16000\n        : (options as AudioOptions).sampleRate;\n    const connection = new RealtimeConnection(sampleRate);\n\n    // Build WebSocket URI with query parameters\n    const uri = ScribeRealtime.buildWebSocketUri(options);\n\n    const websocket = new WebSocket(uri);\n\n    // If microphone mode, set up streaming handler\n    if (\"microphone\" in options && options.microphone) {\n      websocket.addEventListener(\"open\", () => {\n        ScribeRealtime.streamFromMicrophone(\n          options as MicrophoneOptions,\n          connection\n        );\n      });\n    }\n\n    connection.setWebSocket(websocket);\n\n    return connection;\n  }\n\n  private static async streamFromMicrophone(\n    options: MicrophoneOptions,\n    connection: RealtimeConnection\n  ): Promise<void> {\n    const TARGET_SAMPLE_RATE = 16000;\n\n    try {\n      // Get microphone access\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          deviceId: options.microphone?.deviceId,\n          echoCancellation: options.microphone?.echoCancellation ?? true,\n          noiseSuppression: options.microphone?.noiseSuppression ?? true,\n          autoGainControl: options.microphone?.autoGainControl ?? true,\n          channelCount: options.microphone?.channelCount ?? 1,\n          sampleRate: { ideal: TARGET_SAMPLE_RATE },\n        },\n      });\n\n      // Get the actual sample rate from the stream - the ideal may not have been honored\n      const trackSettings = stream.getAudioTracks()[0]?.getSettings();\n      const streamSampleRate = trackSettings?.sampleRate;\n\n      // Create audio context matching the stream's sample rate to avoid Firefox errors\n      // Firefox requires the AudioContext to match the microphone's native sample rate\n      const audioContext = new AudioContext(\n        streamSampleRate ? { sampleRate: streamSampleRate } : {}\n      );\n\n      // Load scribe worklet\n      await loadScribeAudioProcessor(audioContext.audioWorklet);\n\n      // Set up audio pipeline\n      const source = audioContext.createMediaStreamSource(stream);\n      const scribeNode = new AudioWorkletNode(\n        audioContext,\n        \"scribeAudioProcessor\"\n      );\n\n      // Configure the worklet with sample rate info for resampling\n      // (only needed when AudioContext sample rate differs from target)\n      if (audioContext.sampleRate !== TARGET_SAMPLE_RATE) {\n        scribeNode.port.postMessage({\n          type: \"configure\",\n          inputSampleRate: audioContext.sampleRate,\n          outputSampleRate: TARGET_SAMPLE_RATE,\n        });\n      }\n\n      // Handle audio data from worklet\n      scribeNode.port.onmessage = event => {\n        const { audioData } = event.data;\n        // Convert ArrayBuffer to base64\n        const bytes = new Uint8Array(audioData);\n        let binary = \"\";\n        for (let i = 0; i < bytes.length; i++) {\n          binary += String.fromCharCode(bytes[i]);\n        }\n        const base64Audio = btoa(binary);\n\n        connection.send({ audioBase64: base64Audio });\n      };\n\n      // Connect audio pipeline\n      source.connect(scribeNode);\n\n      // Resume audio context if needed\n      if (audioContext.state === \"suspended\") {\n        await audioContext.resume();\n      }\n\n      // Store cleanup function\n      connection._audioCleanup = () => {\n        stream.getTracks().forEach(track => {\n          track.stop();\n        });\n        source.disconnect();\n        scribeNode.disconnect();\n        audioContext.close();\n      };\n    } catch (error) {\n      console.error(\"Failed to start microphone streaming:\", error);\n      throw error;\n    }\n  }\n}\n","import { BaseConversation, type PartialOptions } from \"./BaseConversation\";\nimport { TextConversation } from \"./TextConversation\";\nimport { VoiceConversation } from \"./VoiceConversation\";\n\nexport type {\n  Mode,\n  Role,\n  Options,\n  PartialOptions,\n  ClientToolsConfig,\n  Callbacks,\n  Status,\n  AudioWorkletConfig,\n} from \"./BaseConversation\";\nexport type { InputConfig } from \"./utils/input\";\nexport type { OutputConfig } from \"./utils/output\";\nexport { Input } from \"./utils/input\";\nexport { Output } from \"./utils/output\";\nexport type {\n  IncomingSocketEvent,\n  VadScoreEvent,\n  AudioAlignmentEvent,\n} from \"./utils/events\";\nexport type {\n  SessionConfig,\n  BaseSessionConfig,\n  DisconnectionDetails,\n  Language,\n  ConnectionType,\n  FormatConfig,\n} from \"./utils/BaseConnection\";\nexport { createConnection } from \"./utils/ConnectionFactory\";\nexport { WebSocketConnection } from \"./utils/WebSocketConnection\";\nexport { WebRTCConnection } from \"./utils/WebRTCConnection\";\nexport { postOverallFeedback } from \"./utils/postOverallFeedback\";\nexport { SessionConnectionError } from \"./utils/errors\";\nexport { VoiceConversation } from \"./VoiceConversation\";\nexport { TextConversation } from \"./TextConversation\";\n\n// Scribe exports\nexport {\n  Scribe,\n  AudioFormat,\n  CommitStrategy,\n  RealtimeEvents,\n  RealtimeConnection,\n} from \"./scribe\";\nexport type {\n  AudioOptions,\n  MicrophoneOptions,\n  WebSocketMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n  ScribeCommitThrottledErrorMessage,\n  ScribeTranscriberErrorMessage,\n  ScribeUnacceptedTermsErrorMessage,\n  ScribeRateLimitedErrorMessage,\n  ScribeInputErrorMessage,\n  ScribeQueueOverflowErrorMessage,\n  ScribeResourceExhaustedErrorMessage,\n  ScribeSessionTimeLimitExceededErrorMessage,\n  ScribeChunkSizeExceededErrorMessage,\n  ScribeInsufficientAudioActivityErrorMessage,\n} from \"./scribe\";\n\nexport class Conversation extends BaseConversation {\n  public static startSession(options: PartialOptions): Promise<Conversation> {\n    const fullOptions = Conversation.getFullOptions(options);\n    return fullOptions.textOnly\n      ? TextConversation.startSession(fullOptions)\n      : VoiceConversation.startSession(fullOptions);\n  }\n}\n"],"names":["EMPTY_FREQUENCY_DATA","Uint8Array","BaseConversation","getFullOptions","partialOptions","_partialOptions$overr","textOnly","options","_options$overrides$co","_options$overrides","textOnlyOverride","overrides","conversation","console","warn","isTextOnly","_extends","clientTools","onConnect","onDebug","onDisconnect","onError","onMessage","onAudio","onModeChange","onStatusChange","onCanSendFeedbackChange","onInterruption","constructor","connection","_this","lastInterruptTimestamp","this","mode","status","volume","currentEventId","lastFeedbackEventId","canSendFeedback","endSessionWithDetails","async","details","updateStatus","handleEndSession","parsedEvent","type","handleInterruption","handleAgentResponse","handleUserTranscript","handleTentativeAgentResponse","handleClientToolCall","error","Error","message","String","clientToolName","client_tool_call","tool_name","toolCallId","tool_call_id","handleAudio","handleVadScore","sendMessage","event_id","ping_event","handleMCPToolCall","handleMCPConnectionStatus","handleAgentToolRequest","handleAgentToolResponse","handleConversationMetadata","handleAsrInitiationMetadata","handleAgentChatResponsePart","handleErrorEvent","setVolume","conversationId","updateMode","endSession","reason","close","updateCanSendFeedback","event","interruption_event","source","role","agent_response_event","agent_response","user_transcription_event","user_transcript","response","tentative_agent_response_internal_event","tentative_agent_response","onVadScore","vadScore","vad_score_event","vad_score","Object","prototype","hasOwnProperty","call","_await$this$options$c","result","parameters","formattedResult","JSON","stringify","is_error","e","onUnhandledClientToolCall","onMCPToolCall","mcp_tool_call","onMCPConnectionStatus","mcp_connection_status","onAgentToolRequest","agent_tool_request","agent_tool_response","context","CloseEvent","onAgentToolResponse","onConversationMetadata","conversation_initiation_metadata_event","onAsrInitiationMetadata","asr_initiation_metadata_event","onAgentChatResponsePart","text_response_part","errorType","error_event","error_type","code","debugMessage","debug_message","Event","getId","isOpen","setMicMuted","isMuted","getInputByteFrequencyData","getOutputByteFrequencyData","getInputVolume","getOutputVolume","sendFeedback","like","score","sendContextualUpdate","text","sendUserMessage","sendUserActivity","sendMCPToolApprovalResult","isApproved","is_approved","BaseConnection","config","queue","disconnectionDetails","onDisconnectCallback","onMessageCallback","onModeChangeCallback","debug","info","callback","length","queueMicrotask","forEach","_this$onModeChangeCal","disconnect","_this$onDisconnectCal","handleMessage","push","parseFormat","format","formatPart","sampleRatePart","split","includes","sampleRate","Number","parseInt","isNaN","PACKAGE_VERSION","isValidSocketEvent","CONVERSATION_INITIATION_CLIENT_DATA_TYPE","constructOverrides","_config$overrides","overridesEvent","_config$overrides$age","_config$overrides$age2","_config$overrides$age3","_config$overrides$tts","_config$overrides$tts2","_config$overrides$tts3","_config$overrides$tts4","_config$overrides$con","conversation_config_override","agent","prompt","first_message","firstMessage","language","tts","voice_id","voiceId","speed","stability","similarity_boost","similarityBoost","text_only","customLlmExtraBody","custom_llm_extra_body","dynamicVariables","dynamic_variables","userId","user_id","client","source_info","version","SessionConnectionError","super","closeCode","closeReason","name","WebSocketConnection","socket","inputFormat","outputFormat","addEventListener","setTimeout","undefined","parse","data","create","_config$origin","_config$overrides2","origin","url","signedUrl","separator","agentId","protocols","authorization","WebSocket","conversationConfig","Promise","resolve","reject","_socket","send","once","conversation_id","agent_output_audio_format","user_input_audio_format","_socket2","arrayBufferToBase64","b","buffer","window","btoa","fromCharCode","base64ToArrayBuffer","base64","binaryString","atob","len","bytes","i","charCodeAt","URLCache","Map","createWorkletModuleLoader","sourceCode","worklet","path","cachedUrl","get","addModule","set","blob","Blob","blobURL","URL","createObjectURL","_unused","revokeObjectURL","moduleURL","loadRawAudioProcessor","WebRTCConnection","room","isConnected","audioEventId","audioCaptureContext","audioElements","outputDeviceId","outputAnalyser","outputFrequencyData","setupRoomEventListeners","conversationToken","replace","fetch","ok","statusText","json","token","msg","Room","Date","now","livekitUrl","_room$name$match","connect","onConnected","off","RoomEvent","Connected","on","match","localParticipant","setMicrophoneEnabled","Disconnected","toString","ConnectionStateChanged","state","ConnectionState","DataReceived","payload","_participant","TextDecoder","decode","TrackSubscribed","track","_publication","participant","kind","Track","Kind","Audio","identity","remoteAudioTrack","audioElement","attach","autoplay","controls","setSinkId","style","display","document","body","appendChild","setupAudioCapture","ActiveSpeakersChanged","speakers","startsWith","ParticipantDisconnected","_participant$identity","audioTrackPublications","publication","stop","catch","element","parentNode","removeChild","TextEncoder","encode","publishData","reliable","getRoom","micTrackPublication","getTrackPublication","Source","Microphone","mute","unmute","_error","audioContext","AudioContext","createAnalyser","fftSize","smoothingTimeConstant","mediaStream","MediaStream","mediaStreamTrack","createMediaStreamSource","audioWorklet","AudioWorkletNode","port","postMessage","onmessage","audioData","maxVolume","base64Audio","eventId","audio_event","audio_base_64","setAudioVolume","setAudioOutputDevice","deviceId","HTMLAudioElement","promises","map","all","setAudioInputDevice","currentMicTrackPublication","unpublishTrack","audioConstraints","exact","echoCancellation","noiseSuppression","autoGainControl","channelCount","ideal","audioTrack","createLocalAudioTrack","publishTrack","recoveryError","_this$outputFrequency","frequencyBinCount","getByteFrequencyData","createConnection","connectionType","determineConnectionType","isIosDevice","navigator","platform","userAgent","applyDelay","delayConfig","default","android","delay","_delayConfig$android","test","_delayConfig$ios","ios","TextConversation","startSession","fullOptions","connectionDelay","_connection","defaultConstraints","Input","preferHeadphonesForIosDevices","inputDeviceId","workletPaths","libsampleratePath","inputStream","idealDevice","mediaDevices","enumerateDevices","find","d","keyword","label","toLowerCase","getDeviceIdConstraint","supportsSampleRateConstraint","getSupportedConstraints","analyser","libsamplerateUrl","constraints","voiceIsolation","getUserMedia","audio","resume","permissions","query","_inputStream","_context","getTracks","mediaStreamSource","settingInput","handlePermissionsChange","_track$getSettings","getAudioTracks","getSettings","setInputDevice","forgetInputStreamAndSource","removeEventListener","setMuted","newInputStream","loadAudioConcatProcessor","Output","gain","createGain","src","load","destination","createMediaStreamDestination","srcObject","stream","_audioElement","_audioElement2","pause","setOutputDevice","VoiceConversation","requestWakeLock","wakeLock","request","_e","_options$useWakeLock","input","output","preliminaryInputStream","useWakeLock","_preliminaryInputStre","_preliminaryInputStre2","_input","_output","_wakeLock","release","inputFrequencyData","visibilityChangeHandler","onInputWorkletMessage","user_audio_chunk","onOutputWorkletMessage","finished","addAudioBase64Chunk","chunk","cancelScheduledValues","currentTime","value","fadeOutAudio","exponentialRampToValueAtTime","calculateVolume","frequencyData","clampedVolume","isFinite","Math","min","max","_this$wakeLock","visibilityState","released","then","lock","_this$wakeLock2","_this$options$onAudio","_this$options","alignment","onAudioAlignment","_this$inputFrequencyD","changeInputDevice","newInput","changeOutputDevice","newOutput","postOverallFeedback","likeOrFeedback","feedback","rating","comment","method","headers","EventEmitter","listeners","listener","has","Set","eventListeners","add","delete","emit","args","RealtimeEvents","RealtimeConnection","websocket","eventEmitter","currentSampleRate","_audioCleanup","setWebSocket","readyState","OPEN","message_type","SESSION_STARTED","PARTIAL_TRANSCRIPT","COMMITTED_TRANSCRIPT","COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS","AUTH_ERROR","ERROR","QUOTA_EXCEEDED","COMMIT_THROTTLED","TRANSCRIBER_ERROR","UNACCEPTED_TERMS","RATE_LIMITED","INPUT_ERROR","QUEUE_OVERFLOW","RESOURCE_EXHAUSTED","SESSION_TIME_LIMIT_EXCEEDED","CHUNK_SIZE_EXCEEDED","INSUFFICIENT_AUDIO_ACTIVITY","log","wasClean","errorMessage","CLOSE","_data$commit","_data$sampleRate","audioBase64","commit","sample_rate","previous_text","previousText","loadScribeAudioProcessor","AudioFormat","CommitStrategy","ScribeRealtime","getWebSocketUri","baseUri","DEFAULT_BASE_URI","buildWebSocketUri","params","URLSearchParams","append","modelId","commitStrategy","audioFormat","vadSilenceThresholdSecs","vadThreshold","minSpeechDurationMs","minSilenceDurationMs","languageCode","includeTimestamps","queryString","microphone","uri","streamFromMicrophone","TARGET_SAMPLE_RATE","_options$microphone","_options$microphone$e","_options$microphone2","_options$microphone$n","_options$microphone3","_options$microphone$a","_options$microphone4","_options$microphone$c","_options$microphone5","_stream$getAudioTrack","trackSettings","streamSampleRate","scribeNode","inputSampleRate","outputSampleRate","binary","Conversation"],"mappings":"wUA+DA,MAAMA,EAAuB,IAAIC,WAAW,SAsB/BC,EASD,qBAAOC,CAAeC,GAA8BC,IAAAA,EAC5D,MAAMC,EA9BM,SAAWC,GAAuB,IAAAC,EAAAC,EAChD,MAAQH,SAAUI,GAAoD,OAAlCF,EAAoB,OAApBC,EAAGF,EAAQI,gBAAS,EAAjBF,EAAmBG,cAAYJ,EAAI,CAAE,GACtEF,SAAEA,GAAaC,EACrB,MAAwB,kBAAbD,GAEqB,kBAArBI,GACPJ,IAAaI,GAEbG,QAAQC,KACN,0CAA0CR,6CAAoDI,mEAG3FJ,GAC8B,kBAArBI,EACTA,OAEP,CAEJ,CAYqBK,CAAWX,GAC5B,OAAAY,GACEC,YAAa,CAAE,EACfC,UAAWA,OACXC,QAASA,OACTC,aAAcA,OACdC,QAASA,OACTC,UAAWA,OACXC,QAASA,OACTC,aAAcA,OACdC,eAAgBA,OAChBC,wBAAyBA,OACzBC,eAAgBA,QACbvB,EAAc,CACjBE,WACAK,UAASK,EAAA,CAAA,EACJZ,EAAeO,UAAS,CAC3BC,aAAYI,EAAA,CAAA,EACiB,OADjBX,EACPD,EAAeO,gBAAS,EAAxBN,EAA0BO,aAAY,CACzCN,gBAIR,CAEAsB,WAAAA,CACqBrB,EACAsB,GAA0BC,IAAAA,EAD1BvB,KAAAA,KAAAA,aACAsB,EAAAA,KAAAA,gBApCXE,EAAAA,KAAAA,uBAAyB,EAACC,KAC1BC,KAAa,YAAWD,KACxBE,OAAiB,aAAYF,KAC7BG,OAAS,EAACH,KACVI,eAAiB,EACjBC,KAAAA,oBAAsB,EACtBC,KAAAA,iBAAkB,EA6CpBC,KAAAA,sBAAwBC,eAAOC,GACjB,cAAhBX,EAAKI,QAA0C,eAAhBJ,EAAKI,SACxCJ,EAAKY,aAAa,uBACZZ,EAAKa,mBACXb,EAAKY,aAAa,gBACdZ,EAAKvB,QAAQa,cACfU,EAAKvB,QAAQa,aAAaqB,GAE9B,EAACT,KA6NOV,UAAYkB,eAAOI,GACzB,OAAQA,EAAYC,MAClB,IAAK,eAEH,YADAf,EAAKgB,mBAAmBF,GAG1B,IAAK,iBAEH,YADAd,EAAKiB,oBAAoBH,GAG3B,IAAK,kBAEH,YADAd,EAAKkB,qBAAqBJ,GAG5B,IAAK,oCAEH,YADAd,EAAKmB,6BAA6BL,GAGpC,IAAK,mBACH,UACQd,EAAKoB,qBAAqBN,EAClC,CAAE,MAAOO,GACPrB,EAAKT,QACH,kDAAkD8B,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,KAClG,CACEI,eAAgBX,EAAYY,iBAAiBC,UAC7CC,WAAYd,EAAYY,iBAAiBG,cAG/C,CACA,OAEF,IAAK,QAEH,YADA7B,EAAK8B,YAAYhB,GAInB,IAAK,YAEH,YADAd,EAAK+B,eAAejB,GAItB,IAAK,OAOH,YANAd,EAAKD,WAAWiC,YAAY,CAC1BjB,KAAM,OACNkB,SAAUnB,EAAYoB,WAAWD,WAOrC,IAAK,gBAEH,YADAjC,EAAKmC,kBAAkBrB,GAIzB,IAAK,wBAEH,YADAd,EAAKoC,0BAA0BtB,GAIjC,IAAK,qBAEH,YADAd,EAAKqC,uBAAuBvB,GAI9B,IAAK,sBAEH,YADAd,EAAKsC,wBAAwBxB,GAI/B,IAAK,mCAEH,YADAd,EAAKuC,2BAA2BzB,GAIlC,IAAK,0BAEH,YADAd,EAAKwC,4BAA4B1B,GAInC,IAAK,2BAEH,YADAd,EAAKyC,4BAA4B3B,GAInC,IAAK,QAEH,YADAd,EAAK0C,iBAAiB5B,GAIxB,QAIE,YAHId,EAAKvB,QAAQY,SACfW,EAAKvB,QAAQY,QAAQyB,IAK7B,EAiBO6B,KAAAA,UAAY,EAAGtC,aACpBH,KAAKG,OAASA,GA1WKH,KAAOzB,QAAPA,EACAyB,KAAUH,WAAVA,EAEfG,KAAKzB,QAAQW,WACfc,KAAKzB,QAAQW,UAAU,CAAEwD,eAAgB7C,EAAW6C,iBAEtD1C,KAAKH,WAAWP,UAAUU,KAAKV,WAC/BU,KAAKH,WAAWT,aAAaY,KAAKO,uBAClCP,KAAKH,WAAWL,aAAaS,GAAQD,KAAK2C,WAAW1C,IACrDD,KAAKU,aAAa,YACpB,CAEOkC,UAAAA,GACL,OAAO5C,KAAKO,sBAAsB,CAAEsC,OAAQ,QAC9C,CAYU,sBAAMlC,GACdX,KAAKH,WAAWiD,OAClB,CAEUH,UAAAA,CAAW1C,GACfA,IAASD,KAAKC,OAChBD,KAAKC,KAAOA,EACRD,KAAKzB,QAAQiB,cACfQ,KAAKzB,QAAQiB,aAAa,CAAES,SAGlC,CAEUS,YAAAA,CAAaR,GACjBA,IAAWF,KAAKE,SAClBF,KAAKE,OAASA,EACVF,KAAKzB,QAAQkB,gBACfO,KAAKzB,QAAQkB,eAAe,CAAES,WAGpC,CAEU6C,qBAAAA,GACR,MAAMzC,EAAkBN,KAAKI,iBAAmBJ,KAAKK,oBACjDL,KAAKM,kBAAoBA,IAC3BN,KAAKM,gBAAkBA,EACnBN,KAAKzB,QAAQmB,yBACfM,KAAKzB,QAAQmB,wBAAwB,CAAEY,oBAG7C,CAEUQ,kBAAAA,CAAmBkC,GACvBA,EAAMC,qBACRjD,KAAKD,uBAAyBiD,EAAMC,mBAAmBlB,SAEnD/B,KAAKzB,QAAQoB,gBACfK,KAAKzB,QAAQoB,eAAe,CAC1BoC,SAAUiB,EAAMC,mBAAmBlB,WAI3C,CAEUhB,mBAAAA,CAAoBiC,GACxBhD,KAAKzB,QAAQe,WACfU,KAAKzB,QAAQe,UAAU,CACrB4D,OAAQ,KACRC,KAAM,QACN9B,QAAS2B,EAAMI,qBAAqBC,gBAG1C,CAEUrC,oBAAAA,CAAqBgC,GACzBhD,KAAKzB,QAAQe,WACfU,KAAKzB,QAAQe,UAAU,CACrB4D,OAAQ,OACRC,KAAM,OACN9B,QAAS2B,EAAMM,yBAAyBC,iBAG9C,CAEUtC,4BAAAA,CACR+B,GAEIhD,KAAKzB,QAAQY,SACfa,KAAKzB,QAAQY,QAAQ,CACnB0B,KAAM,2BACN2C,SACER,EAAMS,wCACHC,0BAGX,CAEU7B,cAAAA,CAAemB,GACnBhD,KAAKzB,QAAQoF,YACf3D,KAAKzB,QAAQoF,WAAW,CACtBC,SAAUZ,EAAMa,gBAAgBC,WAGtC,CAEU,0BAAM5C,CAAqB8B,GACnC,GACEe,OAAOC,UAAUC,eAAeC,KAC9BlE,KAAKzB,QAAQU,YACb+D,EAAMxB,iBAAiBC,WAGzB,IAAI,IAAA0C,EACF,MAAMC,EAGHD,OAHSA,QACCnE,KAACzB,QAAQU,YAAY+D,EAAMxB,iBAAiBC,WACrDuB,EAAMxB,iBAAiB6C,aACxBF,EAAK,oCAGFG,EACc,iBAAXF,EAAsBG,KAAKC,UAAUJ,GAAU9C,OAAO8C,GAE/DpE,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcqB,EAAMxB,iBAAiBG,aACrCyC,OAAQE,EACRG,UAAU,GAEd,CAAE,MAAOC,GACP1E,KAAKX,QACH,sDAAkE,MAAXqF,OAAW,EAAXA,EAAarD,UACpE,CACEE,eAAgByB,EAAMxB,iBAAiBC,YAG3CzB,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcqB,EAAMxB,iBAAiBG,aACrCyC,OAAQ,iCAAkCM,MAAAA,OAAAA,EAAAA,EAAarD,UACvDoD,UAAU,GAEd,KACK,CACL,GAAIzE,KAAKzB,QAAQoG,0BAGf,YAFA3E,KAAKzB,QAAQoG,0BAA0B3B,EAAMxB,kBAK/CxB,KAAKX,QACH,yBAAyB2D,EAAMxB,iBAAiBC,qCAChD,CACEF,eAAgByB,EAAMxB,iBAAiBC,YAG3CzB,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcqB,EAAMxB,iBAAiBG,aACrCyC,OAAQ,yBAAyBpB,EAAMxB,iBAAiBC,qCACxDgD,UAAU,GAEd,CACF,CAEU7C,WAAAA,CAAYoB,GAEZf,CAAAA,iBAAAA,CAAkBe,GACtBhD,KAAKzB,QAAQqG,eACf5E,KAAKzB,QAAQqG,cAAc5B,EAAM6B,cAErC,CAEU3C,yBAAAA,CAA0Bc,GAC9BhD,KAAKzB,QAAQuG,uBACf9E,KAAKzB,QAAQuG,sBAAsB9B,EAAM+B,sBAE7C,CAEU5C,sBAAAA,CAAuBa,GAC3BhD,KAAKzB,QAAQyG,oBACfhF,KAAKzB,QAAQyG,mBAAmBhC,EAAMiC,mBAE1C,CAEU7C,uBAAAA,CAAwBY,GACY,aAAxCA,EAAMkC,oBAAoBzD,WAC5BzB,KAAKO,sBAAsB,CACzBsC,OAAQ,QACRsC,QAAS,IAAIC,WAAW,WAAY,CAAEvC,OAAQ,2BAI9C7C,KAAKzB,QAAQ8G,qBACfrF,KAAKzB,QAAQ8G,oBAAoBrC,EAAMkC,oBAE3C,CAEU7C,0BAAAA,CAA2BW,GAC/BhD,KAAKzB,QAAQ+G,wBACftF,KAAKzB,QAAQ+G,uBACXtC,EAAMuC,uCAGZ,CAEUjD,2BAAAA,CAA4BU,GAChChD,KAAKzB,QAAQiH,yBACfxF,KAAKzB,QAAQiH,wBAAwBxC,EAAMyC,8BAE/C,CAEUlD,2BAAAA,CAA4BS,GAChChD,KAAKzB,QAAQmH,yBACf1F,KAAKzB,QAAQmH,wBAAwB1C,EAAM2C,mBAE/C,CAEUnD,gBAAAA,CAAiBQ,GACzB,MAAM4C,EAAY5C,EAAM6C,YAAYC,WAC9BzE,EACJ2B,EAAM6C,YAAYxE,SAAW2B,EAAM6C,YAAYhD,QAAU,gBAEzC,0BAAd+C,EASJ5F,KAAKX,QAAQ,iBAAiBgC,IAAW,CACvCuE,YACAG,KAAM/C,EAAM6C,YAAYE,KACxBC,aAAchD,EAAM6C,YAAYI,cAChCxF,QAASuC,EAAM6C,YAAYpF,UAZ3BT,KAAKO,sBAAsB,CACzBsC,OAAQ,QACRxB,QAASA,EACT8D,QAAS,IAAIe,MAAM,0BAWzB,CAuGQ7G,OAAAA,CAAQgC,EAAiB8D,GAC/BtG,QAAQsC,MAAME,EAAS8D,GACnBnF,KAAKzB,QAAQc,SACfW,KAAKzB,QAAQc,QAAQgC,EAAS8D,EAElC,CAEOgB,KAAAA,GACL,OAAOnG,KAAKH,WAAW6C,cACzB,CAEO0D,MAAAA,GACL,MAAuB,cAAhBpG,KAAKE,MACd,CAMOmG,WAAAA,CAAYC,GACjBtG,KAAKH,WAAWwG,YAAYC,EAC9B,CAEOC,yBAAAA,GACL,OAAOvI,CACT,CAEOwI,0BAAAA,GACL,OAAOxI,CACT,CAEOyI,cAAAA,GACL,OAAO,CACT,CAEOC,eAAAA,GACL,OACF,CAAA,CAEOC,YAAAA,CAAaC,GACb5G,KAAKM,iBASVN,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,WACNgG,MAAOD,EAAO,OAAS,UACvB7E,SAAU/B,KAAKI,iBAEjBJ,KAAKK,oBAAsBL,KAAKI,eAChCJ,KAAK+C,yBAdHlE,QAAQC,KACuB,IAA7BkB,KAAKK,oBACD,8DACA,iFAYV,CAEOyG,oBAAAA,CAAqBC,GAC1B/G,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,oBACNkG,QAEJ,CAEOC,eAAAA,CAAgBD,GACrB/G,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,eACNkG,QAEJ,CAEOE,gBAAAA,GACLjH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,iBAEV,CAEOqG,yBAAAA,CAA0BxF,EAAoByF,GACnDnH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,2BACNc,aAAcD,EACd0F,YAAaD,GAEjB,QC/coBE,EAYpBzH,WAAAA,CAAY0H,EAAgD,CAAE,GAPpDC,KAAAA,MAA+B,QAC/BC,qBAAoD,KAAIxH,KACxDyH,qBAAoD,KACpDC,KAAAA,kBAA8C,KAAI1H,KAClD2H,qBAAsD,KACtDxI,KAAAA,aAGR,EAAAa,KAAKb,QAAUmI,EAAOnI,OACxB,CAEUyI,KAAAA,CAAMC,GACV7H,KAAKb,SAASa,KAAKb,QAAQ0I,EACjC,CAMOvI,SAAAA,CAAUwI,GACf9H,KAAK0H,kBAAoBI,EACzB,MAAMP,EAAQvH,KAAKuH,MACnBvH,KAAKuH,MAAQ,GAETA,EAAMQ,OAAS,GAGjBC,eAAe,KACbT,EAAMU,QAAQH,IAGpB,CAEO1I,YAAAA,CAAa0I,GAClB9H,KAAKyH,qBAAuBK,EAC5B,MAAMrH,EAAUT,KAAKwH,qBACjB/G,GAGFuH,eAAe,KACbF,EAASrH,IAGf,CAEOjB,YAAAA,CAAasI,GAClB9H,KAAK2H,qBAAuBG,CAC9B,CAEUnF,UAAAA,CAAW1C,GAAUiI,IAAAA,EAC7BA,OAAAA,EAAIlI,KAAC2H,uBAALO,EAAAhE,UAA4BjE,EAC9B,CAEUkI,UAAAA,CAAW1H,GACa2H,IAAAA,EAA3BpI,KAAKwH,uBACRxH,KAAKwH,qBAAuB/G,SAC5B2H,EAAApI,KAAKyH,uBAALW,EAAAlE,KAAAlE,KAA4BS,GAEhC,CAEU4H,aAAAA,CAAczH,GAClBZ,KAAK0H,kBACP1H,KAAK0H,kBAAkB9G,GAEvBZ,KAAKuH,MAAMe,KAAK1H,EAEpB,EAGc,SAAA2H,EAAYC,GAC1B,MAAOC,EAAYC,GAAkBF,EAAOG,MAAM,KAClD,IAAK,CAAC,MAAO,QAAQC,SAASH,GAC5B,MAAM,IAAIrH,MAAM,mBAAmBoH,KAGrC,MAAMK,EAAaC,OAAOC,SAASL,GACnC,GAAII,OAAOE,MAAMH,GACf,MAAU,IAAAzH,MAAM,wBAAwBsH,KAG1C,MAAO,CACLF,OAAQC,EACRI,aAEJ,CChLa,MAAAI,EAAkB,SCyFf,SAAAC,EAAmBlG,GACjC,QAASA,EAAMnC,IACjB,CCzFa,MAAAsI,EACX,sCAEI,SAAUC,EACd9B,GAAqB,IAAA+B,EAErB,MAAMC,EAA4C,CAChDzI,KAAMsI,GAGcI,IAAAA,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAsCtB,OAtCIxC,EAAO3I,YACT2K,EAAeS,6BAA+B,CAC5CC,MAAO,CACLC,OAA8B,OAAxBV,EAAEjC,EAAO3I,UAAUqL,YAAK,EAAtBT,EAAwBU,OAChCC,cAAqC,OAAxBV,EAAElC,EAAO3I,UAAUqL,YAAK,EAAtBR,EAAwBW,aACvCC,SAAgC,OAAxBX,EAAEnC,EAAO3I,UAAUqL,YAAK,EAAtBP,EAAwBW,UAEpCC,IAAK,CACHC,SAAUZ,OAAFA,EAAEpC,EAAO3I,UAAU0L,UAAjBX,EAAAA,EAAsBa,QAChCC,MAAOb,OAAFA,EAAErC,EAAO3I,UAAU0L,UAAjBV,EAAAA,EAAsBa,MAC7BC,UAA+B,OAAtBb,EAAEtC,EAAO3I,UAAU0L,UAAG,EAApBT,EAAsBa,UACjCC,iBAAsC,OAAtBb,EAAEvC,EAAO3I,UAAU0L,UAAG,EAApBR,EAAsBc,iBAE1C/L,aAAc,CACZgM,UAAWd,OAAFA,EAAExC,EAAO3I,UAAUC,mBAAjBkL,EAAAA,EAA+BxL,YAK5CgJ,EAAOuD,qBACTvB,EAAewB,sBAAwBxD,EAAOuD,oBAG5CvD,EAAOyD,mBACTzB,EAAe0B,kBAAoB1D,EAAOyD,kBAGxCzD,EAAO2D,SACT3B,EAAe4B,QAAU5D,EAAO2D,eAGlC5B,EAAI/B,EAAO3I,YAAP0K,EAAkB8B,SACpB7B,EAAe8B,YAAc,CAC3BlI,OAAQoE,EAAO3I,UAAUwM,OAAOjI,OAChCmI,QAAS/D,EAAO3I,UAAUwM,OAAOE,UAI9B/B,CACT,CCpDM,MAAOgC,UAA+BlK,MAI1CxB,WAAAA,CACEyB,EACA9C,GAEAgN,MAAMlK,GAASrB,KAPDwL,eAAS,EAAAxL,KACTyL,iBAAW,EAOzBzL,KAAK0L,KAAO,yBACZ1L,KAAKwL,UAAYjN,MAAAA,OAAAA,EAAAA,EAASiN,UAC1BxL,KAAKyL,YAAclN,MAAAA,OAAAA,EAAAA,EAASkN,WAC9B,ECOI,MAAOE,UAA4BtE,EAKvCzH,WAAAA,CACmBgM,EACjBlJ,EACAmJ,EACAC,GAEAP,QAAQvL,KALS4L,mBALHlJ,oBAAc,EAAA1C,KACd6L,iBAAW,EAAA7L,KACX8L,kBAAY,EAGT9L,KAAM4L,OAANA,EAMjB5L,KAAK0C,eAAiBA,EACtB1C,KAAK6L,YAAcA,EACnB7L,KAAK8L,aAAeA,EAEpB9L,KAAK4L,OAAOG,iBAAiB,QAAS/I,IAIpCgJ,WACE,IACEhM,KAAKmI,WAAW,CACdtF,OAAQ,QACRxB,QAAS,mDACT8D,QAASnC,IAEb,KAIJhD,KAAK4L,OAAOG,iBAAiB,QAAS/I,IACpChD,KAAKmI,WACY,MAAfnF,EAAM+C,KACF,CACElD,OAAQ,QACRsC,QAASnC,EACTwI,UAAWxI,EAAM+C,KACjB0F,YAAazI,EAAMH,aAAUoJ,GAE/B,CACEpJ,OAAQ,QACRxB,QACE2B,EAAMH,QAAU,2CAClBsC,QAASnC,EACTwI,UAAWxI,EAAM+C,KACjB0F,YAAazI,EAAMH,aAAUoJ,MAKvCjM,KAAK4L,OAAOG,iBAAiB,UAAW/I,IACtC,IACE,MAAMpC,EAAc2D,KAAK2H,MAAMlJ,EAAMmJ,MACrC,IAAKjD,EAAmBtI,GAMtB,YALAZ,KAAK4H,MAAM,CACT/G,KAAM,gBACNQ,QAAS,gCACT8K,KAAMnJ,EAAMmJ,OAIhBnM,KAAKqI,cAAczH,EACrB,CAAE,MAAOO,GACPnB,KAAK4H,MAAM,CACT/G,KAAM,gBACNQ,QAAS,iCACTF,MAAOA,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,GACvDgL,KAAMnJ,EAAMmJ,MAEhB,GAEJ,CAEO,mBAAaC,CAClB9E,GAEA,IAAIsE,EAA2B,KAE/B,IAAIS,IAAAA,EAAAhD,EAAAiD,EACF,MAAMC,EAAsBF,OAAhBA,EAAG/E,EAAOiF,QAAMF,EAnFX,0BAoFjB,IAAIG,EAEJ,MAAMnB,UAAUhC,EAAA/B,EAAO3I,mBAAS0K,EAAhBA,EAAkB8B,eAAlB9B,EAA0BgC,UAAWpC,EAC/C/F,GAAyB,OAAhBoJ,EAAAhF,EAAO3I,mBAAS2N,EAAhBA,EAAkBnB,eAAlBmB,EAA0BpJ,SAAU,SAEnD,GAAIoE,EAAOmF,UAAW,CACpB,MAAMC,EAAYpF,EAAOmF,UAAU7D,SAAS,KAAO,IAAM,IACzD4D,EAAM,GAAGlF,EAAOmF,YAAYC,WAAmBxJ,aAAkBmI,GACnE,MACEmB,EAAM,GAAGD,qCAA4BjF,EAAOqF,kBAAkBzJ,aAAkBmI,IAGlF,MAAMuB,EAAY,CAjGF,UAkGZtF,EAAOuF,eACTD,EAAUtE,KAAK,UAAUhB,EAAOuF,iBAElCjB,EAAS,IAAIkB,UAAUN,EAAKI,GAE5B,MAAMG,QAA2B,IAAIC,QAEnC,CAACC,EAASC,KACVtB,EAAQG,iBACN,OACA,SAAKoB,EACH,MAAM7D,EAAiBF,EAAmB9B,GAE1C6F,OAAAA,EAAAvB,IAAAuB,EAAQC,KAAK7I,KAAKC,UAAU8E,KAE9B,CAAE+D,MAAM,IAGVzB,EAAQG,iBAAiB,QAAS/I,IAIhCgJ,WACE,IACEkB,EACE,IAAI5B,EACF,qDAGN,KAIJM,EAAQG,iBAAiB,QAAU/I,IAMjCkK,EACE,IAAI5B,EALJtI,EAAMH,SACU,MAAfG,EAAM+C,KACH,kEACA,uEAEgC,CAClCyF,UAAWxI,EAAM+C,KACjB0F,YAAazI,EAAMH,aAAUoJ,OAKnCL,EAAQG,iBACN,UACC/I,IACC,MAAM3B,EAAUkD,KAAK2H,MAAMlJ,EAAMmJ,MAE5BjD,EAAmB7H,KAIH,qCAAjBA,EAAQR,KACVoM,EAAQ5L,EAAQkE,wCAEhB1G,QAAQC,KACN,0DAIN,CAAEuO,MAAM,OAINC,gBACJA,EAAeC,0BACfA,EAAyBC,wBACzBA,GACET,EAEElB,EAActD,QAAYiF,EAAAA,EAA2B,aACrD1B,EAAevD,EAAYgF,GAEjC,WAAW5B,EACTC,EACA0B,EACAzB,EACAC,EAEJ,CAAE,MAAO3K,GAAOsM,IAAAA,EAEd,aADAA,EAAA7B,IAAA6B,EAAQ3K,QACF3B,CACR,CACF,CAEO2B,KAAAA,GACL9C,KAAK4L,OAAO9I,MAAM,IAAM,0BAC1B,CAEOhB,WAAAA,CAAYT,GACjBrB,KAAK4L,OAAOwB,KAAK7I,KAAKC,UAAUnD,GAClC,CAEO,iBAAMgF,CAAYC,GACvBzH,QAAQC,KACN,gDAAgDwH,8CAEpD,ECtNI,SAAUoH,EAAoBC,GAClC,MAAMC,EAAS,IAAI3P,WAAW0P,GAG9B,OADmBE,OAAOC,KAAKxM,OAAOyM,gBAAgBH,GAExD,UAEgBI,EAAoBC,GAClC,MAAMC,EAAeL,OAAOM,KAAKF,GAC3BG,EAAMF,EAAanG,OACnBsG,EAAQ,IAAIpQ,WAAWmQ,GAC7B,IAAK,IAAIE,EAAI,EAAGA,EAAIF,EAAKE,IACvBD,EAAMC,GAAKJ,EAAaK,WAAWD,GAErC,OAAOD,EAAMT,MACf,CCfA,MAAMY,EAAW,IAAIC,IAEL,SAAAC,EAA0BhD,EAAciD,GACtD,OAAcC,MAAAA,EAAuBC,KACnC,MAAMC,EAAYN,EAASO,IAAIrD,GAC/B,GAAIoD,EACF,OAAOF,EAAQI,UAAUF,GAI3B,GAAID,EACF,IAGE,aAFMD,EAAQI,UAAUH,QACxBL,EAASS,IAAIvD,EAAMmD,EAErB,CAAE,MAAO1N,GACP,UAAUC,MACR,sBAAsBsK,+BAAkCmD,aAAgB1N,IAE5E,CAGF,MAAM+N,EAAO,IAAIC,KAAK,CAACR,GAAa,CAAE9N,KAAM,2BACtCuO,EAAUC,IAAIC,gBAAgBJ,GACpC,IAGE,aAFMN,EAAQI,UAAUI,QACxBZ,EAASS,IAAIvD,EAAM0D,EAErB,CAAE,MAAAG,GACAF,IAAIG,gBAAgBJ,EACtB,CAEA,IAIE,MACMK,EAAY,sCADH3B,KAAKa,WAEdC,EAAQI,UAAUS,GACxBjB,EAASS,IAAIvD,EAAM+D,EACrB,CAAE,MAAOtO,GACP,MAAU,IAAAC,MACR,sBAAsBsK,8IAE1B,EAEJ,CC3CO,MAAMgE,EAAwBhB,EACnC,oBAEA,i2HCkCI,MAAOiB,UAAyBtI,EAepCzH,WAAAA,CACEgQ,EACAlN,EACAmJ,EACAC,EACAxE,EAAgD,CAAA,GAEhDiE,MAAMjE,GAAQtH,KArBT0C,oBAAc,EAAA1C,KACL6L,iBAAW,EAAA7L,KACX8L,kBAAY,EAAA9L,KAEpB4P,UAAI,EAAA5P,KACJ6P,aAAc,EACdC,KAAAA,aAAe,EACfC,KAAAA,oBAA2C,KAAI/P,KAC/CgQ,cAAoC,GAAEhQ,KACtCiQ,eAAgC,KAEhCC,KAAAA,eAAsC,KACtCC,KAAAA,oBAAsD,KAU5DnQ,KAAK4P,KAAOA,EACZ5P,KAAK0C,eAAiBA,EACtB1C,KAAK6L,YAAcA,EACnB7L,KAAK8L,aAAeA,EAEpB9L,KAAKoQ,yBACP,CAEO,mBAAahE,CAClB9E,GAEA,IAAI+I,EAGJ,GAAI,sBAAuB/I,GAAUA,EAAO+I,kBAE1CA,EAAoB/I,EAAO+I,sBAClB,MAAA,YAAa/I,KAAUA,EAAOqF,QAkCvC,MAAM,IAAIvL,MACR,yEAjCF,IAAIiI,IAAAA,EAAAiD,EAAAD,EACF,MAAMhB,GAA0BhC,OAAhBA,EAAA/B,EAAO3I,YAAiB,OAAR0K,EAAhBA,EAAkB8B,aAAM,EAAxB9B,EAA0BgC,UAAWpC,EAC/C/F,GAAyB,OAAhBoJ,EAAAhF,EAAO3I,YAAiB,OAAR2N,EAAhBA,EAAkBnB,aAAM,EAAxBmB,EAA0BpJ,SAAU,SAG7CsJ,EAAM,GAvDOD,EAqDe,OAAhBF,EAAG/E,EAAOiF,QAAMF,EAxDjB,4BAIhBE,EAAO+D,QAAQ,YAAa,qDAsDkChJ,EAAOqF,kBAAkBzJ,aAAkBmI,IACpG7H,QAAiB+M,MAAM/D,GAE7B,IAAKhJ,EAASgN,GACZ,MAAM,IAAIpP,MACR,2BAA2BoC,EAAStD,UAAUsD,EAASiN,cAO3D,GAFAJ,SADmB7M,EAASkN,QACHC,OAEpBN,EACH,MAAU,IAAAjP,MAAM,0CAEpB,CAAE,MAAOD,GACP,IAAIyP,EAAMzP,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,GAM1D,MALIA,aAAiBC,OAASD,EAAME,QAAQuH,SAAS,SACnDgI,EACE,gGAGE,IAAIxP,MACR,gDAAgDkG,EAAOqF,YAAYiE,IAEvE,CAKF,CArFJ,IAA2BrE,EAuFvB,MAAMqD,EAAO,IAAIiB,EAEjB,IAEE,MAAMnO,EAAiB,QAAQoO,KAAKC,QAC9BlF,EAActD,EAAY,aAC1BuD,EAAevD,EAAY,aAC3B1I,EAAa,IAAI8P,EACrBC,EACAlN,EACAmJ,EACAC,EACAxE,GAII0J,EAAa1J,EAAO0J,YA3GD,kCA6HVC,IAAAA,QAfTrB,EAAKsB,QAAQF,EAAYX,SAGrB,IAAArD,QAAcC,IACtB,GAAIpN,EAAWgQ,YACb5C,QACK,CACL,MAAMkE,EAAcA,KAClBvB,EAAKwB,IAAIC,EAAUC,UAAWH,GAC9BlE,KAEF2C,EAAK2B,GAAGF,EAAUC,UAAWH,EAC/B,IAGEvB,EAAKlE,OACP7L,EAAW6C,gBAC6B,OAAtCuO,EAAArB,EAAKlE,KAAK8F,MAAM,6BAAsB,EAAtCP,EAAyC,KAAMrB,EAAKlE,MAInDpE,EAAOhJ,gBACJsR,EAAK6B,iBAAiBC,sBAAqB,GAGnD,MAAMpI,EAAiBF,EAAmB9B,GAS1C,OAPAzH,EAAW+H,MAAM,CACf/G,KAAMsI,EACN9H,QAASiI,UAGLzJ,EAAWiC,YAAYwH,GAEtBzJ,CACT,CAAE,MAAOsB,GAEP,YADMyO,EAAKzH,aACLhH,CACR,CACF,CAEQiP,uBAAAA,GAAuBtQ,IAAAA,EAC7BE,KAAAA,KAAK4P,KAAK2B,GAAGF,EAAUC,UAAW9Q,iBAChCV,EAAK+P,aAAc,EACnBhR,QAAQgJ,KAAK,wBACf,GAEA7H,KAAK4P,KAAK2B,GAAGF,EAAUM,aAAc9O,IACnC7C,KAAK6P,aAAc,EACnB7P,KAAKmI,WAAW,CACdtF,OAAQ,QACRsC,QAAS,IAAIC,WAAW,QAAS,CAAEvC,OAAQA,MAAAA,OAAAA,EAAAA,EAAQ+O,iBAIvD5R,KAAK4P,KAAK2B,GAAGF,EAAUQ,uBAAwBC,IACzCA,IAAUC,EAAgBJ,eAC5B3R,KAAK6P,aAAc,EACnB7P,KAAKmI,WAAW,CACdtF,OAAQ,QACRxB,QAAS,uCAAuCyQ,IAChD3M,QAAS,IAAIe,MAAM,iCAMzBlG,KAAK4P,KAAK2B,GACRF,EAAUW,aACV,CAACC,EAAqBC,KACpB,IACE,MAAM7Q,EAAUkD,KAAK2H,OAAM,IAAIiG,aAAcC,OAAOH,IAGpD,GAAqB,UAAjB5Q,EAAQR,KACV,OAGEqI,EAAmB7H,GACrBrB,KAAKqI,cAAchH,GAEnBxC,QAAQC,KAAK,iCAAkCuC,EAEnD,CAAE,MAAOF,GACPtC,QAAQC,KAAK,yCAA0CqC,GACvDtC,QAAQC,KAAK,gBAAgB,IAAIqT,aAAcC,OAAOH,GACxD,IAIJjS,KAAK4P,KAAK2B,GACRF,EAAUgB,gBACV7R,eACE8R,EACAC,EACAC,GAEA,GACEF,EAAMG,OAASC,EAAMC,KAAKC,OAC1BJ,EAAYK,SAASjK,SAAS,SAC9B,CAEA,MAAMkK,EAAmBR,EACnBS,EAAeD,EAAiBE,SAKtC,GAJAD,EAAaE,UAAW,EACxBF,EAAaG,UAAW,EAGpBpT,EAAKmQ,gBAAkB8C,EAAaI,UACtC,UACQJ,EAAaI,UAAUrT,EAAKmQ,eACpC,CAAE,MAAO9O,GACPtC,QAAQC,KACN,qDACAqC,EAEJ,CAIF4R,EAAaK,MAAMC,QAAU,OAC7BC,SAASC,KAAKC,YAAYT,GAG1BjT,EAAKkQ,cAAc1H,KAAKyK,GAGU,IAA9BjT,EAAKkQ,cAAcjI,SAET,MAAZjI,EAAKX,SAALW,EAAKX,QAAU,CAAE0B,KAAM,+BAInBf,EAAK2T,kBAAkBX,EAC/B,CACF,GAGF9S,KAAK4P,KAAK2B,GACRF,EAAUqC,sBACVlT,eAAOmT,GAEH7T,EAAK6C,WADHgR,EAAS5L,OAAS,GAElB4L,EAAS,GAAGd,SAASe,WAAW,SAAW,WAG7B,YAEpB,GAGF5T,KAAK4P,KAAK2B,GACRF,EAAUwC,wBACTrB,IAAkC,IAAAsB,EAC7BA,OAAJA,EAAItB,EAAYK,WAAZiB,EAAsBF,WAAW,UACnC5T,KAAKmI,WAAW,CACdtF,OAAQ,QACRsC,QAAS,IAAIC,WAAW,QAAS,CAAEvC,OAAQ,0BAKrD,CAEOC,KAAAA,GACL,GAAI9C,KAAK6P,YAAa,CACpB,IAEE7P,KAAK4P,KAAK6B,iBAAiBsC,uBAAuB9L,QAChD+L,IACMA,EAAY1B,OACd0B,EAAY1B,MAAM2B,QAI1B,CAAE,MAAO9S,GACPtC,QAAQC,KAAK,+BAAgCqC,EAC/C,CAGInB,KAAK+P,sBACP/P,KAAK+P,oBAAoBjN,QAAQoR,MAAM/S,IACrCtC,QAAQC,KAAK,uCAAwCqC,KAEvDnB,KAAK+P,oBAAsB,MAI7B/P,KAAKgQ,cAAc/H,QAAQkM,IACrBA,EAAQC,YACVD,EAAQC,WAAWC,YAAYF,KAGnCnU,KAAKgQ,cAAgB,GAErBhQ,KAAK4P,KAAKzH,YACZ,CACF,CAEO,iBAAMrG,CAAYT,GACvB,GAAKrB,KAAK6P,aAAgB7P,KAAK4P,KAAK6B,kBAQpC,KAAI,qBAAsBpQ,GAK1B,IACE,MACM8K,GADU,IAAImI,aACCC,OAAOhQ,KAAKC,UAAUnD,UAErCrB,KAAK4P,KAAK6B,iBAAiB+C,YAAYrI,EAAM,CAAEsI,UAAU,GACjE,CAAE,MAAOtT,GACPnB,KAAK4H,MAAM,CACT/G,KAAM,qBACNQ,QAAS,CACPA,UACAF,WAGJtC,QAAQsC,MAAM,qCAAsCA,EACtD,OA1BEtC,QAAQC,KACN,kEA0BN,CAGO4V,OAAAA,GACL,OAAO1U,KAAK4P,IACd,CAEO,iBAAMvJ,CAAYC,GACvB,IAAKtG,KAAK6P,cAAgB7P,KAAK4P,KAAK6B,iBAIlC,YAHA5S,QAAQC,KACN,2EAMJ,MAAM6V,EAAsB3U,KAAK4P,KAAK6B,iBAAiBmD,oBACrDlC,EAAMmC,OAAOC,YAGf,SAAIH,GAAAA,EAAqBrC,MACvB,IAEMhM,QACIqO,EAAoBrC,MAAMyC,aAE1BJ,EAAoBrC,MAAM0C,QAEpC,CAAE,MAAOC,SAEDjV,KAAK4P,KAAK6B,iBAAiBC,sBAAsBpL,EACzD,YAGUtG,KAAC4P,KAAK6B,iBAAiBC,sBAAsBpL,EAE3D,CAEQ,uBAAMmN,CAAkBnB,GAC9B,IAEE,MAAM4C,EAAe,IAAIC,aACzBnV,KAAK+P,oBAAsBmF,EAG3BlV,KAAKkQ,eAAiBgF,EAAaE,iBACnCpV,KAAKkQ,eAAemF,QAAU,KAC9BrV,KAAKkQ,eAAeoF,sBAAwB,GAG5C,MAAMC,EAAc,IAAIC,YAAY,CAAClD,EAAMmD,mBAGrCvS,EAASgS,EAAaQ,wBAAwBH,GAGpDrS,EAAOgO,QAAQlR,KAAKkQ,sBAEdR,EAAsBwF,EAAaS,cACzC,MAAM/G,EAAU,IAAIgH,iBAAiBV,EAAc,qBAGnDlV,KAAKkQ,eAAegB,QAAQtC,GAG5BA,EAAQiH,KAAKC,YAAY,CACvBjV,KAAM,YACN2H,OAAQxI,KAAK8L,aAAatD,OAC1BK,WAAY7I,KAAK8L,aAAajD,aAIhC+F,EAAQiH,KAAKE,UAAa/S,IACxB,MAAOgT,EAAWC,GAAajT,EAAMmJ,KAKrC,GAAI8J,EAFoB,IAES,CAE/B,MAAMC,EAAcxI,EAAoBsI,EAAUpI,QAG5CuI,EAAUnW,KAAK8P,eAGrB9P,KAAKqI,cAAc,CACjBxH,KAAM,QACNuV,YAAa,CACXC,cAAeH,EACfnU,SAAUoU,IAGhB,GAIFjT,EAAOgO,QAAQtC,EACjB,CAAE,MAAOzN,GACPtC,QAAQC,KAAK,kCAAmCqC,EAClD,CACF,CAEOmV,cAAAA,CAAenW,GACpBH,KAAKgQ,cAAc/H,QAAQkM,IACzBA,EAAQhU,OAASA,GAErB,CAEO,0BAAMoW,CAAqBC,GAChC,KAAM,cAAeC,iBAAiBzS,WACpC,MAAM,IAAI5C,MAAM,8CAIlB,MAAMsV,EAAW1W,KAAKgQ,cAAc2G,IAAInW,eAAM2T,GAC5C,UACQA,EAAQhB,UAAUqD,EAC1B,CAAE,MAAOrV,GAEP,MADAtC,QAAQsC,MAAM,2CAA4CA,GACpDA,CACR,CACF,SAEM6L,QAAQ4J,IAAIF,GAGlB1W,KAAKiQ,eAAiBuG,CACxB,CAEO,yBAAMK,CAAoBL,GAC/B,IAAKxW,KAAK6P,cAAgB7P,KAAK4P,KAAK6B,iBAClC,MAAU,IAAArQ,MACR,0EAIJ,IAEE,MAAM0V,EACJ9W,KAAK4P,KAAK6B,iBAAiBmD,oBAAoBlC,EAAMmC,OAAOC,YAG1DgC,MAAAA,GAAAA,EAA4BxE,cACxBwE,EAA2BxE,MAAM2B,aAC7BjU,KAAC4P,KAAK6B,iBAAiBsF,eAC/BD,EAA2BxE,QAK/B,MAAM0E,EAA0C,CAC9CR,SAAU,CAAES,MAAOT,GACnBU,kBAAkB,EAClBC,kBAAkB,EAClBC,iBAAiB,EACjBC,aAAc,CAAEC,MAAO,IAInBC,QAAmBC,EAAsBR,SAGzChX,KAAK4P,KAAK6B,iBAAiBgG,aAAaF,EAAY,CACxD7L,KAAM,aACNxI,OAAQwP,EAAMmC,OAAOC,YAEzB,CAAE,MAAO3T,GACPtC,QAAQsC,MAAM,iCAAkCA,GAGhD,UACQnB,KAAK4P,KAAK6B,iBAAiBC,sBAAqB,EACxD,CAAE,MAAOgG,GACP7Y,QAAQsC,MACN,0DACAuW,EAEJ,CAEA,MAAMvW,CACR,CACF,CAEOqF,0BAAAA,GACL,OAAKxG,KAAKkQ,gBAEcyH,WAAnBxH,sBAALnQ,KAAKmQ,oBAAwB,IAAIlS,WAC/B+B,KAAKkQ,eAAe0H,oBAEtB5X,KAAKkQ,eAAe2H,qBAAqB7X,KAAKmQ,qBACnCnQ,KAACmQ,qBANyB,IAOvC,ECvhBK3P,eAAesX,EACpBxQ,GAEA,MAAMyQ,EAlBR,SAAiCzQ,GAE/B,OAAIA,EAAOyQ,eACFzQ,EAAOyQ,eAIZ,sBAAuBzQ,GAAUA,EAAO+I,kBACnC,SAIF,WACT,CAKyB2H,CAAwB1Q,GAE/C,OAAQyQ,GACN,IAAK,YACH,OAAOpM,EAAoBS,OAAO9E,GACpC,IAAK,SACH,OAAOqI,EAAiBvD,OAAO9E,GACjC,QACE,UAAUlG,MAAM,4BAA4B2W,KAElD,UCpCgBE,IACd,MACE,CACE,iBACA,mBACA,iBACA,OACA,SACA,QACArP,SAASsP,UAAUC,WAEpBD,UAAUE,UAAUxP,SAAS,QAAU,eAAgB0K,QAE5D,gBCVsB+E,EACpBC,EAA2B,CACzBC,QAAS,EAETC,QAAS,MAGX,IAAIC,EAAQH,EAAYC,YACDG,EAAvB,GDKO,WAAWC,KAAKT,UAAUE,WCJ/BK,EAA2BC,OAAtBA,EAAGJ,EAAYE,SAAOE,EAAID,OACtBR,GAAAA,IAAe,KAAAW,EACxBH,EAAuBG,OAAlBA,EAAGN,EAAYO,KAAGD,EAAIH,CAC7B,CAEIA,EAAQ,SACA,IAAAzL,QAAQC,GAAWjB,WAAWiB,EAASwL,GAErD,OCfaK,UAAyB5a,EAC7B,yBAAa6a,CAClBxa,GAEA,MAAMya,EAAc9a,EAAiBC,eAAeI,GAEhDya,EAAYvZ,gBACduZ,EAAYvZ,eAAe,CAAES,OAAQ,eAEnC8Y,EAAYtZ,yBACdsZ,EAAYtZ,wBAAwB,CAAEY,iBAAiB,IAErD0Y,EAAYxZ,cACdwZ,EAAYxZ,aAAa,CAAES,KAAM,cAE/B+Y,EAAYtZ,yBACdsZ,EAAYtZ,wBAAwB,CAAEY,iBAAiB,IAGzD,IAAIT,EAAoC,KACxC,IAGE,aAFMwY,EAAWW,EAAYC,iBAC7BpZ,QAAmBiY,EAAiBvZ,GACzB,IAAAua,EAAiBE,EAAanZ,EAC3C,CAAE,MAAOsB,GAAO,IAAA+X,EAKd,MAJIF,EAAYvZ,gBACduZ,EAAYvZ,eAAe,CAAES,OAAQ,iBAE7B,OAAVgZ,EAAArZ,IAAAqZ,EAAYpW,QACN3B,CACR,CACF,ECzBF,MAGMgY,EAAqB,CACzBjC,kBAAkB,EAClBC,kBAAkB,EAElBC,iBAAiB,EAEjBC,aAAc,CAAEC,MAAO,UAGZ8B,EACJ,mBAAahN,EAAOvD,WACzBA,EAAUL,OACVA,EAAM6Q,8BACNA,EAA6BC,cAC7BA,EAAaC,aACbA,EAAYC,kBACZA,EAAiBna,QACjBA,IAEA,IAAI8F,EAA+B,KAC/BsU,EAAkC,KAEtC,IACE,MAAMlb,EAAOS,EACX6J,CAAAA,WAAY,CAAEyO,MAAOzO,IAClBsQ,GAGL,GAAIlB,KAAiBoB,EAA+B,CAClD,MAEMK,SADE7L,OAAOqK,UAAUyB,aAAaC,oBACDC,KACnCC,GAGa,eAAXA,EAAErH,MACF,CAAC,SAAU,YAAa,YAAYoH,KAAKE,GACvCD,EAAEE,MAAMC,cAAcrR,SAASmR,KAGjCL,IACFnb,EAAQiY,SAAW,CAAEc,MAAOoC,EAAYlD,UAE5C,CAEI8C,IACF/a,EAAQiY,SAAW4C,EAAMc,sBAAsBZ,IAGjD,MAAMa,EACJjC,UAAUyB,aAAaS,0BAA0BvR,WAEnD1D,EAAU,IAAI0I,OAAOsH,aACnBgF,EAA+B,CAAEtR,cAAe,CAAA,GAElD,MAAMwR,EAAWlV,EAAQiQ,iBACzB,IAAK+E,EAA8B,CAEjC,MAAMG,EAAmBd,GA5D/B,0GA6DYrU,EAAQwQ,aAAa3G,UAAUsL,EACvC,OACM5K,EACJvK,EAAQwQ,aACI,MAAZ4D,OAAY,EAAZA,EAAkC,mBAGpC,MAAMgB,EAAWvb,EAAKwb,CAAAA,gBAAgB,GAASjc,GAC/Ckb,QAAoBvB,UAAUyB,aAAac,aAAa,CACtDC,MAAOH,IAGT,MAAMrX,EAASiC,EAAQuQ,wBAAwB+D,GACzC7K,EAAU,IAAIgH,iBAAiBzQ,EAAS,qBAC9CyJ,EAAQiH,KAAKC,YAAY,CAAEjV,KAAM,YAAa2H,SAAQK,eAEtD3F,EAAOgO,QAAQmJ,GACfA,EAASnJ,QAAQtC,SAEXzJ,EAAQwV,SAEd,MAAMC,QAAoB1C,UAAU0C,YAAYC,MAAM,CACpDnP,KAAM,eAER,OAAO,IAAI0N,EACTjU,EACAkV,EACAzL,EACA6K,EACAvW,EACA0X,EACAvb,EAEJ,CAAE,MAAO8B,GAAO2Z,IAAAA,EAAAC,EAKd,MAJW,OAAXD,EAAArB,IAAAqB,EAAaE,YAAY/S,QAAQqK,IAC/BA,EAAM2B,SAER8G,OAAAA,EAAA5V,IAAA4V,EAASjY,QACH3B,CACR,CACF,CAGQ,4BAAO+Y,CACbZ,GAEA,GAAKA,EAGL,OAAOrB,IAAgB,CAAEX,MAAOgC,GAAkB,CAAErC,MAAOqC,EAC7D,CAEA1Z,WAAAA,CACkBuF,EACAkV,EACAzL,EACT6K,EACCwB,EACAL,EACAvb,EAGIR,QAAQsC,OATJgE,KAAAA,aACAkV,EAAAA,KAAAA,cACAzL,EAAAA,KAAAA,oBACT6K,iBAAA,EAAAzZ,KACCib,uBAAA,EAAAjb,KACA4a,iBAAA,EAAA5a,KACAX,aA4BF6b,EAAAA,KAAAA,cAAwB,EA0CxBC,KAAAA,wBAA0B,KAChC,GAA+B,WAA3Bnb,KAAK4a,YAAY9I,MACnB9R,KAAKX,QAAQ,yCAEHW,KAAKkb,aAAc,CAAA,IAAAE,EAE7B,MAAO9I,GAAStS,KAAKyZ,YAAY4B,kBAC3B7E,SAAEA,UAAU4E,EAAG9I,MAAAA,OAAAA,EAAAA,EAAOgJ,eAAaF,EAAI,CAAA,EAC7Cpb,KAAKub,eAAe/E,GAAUtC,MAAM/S,IAClCnB,KAAKX,QACH,wDACA8B,IAGN,GA1FgBnB,KAAOmF,QAAPA,EACAnF,KAAQqa,SAARA,EACAra,KAAO4O,QAAPA,EACT5O,KAAWyZ,YAAXA,EACCzZ,KAAiBib,kBAAjBA,EACAjb,KAAW4a,YAAXA,EACA5a,KAAOX,QAAPA,EAKRW,KAAK4a,YAAY7O,iBAAiB,SAAU/L,KAAKmb,wBACnD,CAEQK,0BAAAA,GACN,IAAK,MAAMlJ,KAAStS,KAAKyZ,YAAYuB,YACnC1I,EAAM2B,OAERjU,KAAKib,kBAAkB9S,YACzB,CAEO,WAAMrF,GACX9C,KAAKwb,6BACLxb,KAAK4a,YAAYa,oBACf,SACAzb,KAAKmb,+BAEGnb,KAACmF,QAAQrC,OACrB,CAEO4Y,QAAAA,CAASpV,GACdtG,KAAK4O,QAAQiH,KAAKC,YAAY,CAAEjV,KAAM,WAAYyF,WACpD,CAGO,oBAAMiV,CAAejC,GAC1B,IACE,GAAItZ,KAAKkb,aACP,MAAU,IAAA9Z,MAAM,qCAElBpB,KAAKkb,cAAe,EAEpB,MAAM3c,EAAOS,EACRma,CAAAA,EAAAA,GAGDG,IACF/a,EAAQiY,SAAW4C,EAAMc,sBAAsBZ,IAIjD,MAAMiB,EAAWvb,EAAA,CAAKwb,gBAAgB,GAASjc,GAIzCod,QAAuBzD,UAAUyB,aAAac,aAAa,CAC/DC,MAAOH,IAGTva,KAAKwb,6BAGLxb,KAAKyZ,YAAckC,EACnB3b,KAAKib,kBACHjb,KAAKmF,QAAQuQ,wBAAwBiG,GAGvC3b,KAAKib,kBAAkB/J,QAAQlR,KAAKqa,SACtC,CAAE,MAAOlZ,GAEP,MADAnB,KAAKX,QAAQ,iCAAkC8B,GACzCA,CACR,CAAC,QACCnB,KAAKkb,cAAe,CACtB,CACF,ECrMK,MAAMU,EAA2BlN,EACtC,uBAEA,i8ECEW,MAAAmN,EACJ,mBAAazP,EAAOvD,WACzBA,EAAUL,OACVA,EAAMyH,eACNA,EAAcsJ,aACdA,IAEA,IAAIpU,EAA+B,KAC/B4N,EAAwC,KAC5C,IACE5N,EAAU,IAAIgQ,aAAa,CAAEtM,eAC7B,MAAMwR,EAAWlV,EAAQiQ,iBACnB0G,EAAO3W,EAAQ4W,aAGrBhJ,EAAe,IAAIH,MACnBG,EAAaiJ,IAAM,GACnBjJ,EAAakJ,OACblJ,EAAaE,UAAW,EACxBF,EAAaK,MAAMC,QAAU,OAE7BC,SAASC,KAAKC,YAAYT,GAG1B,MAAMmJ,EAAc/W,EAAQgX,+BAC5BpJ,EAAaqJ,UAAYF,EAAYG,OAErCP,EAAK5K,QAAQmJ,GACbA,EAASnJ,QAAQgL,SAEXN,EACJzW,EAAQwQ,aACI,MAAZ4D,OAAY,EAAZA,EAAqC,sBAEvC,MAAM3K,EAAU,IAAIgH,iBAAiBzQ,EAAS,wBAmB9C,OAlBAyJ,EAAQiH,KAAKC,YAAY,CAAEjV,KAAM,YAAa2H,WAC9CoG,EAAQsC,QAAQ4K,SAEV3W,EAAQwV,SAGV1K,GAAkB8C,EAAaI,iBAC3BJ,EAAaI,UAAUlD,GAGb,IAAI4L,EACpB1W,EACAkV,EACAyB,EACAlN,EACAmE,EAIJ,CAAE,MAAO5R,GAAO,IAAAmb,EAAAC,EAUd,MARID,OAAJA,EAAIvJ,IAAAuJ,EAAclI,YAChBrB,EAAaqB,WAAWC,YAAYtB,GAE1B,OAAZwJ,EAAAxJ,IAAAwJ,EAAcC,QACVrX,GAA6B,WAAlBA,EAAQ2M,aACf3M,EAAQrC,QAGV3B,CACR,CACF,CAEAvB,WAAAA,CACkBuF,EACAkV,EACAyB,EACAlN,EACAmE,QAJA5N,aAAA,EAAAnF,KACAqa,cAAA,EAAAra,KACA8b,UAAA,EAAA9b,KACA4O,aACAmE,EAAAA,KAAAA,kBAJA,EAAA/S,KAAOmF,QAAPA,EACAnF,KAAQqa,SAARA,EACAra,KAAI8b,KAAJA,EACA9b,KAAO4O,QAAPA,EACA5O,KAAY+S,aAAZA,CACf,CAEI,qBAAM0J,CAAgBjG,GAC3B,KAAM,cAAeC,iBAAiBzS,WACpC,MAAU,IAAA5C,MAAM,oDAIZpB,KAAK+S,aAAaI,UAAUqD,GAAY,GAChD,CAEO,WAAM1T,GAEP9C,KAAK+S,aAAaqB,YACpBpU,KAAK+S,aAAaqB,WAAWC,YAAYrU,KAAK+S,cAEhD/S,KAAK+S,aAAayJ,cACRxc,KAACmF,QAAQrC,OACrB,ECrFI,MAAO4Z,UAA0Bxe,EAC7B,4BAAaye,GACnB,GAAI,aAAczE,UAEhB,IACE,aAAaA,UAAU0E,SAASC,QAAQ,SAC1C,CAAE,MAAOC,GAAI,CAIf,OACF,IAAA,CAEO,yBAAa/D,CAClBxa,GAAuB,IAAAwe,EAEvB,MAAM/D,EAAc9a,EAAiBC,eAAeI,GAEhDya,EAAYvZ,gBACduZ,EAAYvZ,eAAe,CAAES,OAAQ,eAEnC8Y,EAAYtZ,yBACdsZ,EAAYtZ,wBAAwB,CAAEY,iBAAiB,IAGzD,IAAI0c,EAAsB,KACtBnd,EAAoC,KACpCod,EAAwB,KACxBC,EAA6C,KAG7CN,EAAoC,MADD,OAAtBG,EAAGxe,EAAQ4e,cAAWJ,KAGrCH,QAAiBF,EAAkBC,mBAGrC,IAAI,IAAAS,EA6BF,OA1BAF,QAA+BhF,UAAUyB,aAAac,aAAa,CACjEC,OAAO,UAGHrC,EAAWW,EAAYC,iBAC7BpZ,QAAmBiY,EAAiBvZ,IACnCye,EAAOC,SAAgBjQ,QAAQ4J,IAAI,CAClCwC,EAAMhN,OAAMpN,EACPa,CAAAA,EAAAA,EAAWgM,aACdwN,8BAA+B9a,EAAQ8a,8BACvCC,cAAe/a,EAAQ+a,cACvBC,aAAchb,EAAQgb,aACtBC,kBAAmBjb,EAAQib,qBAE7BqC,EAAOzP,OAAMpN,EAAA,GACRa,EAAWiM,aACdmE,CAAAA,eAAgB1R,EAAQ0R,eACxBsJ,aAAchb,EAAQgb,kBAI1B6D,OAAAA,EAAAF,IAAAE,EAAwBpC,YAAY/S,QAAQqK,IAC1CA,EAAM2B,SAERiJ,EAAyB,KAElB,IAAIR,EACT1D,EACAnZ,EACAmd,EACAC,EACAL,EAEJ,CAAE,MAAOzb,GAAOkc,IAAAA,EAAAnE,EAAAoE,EAAAC,EACVvE,EAAYvZ,gBACduZ,EAAYvZ,eAAe,CAAES,OAAQ,iBAEvCmd,OAAAA,EAAAH,IAAAG,EAAwBrC,YAAY/S,QAAQqK,IAC1CA,EAAM2B,SAEE,OAAViF,EAAArZ,IAAAqZ,EAAYpW,cACNwa,OAANA,EAAMN,QAAAM,EAAAA,EAAOxa,sBACbya,EAAMN,UAAAM,EAAQza,SACd,IAAI,IAAA0a,eACFA,EAAMZ,UAAAY,EAAUC,WAChBb,EAAW,IACb,CAAE,MAAOE,IACT,MAAM3b,CACR,CACF,CAMAvB,WAAAA,CACErB,EACAsB,EACOmd,EACAC,EACAL,GAEPrR,MAAMhN,EAASsB,GAAYG,KAJpBgd,WACAC,EAAAA,KAAAA,YACAL,EAAAA,KAAAA,cATDc,EAAAA,KAAAA,+BACAvN,yBAAmB,EAAAnQ,KACnB2d,wBAA+C,KAAI3d,KA8EnD4d,sBAAyB5a,IAMX,cAAhBhD,KAAKE,QACPF,KAAKH,WAAWiC,YAAY,CAC1B+b,iBAAkBnQ,EAPE1K,EAAMmJ,KAAK,GAOuByB,WAKpDkQ,KAAAA,uBAAyB,EAAG3R,WAChB,YAAdA,EAAKtL,MACPb,KAAK2C,WAAWwJ,EAAK4R,SAAW,YAAc,aAEjD/d,KAEOge,oBAAuBC,IAC7Bje,KAAKid,OAAOnB,KAAKA,KAAKoC,sBACpBle,KAAKid,OAAO9X,QAAQgZ,aAEtBne,KAAKid,OAAOnB,KAAKA,KAAKsC,MAAQpe,KAAKG,OACnCH,KAAKid,OAAOrO,QAAQiH,KAAKC,YAAY,CAAEjV,KAAM,qBAC7Cb,KAAKid,OAAOrO,QAAQiH,KAAKC,YAAY,CACnCjV,KAAM,SACN+M,OAAQI,EAAoBiQ,WAIxBI,aAAe,KAErBre,KAAK2C,WAAW,aAChB3C,KAAKid,OAAOrO,QAAQiH,KAAKC,YAAY,CAAEjV,KAAM,cAC7Cb,KAAKid,OAAOnB,KAAKA,KAAKwC,6BACpB,KACAte,KAAKid,OAAO9X,QAAQgZ,YAAc,GAIpCnS,WAAW,KACThM,KAAKid,OAAOnB,KAAKA,KAAKsC,MAAQpe,KAAKG,OACnCH,KAAKid,OAAOrO,QAAQiH,KAAKC,YAAY,CAAEjV,KAAM,sBAC5C,MACJb,KAEOue,gBAAmBC,IACzB,GAA6B,IAAzBA,EAAczW,OAChB,SAKF,IAAI5H,EAAS,EACb,IAAK,IAAImO,EAAI,EAAGA,EAAIkQ,EAAczW,OAAQuG,IACxCnO,GAAUqe,EAAclQ,GAAK,IAI/B,OAFAnO,GAAUqe,EAAczW,OAEjB5H,EAAS,EAAI,EAAIA,EAAS,EAAI,EAAIA,GAC1CH,KA2IMyC,UAAY,EAAGtC,aAEpB,MAAMse,EAAgB3V,OAAO4V,SAASve,GAClCwe,KAAKC,IAAI,EAAGD,KAAKE,IAAI,EAAG1e,IACxB,EACJH,KAAKG,OAASse,EAEVze,KAAKH,sBAAsB8P,EAE7B3P,KAAKH,WAAWyW,eAAemI,GAG/Bze,KAAKid,OAAOnB,KAAKA,KAAKsC,MAAQK,GA7RzBze,KAAKgd,MAALA,EACAhd,KAAMid,OAANA,EACAjd,KAAQ4c,SAARA,EAGP5c,KAAKgd,MAAMpO,QAAQiH,KAAKE,UAAY/V,KAAK4d,sBACzC5d,KAAKid,OAAOrO,QAAQiH,KAAKE,UAAY/V,KAAK8d,uBAEtClB,IAGF5c,KAAK2d,wBAA0B,KAAKmB,IAAAA,EACD,YAA7BxL,SAASyL,iBAA8C,OAAjBD,EAAI9e,KAAK4c,WAALkC,EAAeE,UAC3DtC,EAAkBC,kBAAkBsC,KAAKC,IACvClf,KAAK4c,SAAWsC,KAItB5L,SAASvH,iBACP,mBACA/L,KAAK2d,yBAGX,CAEmB,sBAAMhd,SACZ4K,MAAC5K,mBAERX,KAAK2d,yBACPrK,SAASmI,oBACP,mBACAzb,KAAK2d,yBAIT,IAAI,IAAAwB,QACIA,OAANA,EAAMnf,KAAK4c,eAALuC,EAAAA,EAAe1B,WACrBzd,KAAK4c,SAAW,IAClB,CAAE,MAAOE,GAAI,OAEP9c,KAAKgd,MAAMla,cACP9C,KAACid,OAAOna,OACpB,CAEmBhC,kBAAAA,CAAmBkC,GACpCuI,MAAMzK,mBAAmBkC,GACzBhD,KAAKqe,cACP,CAEmBzc,WAAAA,CAAYoB,OAQUoc,EAAAC,EAPvC9T,MAAM3J,YAAYoB,GAEdA,EAAMoT,YAAYkJ,WAAatf,KAAKzB,QAAQghB,kBAC9Cvf,KAAKzB,QAAQghB,iBAAiBvc,EAAMoT,YAAYkJ,WAG9Ctf,KAAKD,wBAA0BiD,EAAMoT,YAAYrU,WAC/CiB,EAAMoT,YAAYC,uBACpB+I,GAAAC,EAAArf,KAAKzB,SAAQgB,UAAb6f,EAAAlb,KAAAmb,EAAuBrc,EAAMoT,YAAYC,eAInCrW,KAAKH,sBAAsB8P,GAC/B3P,KAAKge,oBAAoBhb,EAAMoT,YAAYC,gBAI/CrW,KAAKI,eAAiB4C,EAAMoT,YAAYrU,SACxC/B,KAAK+C,wBACL/C,KAAK2C,WAAW,YAEpB,CAiEO0D,WAAAA,CAAYC,GAEbtG,KAAKH,sBAAsB8P,EAC7B3P,KAAKH,WAAWwG,YAAYC,GAG5BtG,KAAKgd,MAAMtB,SAASpV,EAExB,CAEOC,yBAAAA,GAKL,OAJuBiZ,MAAnBxf,KAAC0d,qBAAL1d,KAAK0d,mBAAuB,IAAIzf,WAC9B+B,KAAKgd,MAAM3C,SAASzC,oBAEtB5X,KAAKgd,MAAM3C,SAASxC,qBAAqB7X,KAAK0d,yBAClCA,kBACd,CAEOlX,0BAAAA,GAEL,OAAIxG,KAAKH,sBAAsB8P,EACV3P,KAAKH,WAAW2G,8BAK5B,IAAIvI,WAAW,OAGA,MAAxB+B,KAAKmQ,sBAALnQ,KAAKmQ,oBAAwB,IAAIlS,WAC/B+B,KAAKid,OAAO5C,SAASzC,oBAEvB5X,KAAKid,OAAO5C,SAASxC,qBAAqB7X,KAAKmQ,qBACpCnQ,KAACmQ,oBACd,CAEO1J,cAAAA,GACL,OAAWzG,KAACue,gBAAgBve,KAAKuG,4BACnC,CAEOG,eAAAA,GACL,OAAW1G,KAACue,gBAAgBve,KAAKwG,6BACnC,CAEO,uBAAMiZ,EAAkB5W,WAC7BA,EAAUL,OACVA,EAAM6Q,8BACNA,EAA6BC,cAC7BA,IAEA,IAEE,GAAItZ,KAAKH,sBAAsB8L,EAC7B,IAEE,aADU3L,KAACgd,MAAMzB,eAAejC,GACzBtZ,KAAKgd,KACd,CAAE,MAAO7b,GACPtC,QAAQC,KACN,yDACAqC,EAGJ,CAIEnB,KAAKH,sBAAsB8P,SACvB3P,KAAKH,WAAWgX,oBAAoByC,GAAiB,UAIvDtZ,KAAKgd,MAAMla,QAEjB,MAAM4c,QAAiBtG,EAAMhN,OAAO,CAClCvD,WAAYA,MAAAA,EAAAA,EAAc7I,KAAKH,WAAWgM,YAAYhD,WACtDL,OAAQA,MAAAA,EAAAA,EAAUxI,KAAKH,WAAWgM,YAAYrD,OAC9C6Q,gCACAC,gBACAC,aAAcvZ,KAAKzB,QAAQgb,aAC3BC,kBAAmBxZ,KAAKzB,QAAQib,kBAChCna,QAASW,KAAKzB,QAAQc,UAMxB,OAHAW,KAAKgd,MAAQ0C,EACb1f,KAAKgd,MAAMpO,QAAQiH,KAAKE,UAAY/V,KAAK4d,sBAE9B5d,KAACgd,KACd,CAAE,MAAO7b,GAEP,MADAtC,QAAQsC,MAAM,8BAA+BA,GACvCA,CACR,CACF,CAEO,wBAAMwe,EAAmB9W,WAC9BA,EAAUL,OACVA,EAAMyH,eACNA,IAEA,IAEE,GAAIjQ,KAAKH,sBAAsB8L,EAC7B,IAEE,aADU3L,KAACid,OAAOR,gBAAgBxM,GAC3BjQ,KAAKid,MACd,CAAE,MAAO9b,GACPtC,QAAQC,KACN,0DACAqC,EAGJ,CAIEnB,KAAKH,sBAAsB8P,SACnB3P,KAACH,WAAW0W,qBAAqBtG,GAAkB,UAIrDjQ,KAACid,OAAOna,QAElB,MAAM8c,QAAkB/D,EAAOzP,OAAO,CACpCvD,WAAsB,MAAVA,EAAAA,EAAc7I,KAAKH,WAAWiM,aAAajD,WACvDL,OAAc,MAANA,EAAAA,EAAUxI,KAAKH,WAAWiM,aAAatD,OAC/CyH,iBACAsJ,aAAcvZ,KAAKzB,QAAQgb,eAK7B,OAFAvZ,KAAKid,OAAS2C,EAEP5f,KAAKid,MACd,CAAE,MAAO9b,GAEP,MADAtC,QAAQsC,MAAM,+BAAgCA,GACxCA,CACR,CACF,EC5WI,SAAU0e,EACdnd,EACAod,EACAvT,EAtBuB,6BAwBvB,MAAMgH,EAIF,GASJ,MAP8B,kBAAnBuM,EACTvM,EAAKwM,SAAWD,EAAiB,OAAS,WAE1CvM,EAAKyM,OAASF,EAAeE,OAC7BzM,EAAK0M,QAAUH,EAAeG,SAGzB1P,MAAM,GAAGhE,6BAAkC7J,aAA2B,CAC3Ewd,OAAQ,OACR3M,KAAMhP,KAAKC,UAAU+O,GACrB4M,QAAS,CACP,eAAgB,qBAGtB,CCoBA,MAAMC,EAAYxgB,WAAAA,GAAAI,KACRqgB,UAA4D,IAAI5R,GAAK,CAE7E8C,EAAAA,CAAGvO,EAAesd,GACXtgB,KAAKqgB,UAAUE,IAAIvd,IACtBhD,KAAKqgB,UAAUpR,IAAIjM,EAAO,IAAIwd,KAEhC,MAAMC,EAAiBzgB,KAAKqgB,UAAUtR,IAAI/L,GACtCyd,GACFA,EAAeC,IAAIJ,EAEvB,CAEAlP,GAAAA,CAAIpO,EAAesd,GACjB,MAAMG,EAAiBzgB,KAAKqgB,UAAUtR,IAAI/L,GACtCyd,GACFA,EAAeE,OAAOL,EAE1B,CAEAM,IAAAA,CAAK5d,KAAkB6d,GACrB,MAAMJ,EAAiBzgB,KAAKqgB,UAAUtR,IAAI/L,GACtCyd,GACFA,EAAexY,QAAQqY,IACrBA,KAAYO,IAGlB,EAMU,IAAAC,GAAZ,SAAYA,GAEVA,EAAA,gBAAA,kBAEAA,EAAA,mBAAA,qBAEAA,EAAA,qBAAA,uBAEAA,EAAA,qCAAA,uCAEAA,EAAA,WAAA,aAEAA,EAAA,MAAA,QAEAA,EAAA,KAAA,OAEAA,EAAA,MAAA,QAEAA,EAAA,eAAA,iBAEAA,EAAA,iBAAA,mBAEAA,EAAA,kBAAA,oBAEAA,EAAA,iBAAA,mBAEAA,EAAA,aAAA,eAEAA,EAAA,YAAA,cAEAA,EAAA,eAAA,iBAEAA,EAAA,mBAAA,qBAEAA,EAAA,4BAAA,8BAEAA,EAAA,oBAAA,sBAEAA,EAAA,4BAAA,6BACD,CAvCD,CAAYA,IAAAA,EAuCX,WA2DYC,EAMXnhB,WAAAA,CAAYiJ,GALJmY,KAAAA,UAA8B,KAAIhhB,KAClCihB,aAA6B,IAAIb,OACjCc,kBAA4B,KAC7BC,KAAAA,mBAGL,EAAAnhB,KAAKkhB,kBAAoBrY,CAC3B,CAMOuY,YAAAA,CAAaJ,GAClBhhB,KAAKghB,UAAYA,EAGbhhB,KAAKghB,UAAUK,aAAevU,UAAUwU,KAC1CthB,KAAKihB,aAAaL,KAAKE,EAAeQ,MAGtCthB,KAAKghB,UAAUjV,iBAAiB,OAAQ,KACtC/L,KAAKihB,aAAaL,KAAKE,EAAeQ,QAI1CthB,KAAKghB,UAAUjV,iBAAiB,UAAY/I,IAC1C,IACE,MAAMmJ,EAAO5H,KAAK2H,MAAMlJ,EAAMmJ,MAE9B,OAAQA,EAAKoV,cACX,IAAK,kBACHvhB,KAAKihB,aAAaL,KAAKE,EAAeU,gBAAiBrV,GACvD,MACF,IAAK,qBACHnM,KAAKihB,aAAaL,KAAKE,EAAeW,mBAAoBtV,GAC1D,MACF,IAAK,uBACHnM,KAAKihB,aAAaL,KAAKE,EAAeY,qBAAsBvV,GAC5D,MACF,IAAK,uCACHnM,KAAKihB,aAAaL,KAChBE,EAAea,qCACfxV,GAEF,MAEF,IAAK,aACHnM,KAAKihB,aAAaL,KAAKE,EAAec,WAAYzV,GAClDnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,iBACHnM,KAAKihB,aAAaL,KAAKE,EAAegB,eAAgB3V,GACtDnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,mBACHnM,KAAKihB,aAAaL,KAAKE,EAAeiB,iBAAkB5V,GACxDnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,oBACHnM,KAAKihB,aAAaL,KAAKE,EAAekB,kBAAmB7V,GACzDnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,mBACHnM,KAAKihB,aAAaL,KAAKE,EAAemB,iBAAkB9V,GACxDnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,eACHnM,KAAKihB,aAAaL,KAAKE,EAAeoB,aAAc/V,GACpDnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,cACHnM,KAAKihB,aAAaL,KAAKE,EAAeqB,YAAahW,GACnDnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,iBACHnM,KAAKihB,aAAaL,KAAKE,EAAesB,eAAgBjW,GACtDnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,qBACHnM,KAAKihB,aAAaL,KAAKE,EAAeuB,mBAAoBlW,GAC1DnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,8BACHnM,KAAKihB,aAAaL,KAChBE,EAAewB,4BACfnW,GAEFnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,sBACHnM,KAAKihB,aAAaL,KAAKE,EAAeyB,oBAAqBpW,GAC3DnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,8BACHnM,KAAKihB,aAAaL,KAChBE,EAAe0B,4BACfrW,GAEFnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,IAAK,QACHnM,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1V,GAC7C,MACF,QACEtN,QAAQC,KAAK,wBAAyBqN,GAE5C,CAAE,MAAOhL,GACPtC,QAAQsC,MAAM,qCAAsCA,EAAO6B,EAAMmJ,MACjEnM,KAAKihB,aAAaL,KAChBE,EAAee,MACf,IAAIzgB,MAAM,4BAA4BD,KAE1C,IAGFnB,KAAKghB,UAAUjV,iBAAiB,QAAU5K,IACxCtC,QAAQsC,MAAM,mBAAoBA,GAClCnB,KAAKihB,aAAaL,KAAKE,EAAee,MAAO1gB,KAG/CnB,KAAKghB,UAAUjV,iBAAiB,QAAU/I,IAMxC,GALAnE,QAAQ4jB,IACN,0BAA0Bzf,EAAM+C,iBAAiB/C,EAAMH,qBAAqBG,EAAM0f,aAI/E1f,EAAM0f,UAA4B,MAAf1f,EAAM+C,MAAgC,OAAf/C,EAAM+C,KAAgB,CACnE,MAAM4c,EAAe,kCAAkC3f,EAAM+C,UAAU/C,EAAMH,QAAU,uBACvFhE,QAAQsC,MAAMwhB,GACd3iB,KAAKihB,aAAaL,KAAKE,EAAee,MAAO,IAAIzgB,MAAMuhB,GACzD,CAEA3iB,KAAKihB,aAAaL,KAAKE,EAAe8B,MAAO5f,IAEjD,CAuBOuO,EAAAA,CACLvO,EACAsd,GAIAtgB,KAAKihB,aAAa1P,GAAGvO,EAAOsd,EAC9B,CAiBOlP,GAAAA,CACLpO,EACAsd,GAIAtgB,KAAKihB,aAAa7P,IAAIpO,EAAOsd,EAC/B,CA4BOlT,IAAAA,CAAKjB,GAKX,IAAA0W,EAAAC,EACC,IAAK9iB,KAAKghB,WAAahhB,KAAKghB,UAAUK,aAAevU,UAAUwU,KAC7D,UAAUlgB,MAAM,8BAGlB,MAAMC,EAA2B,CAC/BkgB,aAAc,oBACdlL,cAAelK,EAAK4W,YACpBC,OAAmBH,OAAbA,EAAE1W,EAAK6W,SAAMH,EACnBI,mBAAWH,EAAE3W,EAAKtD,YAAUia,EAAI9iB,KAAKkhB,kBACrCgC,cAAe/W,EAAKgX,cAGtBnjB,KAAKghB,UAAU5T,KAAK7I,KAAKC,UAAUnD,GACrC,CAuBO2hB,MAAAA,GACL,IAAKhjB,KAAKghB,WAAahhB,KAAKghB,UAAUK,aAAevU,UAAUwU,KAC7D,MAAM,IAAIlgB,MAAM,8BAUlBpB,KAAKghB,UAAU5T,KAAK7I,KAAKC,UAPQ,CAC/B+c,aAAc,oBACdlL,cAAe,GACf2M,QAAQ,EACRC,YAAajjB,KAAKkhB,oBAItB,CAkBOpe,KAAAA,GAED9C,KAAKmhB,eACPnhB,KAAKmhB,gBAIHnhB,KAAKghB,WACPhhB,KAAKghB,UAAUle,MAAM,IAAM,qBAE/B,EC7eK,MAAMsgB,EAA2B1U,EACtC,uBAEA,ssGCHU,IAAA2U,EAUAC,GAVZ,SAAYD,GACVA,EAAA,SAAA,WACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,WACD,CARD,CAAYA,IAAAA,EAQX,CAAA,IAED,SAAYC,GACVA,EAAA,OAAA,SACAA,EAAA,IAAA,KACD,CAHD,CAAYA,IAAAA,EAGX,CAAA,IAiFY,MAAAC,EAGH,sBAAOC,CACbC,EAAkBF,EAAeG,kBAEjC,MAAO,GAAGD,8BACZ,CAEQ,wBAAOE,CACbplB,GAEA,MAAMklB,EAAUF,EAAeC,gBAAgBjlB,EAAQklB,SACjDG,EAAS,IAAIC,gBAanB,GAVAD,EAAOE,OAAO,WAAYvlB,EAAQwlB,SAClCH,EAAOE,OAAO,QAASvlB,EAAQoS,YAGA1E,IAA3B1N,EAAQylB,gBACVJ,EAAOE,OAAO,kBAAmBvlB,EAAQylB,qBAEf/X,IAAxB1N,EAAQ0lB,aACVL,EAAOE,OAAO,eAAgBvlB,EAAQ0lB,kBAEAhY,IAApC1N,EAAQ2lB,wBAAuC,CACjD,GACE3lB,EAAQ2lB,yBAA2B,IACnC3lB,EAAQ2lB,wBAA0B,EAElC,MAAM,IAAI9iB,MAAM,uDAElBwiB,EAAOE,OACL,6BACAvlB,EAAQ2lB,wBAAwBtS,WAEpC,CACA,QAA6B3F,IAAzB1N,EAAQ4lB,aAA4B,CACtC,GAAI5lB,EAAQ4lB,aAAe,IAAO5lB,EAAQ4lB,aAAe,GACvD,MAAU,IAAA/iB,MAAM,4CAElBwiB,EAAOE,OAAO,gBAAiBvlB,EAAQ4lB,aAAavS,WACtD,CACA,QAAoC3F,IAAhC1N,EAAQ6lB,oBAAmC,CAC7C,GACE7lB,EAAQ6lB,qBAAuB,IAC/B7lB,EAAQ6lB,oBAAsB,IAE9B,MAAM,IAAIhjB,MAAM,mDAElBwiB,EAAOE,OACL,yBACAvlB,EAAQ6lB,oBAAoBxS,WAEhC,CACA,QAAqC3F,IAAjC1N,EAAQ8lB,qBAAoC,CAC9C,GACE9lB,EAAQ8lB,sBAAwB,IAChC9lB,EAAQ8lB,qBAAuB,IAE/B,MAAU,IAAAjjB,MAAM,oDAElBwiB,EAAOE,OACL,0BACAvlB,EAAQ8lB,qBAAqBzS,WAEjC,MAC6B3F,IAAzB1N,EAAQ+lB,cACVV,EAAOE,OAAO,gBAAiBvlB,EAAQ+lB,mBAEPrY,IAA9B1N,EAAQgmB,mBACVX,EAAOE,OACL,qBACAvlB,EAAQgmB,kBAAoB,OAAS,SAIzC,MAAMC,EAAcZ,EAAOhS,WAC3B,OAAO4S,EAAc,GAAGf,KAAWe,IAAgBf,CACrD,CA6BO,cAAOvS,CACZ3S,GAEA,IAAKA,EAAQwlB,QACX,MAAM,IAAI3iB,MAAM,uBAIlB,MAIMvB,EAAa,IAAIkhB,EAHrB,eAAgBxiB,GAAWA,EAAQkmB,WAC/B,KACClmB,EAAyBsK,YAI1B6b,EAAMnB,EAAeI,kBAAkBplB,GAEvCyiB,EAAY,IAAIlU,UAAU4X,GAchC,MAXI,eAAgBnmB,GAAWA,EAAQkmB,YACrCzD,EAAUjV,iBAAiB,OAAQ,KACjCwX,EAAeoB,qBACbpmB,EACAsB,KAKNA,EAAWuhB,aAAaJ,GAEjBnhB,CACT,CAEQ,iCAAa8kB,CACnBpmB,EACAsB,GAEA,MAAM+kB,EAAqB,KAE3B,IAAIC,IAAAA,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAEF,MAAMjJ,QAAenE,UAAUyB,aAAac,aAAa,CACvDC,MAAO,CACLlE,SAAUqO,OAAFA,EAAEtmB,EAAQkmB,iBAARI,EAAAA,EAAoBrO,SAC9BU,iBAAsD4N,OAAtCA,EAAEC,OAAFA,EAAExmB,EAAQkmB,iBAARM,EAAAA,EAAoB7N,mBAAgB4N,EACtD3N,iBAAsD6N,OAAtCA,EAAEC,OAAFA,EAAE1mB,EAAQkmB,iBAARQ,EAAAA,EAAoB9N,mBAAgB6N,EACtD5N,gBAAoD8N,OAArCA,EAAEC,OAAFA,EAAE5mB,EAAQkmB,iBAARU,EAAAA,EAAoB/N,kBAAe8N,EACpD7N,aAA8C+N,OAAlCA,EAAEC,OAAFA,EAAE9mB,EAAQkmB,iBAARY,EAAAA,EAAoBhO,cAAY+N,EAAI,EAClDvc,WAAY,CAAEyO,MAAOsN,MAKnBW,EAAgBD,OAAHA,EAAGjJ,EAAOhB,iBAAiB,SAAxBiK,EAAAA,EAA4BhK,cAC5CkK,EAAmBD,MAAAA,OAAAA,EAAAA,EAAe1c,WAIlCqM,EAAe,IAAIC,aACvBqQ,EAAmB,CAAE3c,WAAY2c,GAAqB,CAAE,SAIpDpC,EAAyBlO,EAAaS,cAG5C,MAAMzS,EAASgS,EAAaQ,wBAAwB2G,GAC9CoJ,EAAa,IAAI7P,iBACrBV,EACA,wBAKEA,EAAarM,aAAe+b,GAC9Ba,EAAW5P,KAAKC,YAAY,CAC1BjV,KAAM,YACN6kB,gBAAiBxQ,EAAarM,WAC9B8c,iBAAkBf,IAKtBa,EAAW5P,KAAKE,UAAY/S,IAC1B,MAAMgT,UAAEA,GAAchT,EAAMmJ,KAEtBkC,EAAQ,IAAIpQ,WAAW+X,GAC7B,IAAI4P,EAAS,GACb,IAAK,IAAItX,EAAI,EAAGA,EAAID,EAAMtG,OAAQuG,IAChCsX,GAAUtkB,OAAOyM,aAAaM,EAAMC,IAEtC,MAAM4H,EAAcpI,KAAK8X,GAEzB/lB,EAAWuN,KAAK,CAAE2V,YAAa7M,KAIjChT,EAAOgO,QAAQuU,GAGY,cAAvBvQ,EAAapD,aACToD,EAAayF,SAIrB9a,EAAWshB,cAAgB,KACzB9E,EAAOrB,YAAY/S,QAAQqK,IACzBA,EAAM2B,SAER/Q,EAAOiF,aACPsd,EAAWtd,aACX+M,EAAapS,QAEjB,CAAE,MAAO3B,GAEP,MADAtC,QAAQsC,MAAM,wCAAyCA,GACjDA,CACR,CACF,EAnOWoiB,EACaG,iBAAmB,gCC7BhCmC,UAAqB3nB,EACzB,mBAAO6a,CAAaxa,GACzB,MAAMya,EAAc6M,EAAa1nB,eAAeI,GAChD,OAAOya,EAAY1a,SACfwa,EAAiBC,aAAaC,GAC9B0D,EAAkB3D,aAAaC,EACrC"}